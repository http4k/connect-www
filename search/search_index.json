{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"changelog/","text":"Changelog \u00b6 This list is not intended to be all-encompassing - it will document major and breaking API changes with their rationale when appropriate. Given version A.B.C.D , breaking changes are to be expected in version number increments where changes in the A or B sections: v5.21.0.0 (uncut) \u00b6 http4k-connect- * - Upgrade dependencies including Kotlin to 2.0.10 http4k-connect-ai-openai- ** - [Breaking] Model ResponseFormat as a sealed class hierarchy. Removed ResponseFormatType as now inherent in the JSON marshalling. Alpha support for json_schema response format, but it's just a map right now with no class structure. v5.20.0.0 \u00b6 http4k-connect- * - Upgrade dependencies, including Kotshi to 3.0.0. Version bump to highlight that this could be a breaking change if you are using the Kotshi annotation processor. http4k-connect-amazon-s3= * - Add CommonPrefixes field to S3 ListObjectsV2 response. H/T @kwydler v5.19.0.2 \u00b6 http4k-connect- * - [Fix] Add missing @JsonSerializable annotation to ReceiveMessage action v5.19.0.1 \u00b6 http4k-connect- * - [Fix] Add missing Kotshi adapter to Core Moshi adapter factory. v5.19.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect- * - [Breaking] http4k has introduced a breaking change in 5.26.0.0. If you are using the typesafe configuration environment, you will need to update your code to use the repackaged Environment classes - these are now in org.http4k.config instead of org.http4k.cloudnative.env . Just updating your imports should be sufficient to fix this. v5.18.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-cognito * - [Breaking] AWS Cognito: Add support for server side authentication ( AdminInitiateAuth and AdminRespondToAuthChallenge). H/T @markth0mas http4k-connect-ai- ** - [Breaking] Repackaged ModelName to common location. Just update imports! http4k-connect-ai-langchain - [Breaking] Added support for LmStudio chat and embedding models. Break is renamed: ChatModelOptions to OpenAiChatModelOptions . http4k-connect-ai-lmstudio * - [New module!] LmStudio adapter module and fake so you can connect to a locally running LLM server running any model. v5.17.1.1 \u00b6 http4k-connect-amazon-sqs- * - [Fix] Type of SQS ReceiveMessage waitTimeSeconds parameter was incorrect. H/T @oharaandrew314 v5.17.1.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-s3- * - Support all storage classes, including the restore lifecycle for glacier. H/T @oharaandrew314 http4k-connect-amazon-s3- * - Support S3 object tagging. H/T @oharaandrew314 v5.17.0.2 \u00b6 http4k-connect-ai-openai - Choices are not optional in conversation completion. http4k-connect-ai-langchain - Fix streaming for OpenAiChatLanguageModel. v5.17.0.1 \u00b6 http4k-connect-ai-langchain - Added support for System messages in Ollama models v5.17.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-ai- * - Migration of the various AI packages (OpenAI/Langchain) to http4k-ai- subpackage name. http4k-connect-ai-openai - [Breaking] Use FloatArray for embeddings instead of List<Float> http4k-connect-ai-ollama * - [New module!] Ollama adapter module so you can use Http4k-connect adapters in LangChain apps. http4k-connect-ai-langchain - Added support for Ollama models v5.16.0.2 \u00b6 http4k-connect-ai-langchain - Properly support all message types in OpenAI Adapter. v5.16.0.1 \u00b6 http4k-connect-langchain - Tools requests cannot be empty for chat completions in OpenAI Adapter. v5.16.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-langchain - [New module!] LangChain adapter module so you can use Http4k-connect adapters in LangChain apps. Currently only OpenAI is supported. http4k-connect-openai- * - [Breaking] Support tool calls and more modern API version for ChatCompletion. v5.15.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-sqs- - [Possible break] Implement JSON version of SQS in both fake and adapter. Ensure you are using an up-to-date version of the AWS SDK (which will support the JSON message format). Massive H/T @oharaandrew314 v5.14.0.0 \u00b6 http4k-connect- * - Upgrade dependencies, including Kotlin to V2! v5.13.0.0 \u00b6 http4k-connect- * - Upgrade dependencies, including Kotlin to 1.9.24 http4k-connect-amazon-dynamodb * - Add StreamsEventResponse model. H/T @charlee-dev http4k-connect-evidently * - [Fix #405] Properly parse evidently project and features names from ARN. H/T @oharaandrew314 v5.12.2.0 \u00b6 http4k-connect- * - Upgrade dependencies v5.12.1.0 \u00b6 http4k-connect- * - Upgrade dependencies v5.12.0.0 \u00b6 http4k-connect- * - Upgrade dependencies, and api changes to support new http4k version. v5.11.0.0 \u00b6 http4k-connect- * - Upgrade dependencies http4k-connect- * - [Breaking] Reordering of the parameters in adapter constructors to put overrideEndpoint at the end of the list, since it is the least commonly used. To fix, just reorder your parameters. v5.10.1.0 \u00b6 http4k-connect- * - Upgrade dependencies http4k-connect-amazon-dynamodb * - Align secondary index constructors in DynamoDbTableMapperSchema. H/T @obecker http4k-connect-amazon-dynamodb-fake - Validate reserved words in DynamoDB condition expressions. H/T @oharaandrew314 v5.10.0.0 \u00b6 http4k-connect- * - Upgrade dependencies http4k-connect-amazon-dynamodb - [Breaking] DynamoDbIndexMapper now supports custom projections. Closes #391. H/T @oharaandrew314 v5.9.0.0 \u00b6 http4k-connect-amazon-dynamodb - [Breaking] keyCondition in query DSL no longer accepts arbitrary attributes. Fixes #380. H/T @obecker v5.8.0.0 \u00b6 http4k-connect- * - Upgrade dependencies, including Kotlin to 1.9.23 http4k-connect-amazon-dynamodb - [Breaking] ExclusiveStartKey in DynamoDbIndexMapper functions is now an unconstrained Key . Fixes #372. H/T @oharaandrew314 v5.7.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-dynamodb - Query builder for DynamoDB. H/T @obecker http4k-connect-amazon-dynamodb - [Breaking] Query and Scan Select field is enum instead of String. To fix, just replace the hardcoded string with the enum! H/T @obecker http4k-connect-amazon-kms - Support for KeySpec property. H/T @oharaandrew314 v5.6.15.0 \u00b6 http4k-connect-storage- * StoragePropertyBag allows storage-backed dynamic backing Read/WriteProperties. Extend StoragePropertyBag and declare typed properties with item<TYPE>() . Properties are stored into the backing storage using standard automarshalling. v5.6.14.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect- * - Add optional endpoint parameter to all AWS service HTTP implementations. H/T @obecker v5.6.13.0 \u00b6 http4k-connect- * - Upgrade dependencies. v5.6.12.0 \u00b6 http4k-connect- * - Upgrade dependencies. v5.6.11.0 \u00b6 http4k-connect-amazon-core - SSO credentials provider now caches credentials until they expire. Stops re-login v5.6.10.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-core - Simpler API for retrieving the AWS credentials of a custom profile. H/T @obecker http4k-connect-amazon-s3 * - Add parameter to force path-style requests to S3 buckets. H/T @obecker v5.6.9.0 \u00b6 http4k-connect-amazon-apprunner * - [New module] Client and fake v5.6.8.2 \u00b6 http4k-connect-amazon-containercredentials * - Add Kotshi adapter to Moshi instance. v5.6.8.1 \u00b6 http4k-connect- * - Fix AutoMarshalledPageAction not recognising arrays with whitespace. v5.6.8.0 \u00b6 http4k-connect- * - Upgrade dependencies. v5.6.7.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-eventbridge * Events can be sent with the ARN and not just with the EventBusName v5.6.6.0 \u00b6 http4k-connect-amazon-dynamodb-client * - [Fix] #344 Handle failures in DynamoDbTableMapper.delete() H/T @obecker http4k-connect-amazon-evidently * Add updateFeature to Evidently. H/T @oharaandrew314 v5.6.5.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect- * - Fix AutomarshalledPagedAction so that it deals with pages of results which do not get returned inside a list but in an object wrapping a list. v5.6.4.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon- ** - Added Amazon Presigner for creating pre-signed requests. H/T @oharaandrew314 http4k-connect-amazon-dynamodb-fake * - [Fix] #327 Query algorithm is slight wrong in fake dynamo. H/T @oharaandrew314 v5.6.3.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-systemsmanager-fake * - [Fix] #339 - Fake Systems Manager does not overwrite parameters - returns 400 v5.6.2.0 \u00b6 http4k-connect- * - Upgrade dependencies. v5.6.1.0 \u00b6 http4k-connect- * - Upgrade dependencies. v5.6.0.0 \u00b6 http4k-connect- * - Upgrade dependencies, including Kotlin to 1.9.21 http4k-connect-amazon-dynamodb-fake - Add support for sparse indexes. H/T @obecker http4k-connect-openai [Fix] Optional fields in getModels call v5.5.1.0 \u00b6 http4k-connect- * - Upgrade dependencies http4k-connect-gitlab - [New module] Basic adapter module v5.5.0.1 \u00b6 http4k-connect-amazon-eventbridge - Support newline characters inside JSON v5.5.0.0 \u00b6 http4k-connect- * - Upgrade dependencies http4k-connect-amazon-iamidentitycenter - [Breaking] Browser infra moved to core. Simple reimport to fix. v5.4.0.0 \u00b6 http4k-connect- * - Upgrade dependencies, including Kotlin to 1.9.20. v5.3.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect- * - [Breaking - dev] http4k-connect is now built with Java 21. http4k-connect-amazon-iamidentitycenter - [New module] Adapter and fake implementation, plus interactive SSO login via a browser. v5.2.5.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect- * - Generated extension functions create defaults for collections types when they are defaulted in the core Action. v5.2.4.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect- * - Prevent extra dependencies being published in maven artefacts. v5.2.3.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-dynamodb-fake Support for TransactWriteItems v5.2.2.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-dynamodb Present a more concise introduction to the DynamoDB table mapper. H/T @oharaandrew314 http4k-connect-amazon-cloudwatchlogs - [New module] Adapter and fake implementation. v5.2.0.0 \u00b6 http4k-connect- * - Upgrade dependencies including Kotlin to 1.9.10. http4k-connect-openai [Breaking change] Added support for Streaming version of ChatCPT completions to both library and fake implementation. http4k-connect-amazon-evidently [New module] Add support for this feature flagging service. H/T @oharaandrew314 v5.1.7.0 \u00b6 http4k-connect-amazon-dynamodb-fake Add support for the entire update expression syntax. H/T @oharaandrew314 v5.1.6.2 \u00b6 http4k-connect-amazon-eventbridge-fake * - [Fix] Add proper indexing to fake when sending events. v5.1.6.1 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-firehose * - [Fix] Serialize DeliveryStreamName correctly in Moshi. v5.1.6.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect- ** - Make generation of IDs more deterministic v5.1.5.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-cognito- ** - Add ConfirmForgottenPassword. H/T @dmcg v5.1.4.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-sqs - Add DeleteMessageBatch action. H/T @oharaandrew314 http4k-connect-amazon-containercredentials - Add container credentials chain @oharaandrew314 http4k-connect-amazon-cognito - Moshi config was incorrect for successful user password auth response H/T @time4tea v5.1.3.0 \u00b6 http4k-connect- * - Upgrade dependencies, including Kotlin to 1.9.0. http4k-connect-amazon-dynamodb - Add scanPage and queryPage operations to DynamoDb table mapper. Pagination can now be controlled by the caller. H/T @oharaandrew314 http4k-connect-amazon-dynamodb-fake - putItem now supports a ConditionExpression . http4k-connect-amazon-dynamodb-fake - [Fix] query and scan will now return the correct LastEvaluatedKey based on the current index. H/T @oharaandrew314 http4k-connect-amazon-dynamodb-fake - [Fix] Condition Expressions now support name substitutions in the attribute_exists and attribute_not_exists functions http4k-connect-amazon-containercredentials - [Fix] Handle ARN NOT_SUPPLIED when getting aws credentials and running on AWS AppRunner v5.1.2.0 \u00b6 http4k-connect-amazon-eventbridge - [New module] Adapter and fake implementation. v5.1.1.0 \u00b6 http4k-connect-amazon-firehose - [New module] Adapter and fake implementation. v5.1.0.0 \u00b6 http4k-connect- * - Upgrade dependencies, including Kotlin to 1.9.0. http4k-connect-amazon-kms-fake - Will now generate unique key pairs for each CMK. H/T @oharaandrew314 http4k-connect-amazon-kms-fake - [Fix] Getting the public key for an ECDSA CMK will now work as expected. H/T @oharaandrew314 v5.0.1.0 \u00b6 http4k-connect- * - Upgrade dependencies v5.0.0.0 \u00b6 http4k-connect * : Upgrade to http4k platform v5 version. http4k-connect * : [Breaking] Remove all previous deprecations from all modules for v4. To upgrade cleanly, first upgrade to v3.43.0.0 and then re-upgrade to v5.0.0.0 . This will ensure that you only have to deal with Deprecations between the major versions. http4k-connect-kapt-generator : [Breaking] This generator module has been removed due to the replacement of Kapt with KSP. To fix, migrate to use the KSP gradle plugin with the http4k-connect-ksp-generator module instead. There are no more changes required as it is a drop-in replacement. v3.43.1.0 \u00b6 http4k-connect- * - Upgrade dependencies http4k-connect- * - [Fix] Code generation for pagination was broken when using AutomarshalledPagedAction v3.43.0.0 \u00b6 http4k-connect- * - Upgrade dependencies, including Kotlin to 1.8.22 v3.42.1.0 \u00b6 http4k-connect-openai-fake - Support for NoAuth plugin installation. v3.42.0.0 \u00b6 http4k-connect-openai-plugin - [New module] OpenAI plugin development SDK. http4k-connect provides APIs to create plugins for all 3 plugin authorization types - User, Service and OAuth. http4k-connect-openai-fake - Plugins can now be installed into the FakeOpenAI server. All 3 plugin auth types are supported. v3.41.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-openai - Properly support OAuth plugin types v3.40.5.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.40.4.0 \u00b6 http4k-connect-openai - Small fixes. v3.40.3.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-openai - Add CreateEmbeddings call. v3.40.2.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-kms-fake * - [Fix] Encryption.decryption works with binary messages v3.40.1.2 \u00b6 http4k-connect-kakfa-rest * - Correct content type and trimming string for producing records to Kafka v3. v3.40.1.1 \u00b6 http4k-connect-kakfa-rest * - Add produceRecordsWithPartitions() for production and partitioning in V3 API. v3.40.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect- * - Support for multiple action types in a single module. http4k-connect- * - [Deprecation] Action types have been moved to super-package. Custom Actions will need to be updated. http4k-connect-kakfa-rest * - [Breaking] Rearrangement of action modules and start to support V3 endpoints. v3.39.2.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-dynamodb - Helper methods for creating sets and lists of value types. v3.39.1.0 \u00b6 http4k-connect-openai - Set a sensible limit on the number of max tokens in chat completions. http4k-connect-openai - [New module] Client and fake. v3.39.0.1 \u00b6 http4k-connect-kakfa-schemaregistry * - [Fix] Don't break on registering the same schema. v3.39.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-mattermost * - [New module] Initial support for a couple of actions. H/T @tkint http4k-connect-kakfa-schemaregistry * - [Breaking] Added some actions and tightened up types. Breaks are purely primitive -> ValueType. v3.38.1.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect- * - New release process. v3.38.0.1 \u00b6 http4k-connect- * - Add missing JsonSerializable annotation v3.38.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.37.1.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-dynamo-fake - Dynamodb query scan pagination. H/T @oharaandrew314 v3.37.0.1 \u00b6 - http4k-connect-amazon-dynamo * - Fixed copy() so that it does not stop on first item. \u00b6 v3.37.0.0 \u00b6 http4k-connect- * - Upgrade dependencies, including Kotlin to 1.8.20 http4k-connect-amazon-dynamo * - Added copy() operation. v3.36.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-kms-fake- * - Real fake keys are now used for signing and verifying bytes. v3.35.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.34.0.1 \u00b6 http4k-connect- * - Fixed pagination to stop when a failure is encountered. v3.34.0.0 \u00b6 http4k-connect-github - Better name for GitHub webhook events v3.33.4.0 \u00b6 http4k-connect-amazon-secretsmanager- * - Support for ARNs in FakeSecretsManager and in API. v3.33.3.0 \u00b6 http4k-connect-kakfa-schemaregistry * - Changes to register schema version API contract. v3.33.2.0 \u00b6 http4k-connect-kakfa-rest * - Avro records can have non-Avro keys. v3.33.1.0 \u00b6 http4k-connect-kakfa-schemaregistry * - Changes to register schema version API contract. v3.33.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-kakfa-schemaregistry * - [New module] Client and fake. v3.32.0.0 \u00b6 http4k-connect-kakfa-rest * - Add helpers for consuming and producing. v3.31.1.0 \u00b6 http4k-connect-kakfa-rest * - Adding message partitioning strategies. v3.31.0.0 \u00b6 http4k-connect-kakfa-rest * - [Break] Support for Avro message and Schema marshalling. Rework API for ease of use v3.30.0.0 \u00b6 http4k-connect-kakfa-rest * - [Rename Module] Fixes to binary message formats and auto-commit. Add Seeking for offsets. v3.29.1.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-kakfa-http-proxy * - [New module] For sending messages to Kafka without the need for the entire Kafka broker infrastructure. v3.29.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.28.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-sns-fake * [Breaking] Change SNSMessage to include subject and attributes v3.27.1.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-ksp-generator * - Generation of adapters is now done via KSP instead of KAPT. v3.27.0.2 \u00b6 http4k-connect-ksp-generator * - Support for Object action classes. v3.27.0.1 \u00b6 http4k-connect-amazon-containercredentials - [Fix] AWS_CONTAINER_AUTHORIZATION_TOKEN is optional. v3.27.0.0 \u00b6 http4k-connect- * - Upgrade dependencies, including Kotlin to 1.8.0 http4k-connect-ksp-generator * - [New module] A version of Action and Adapter code generator written using KSP. http4k-connect-amazon-instancemetadata - Add Amazon RegionProvider with environment, profile, and imds support. H/T @oharaandrew314 v3.26.4.0 \u00b6 http4k-connect- * - Upgrade dependencies http4k-connect-amazon-instancemetadata - [New module] Query metadata and credentials from the current Amazon EC2 environment. H/T @oharaandrew314 http4k-connect-amazon-ec2credentials - Deprecated. Use the http4k-connect-amazon-instancemetadata module v3.26.3.0 \u00b6 http4k-connect-cognito - We now generate action code using Kapt, as per the other adapters. http4k-connect-cognito-fake - Fixes to login page. v3.26.2.0 \u00b6 http4k-connect- * - Upgrade dependencies http4k-connect-amazon-dynamodb - Add support for DynamoDb ImportTable and related actions. H/T @alex859 v3.26.1.0 \u00b6 http4k-connect-amazon-dynamodb - Add tableMapper batchGet and batchDelete operations. H/T @oharaandrew314 http4k-connect-cognito-fake - Enforce matching of Client Secret as well as ClientId http4k-connect-cognito-fake - Make Fake support OIDC token endpoint parameters (client_credentials_basic) v3.26.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-cognito * - Implement OAuth server with JWT signing and Well Known endpoint. v3.25.5.0 \u00b6 http4k-connect-amazon-containercredentials - Support passing of full CC URL and auth token header. This makes us compatible with AWS Snapstart http4k-connect-storage-http - Replace Swagger UI implementation. http4k-connect- * - Upgrade dependencies. v3.25.4.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.25.3.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.25.2.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.25.1.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.25.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.24.0.0 \u00b6 http4k-connect-google-analytics * - [New module] Split Google Analytics clients to support UA and GA4. v3.23.2.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.23.1.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.23.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.22.2.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-dynamo * - Added some useful methods for mapping Attributes such as Attribute.map(BiDiMapping) and Attribute.list(BiDiMapping) v3.22.1.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.22.0.0 \u00b6 http4k-connect- * - Upgrade dependencies, including Kotlin to 1.7.20. v3.21.3.1 \u00b6 http4k-connect- * - Republish of 3.21.3.0. v3.21.3.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-core - Tweak to ProfileCredentialsProvider. H/T @oharaandrew314 v3.21.2.1 \u00b6 http4k-connect- * - Republish of 3.21.2.0. v3.21.2.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.21.1.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.21.0.0 \u00b6 http4k-connect-amazon-sns-fake * - [Unlikely Break] FakeSNS now works on a single region only - so published messages need to match the region which the Fake was created with. v3.20.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-sns-fake * - [Breaking] Enable setting of region - this now defaults to the test region ldn-north-1 , but you can override if you need to do so in your testing environment. v3.19.2.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.19.1.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.19.0.0 \u00b6 http4k-connect-amazon-ses - Allow both text and html body on emails. v3.18.1.3 \u00b6 http4k-connect-amazon-dynamodb-fake - Fix batchWriteItem with multiple requests per table. H/T @oharaandrew314 v3.18.1.2 \u00b6 http4k-connect-amazon-dynamodb-fake - Fix request/response for fake dynamodb batch operations. H/T @oharaandrew314 v3.18.1.1 \u00b6 http4k-connect-amazon-dynamodb-fake - PutItem now only replaces items with the correct Primary Key. H/T @oharaandrew314 v3.18.1.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect- * - Added convenience automarshalling for pagination. http4k-connect-amazon-dynamodb-fake - New actions supported: Query , Scan , Updateitem . H/T @oharaandrew314 for the contributions. v3.18.0.0 \u00b6 http4k-connect- * - Upgrade dependencies, including Kotlin to 1.7.0. v3.17.3.1 \u00b6 http4k-connect- * - Fix broken POMs which removed all runtime dependencies v3.17.3.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.17.2.0 \u00b6 http4k-connect- * - Upgrade dependencies, including Kotlin to 1.6.21. http4k-connect-amazon-dynamodb- - Add auto Lens extensions for object mapping: Moshi.autoDynamoLens<AnObject>() v3.17.1.0 \u00b6 http4k-connect- * - Upgrade dependencies, including Kotlin to 1.6.20. v3.17.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-containercredentials Added loading of credentials from Container Credentials service. http4k-connect-amazon-containercredentials-fake - [New module] Fake for the above. http4k-connect-amazon-sts- * - [Unlikely break] Repackaged Credentials to core. v3.16.6.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.16.5.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.16.4.0 \u00b6 http4k-connect-amazon-kms * - EncryptionAlgorithms in GetPublicKey is optional (but not according to the AWS docs... ) v3.16.3.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-sts - WebIdentityToken provider refreshes token from disc on re-auth. v3.16.2.0 \u00b6 http4k-connect- * - Upgrade dependencies. v3.16.1.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon- * - Add missing exception message in the case of remote failure. v3.16.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-storage-jdbc * - [Possible break] Due to upgrade of Exposed and H2SQL - API differences. Need to fix as required. http4k-connect-amazon.dynamodb - Support defaulted() for falling back to another column. v3.15.2.1 \u00b6 http4k-connect-amazon- * - AssumeRoleWithWebIdentity response has optional fields which are not documented. Grrrr. v3.15.2.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon- * - Fix #105 - WebIdentityProvider to STS does not set host name when refreshing token. v3.15.1.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon.dynamodb - [Fix] ConsumedCapacity is not a long v3.15.0.0 \u00b6 http4k-connect- * - [Breaking] Upgrade dependencies. The http4k upgrade must be done in lockstep with this version as there has been a breaking change in http4k. v3.14.0.0 \u00b6 http4k-connect- * - [Break] Upgrade of Forkhandles to v2.0.0.0 means some unfortunately exposed constructor methods have gone away. Simple to fix - deprecation warnings will take care of it. http4k-connect- * - Upgrade dependencies and Kotlin to 1.6.10. v3.13.1.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-storage-redis- * - Vary lifetime of items. v3.13.0.0 \u00b6 http4k-connect- * - Upgrade dependencies and Kotlin to 1.6.0. http4k-connect- * - [Break] Changes to Kotshi mean that JsonFactories are now interfaces instead of abstract classes. v3.12.2.0 \u00b6 http4k-connect- * - Upgrade dependencies and Gradle. v3.12.1.1 \u00b6 http4k-connect- * - Fix Base64 decoding of ByteArrays(roundtripping). v3.12.1.0 \u00b6 http4k-connect-amazon-dynamodb * - Add defaulted() to Attribute Lenses v3.12.0.0 \u00b6 http4k-connect-amazon-dynamodb * - [Breaking] Fix TransactionGetItems to not blow up if item missing. Item is now nullable in response. v3.11.2.0 \u00b6 http4k-connect- * - Upgrade dependencies v3.11.1.0 \u00b6 http4k-connect- * - Upgrade dependencies http4k-amazon-ses * - [New module] client and Fake for SES. @H/T ToastShaman v3.11.0.1 \u00b6 http4k-connect- * - Upgrade dependencies http4k-connect-github - [Break] Replace Secret with GitHubToken in rest of API. v3.10.0.1 \u00b6 http4k-connect-amazon-sqs-fake - [Fix] Calculated attribute MD5 was incorrect. v3.10.0.0 \u00b6 http4k-connect-amazon-sqs - [Breaking] Parsing of message attributes in ReceiveMessage is implemented. SQS docs are wrong... v3.9.0.0 \u00b6 http4k-connect- * - Upgrade dependencies http4k-connect-github - [Break] Replace Secret with GitHubToken in filters. v3.8.3.0 \u00b6 http4k-connect- * - Upgrade dependencies http4k-connect-amazon-sqs- * - Support ListQueues. v3.8.2.0 \u00b6 http4k-connect- * - Upgrade dependencies http4k-connect-github - Fixing up to make 404s possible in the GitHub action. v3.8.1.1 \u00b6 http4k-connect-amazon-sqs-fake - Make MD5 of SQS messages pad right to 32 chars. v3.8.1.0 \u00b6 http4k-connect- * - Upgrade dependencies, including Kotlin to 1.5.30. http4k-connect-amazon-sts * - Added convenience functions for Credential Providers. v3.8.0.0 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-sts * - Support STS (refreshing) Credential providers including by WebIdentityToken. v3.7.0.0 \u00b6 http4k-connect-amazon-sqs * - [Breaking] Change to use QueueUrl universally. This ia much more consistent and aligns with the behaviour of the standard AWS SDK. You will need to update your configurations to pass in the urls instead of the standard queue names/ARNs v3.6.4.0 \u00b6 http4k-connect-amazon-sqs * - Support GetQueueAttributes v3.6.3.2 \u00b6 http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-sqs * - Fix ReceiveMessage to correctly return requested number of messages. v3.6.3.1 \u00b6 http4k-connect-amazon-sqs * - Fix ReceiveMessage to correctly handle multiple messages. v3.6.3.0 \u00b6 http4k-connect- * - Upgrade dependencies, including http4k to 4.11.0.1. http4k-connect-amazon-sqs * - Support for WaitTimeSeconds when receiving messages. v3.6.2.0 \u00b6 http4k-connect-amazon-s3 * - Add HeadBucket and HeadKey http4k-connect- * - Upgrade dependencies, including http4k to 4.10.1.0. v3.6.1.0 \u00b6 http4k-connect- * - Upgrade dependencies, including http4k to 4.10.0.1. v3.6.0.0 \u00b6 http4k-connect-amazon-s3-fake * - Fix FakeS3 CopyKey command. H/T @ToastShaman http4k-connect- * - Upgrade dependencies, including http4k to 4.9.10.0. v3.5.1.0 \u00b6 http4k-connect- * - Upgrade dependencies, including http4k to 4.9.9.0. http4k-connect-github : Fix token usage and add authScheme parameter. v3.5.0.0 \u00b6 http4k-connect- * - Upgrade dependencies, including http4k to 4.9.8.0. http4k-connect-*-fake [Breaking] Replaced usage of ChaosFake with the ChaoticHttpHandler from http4k. Nothing massive, but you may need to update some imports as they have moved v3.4.2.0 \u00b6 http4k-connect- * - Upgrade dependencies, including http4k to 4.9.7.0. http4k-connect-amazon-s3-fake - Fix #56 - S3(Fake): preserve encoding in bucketGetKey - H/T @tkint v3.4.1.0 \u00b6 http4k-connect-google-analytics - [New module] Added support for GA events. v3.4.0.0 \u00b6 http4k-connect-amazon- * - Region is now not reliant on default AWS format. This helps with on-prem installations with non-standard region format. http4k-connect-google-analytics - [Breaking] Moved Tracking ID out of pageView and into adapter as is global. v3.3.3.0 \u00b6 http4k-connect- * - Upgrade dependencies, including http4k to 4.9.5.0. v3.3.2.0 \u00b6 http4k-connect- * - Upgrade dependencies, including http4k to 4.9.3.1. v3.3.1.0 \u00b6 http4k-connect- * - Upgrade dependencies, including http4k to 4.9.1.0. v3.3.0.0 \u00b6 http4k-connect- * - Upgrade dependencies, including http4k to 4.9.0.2. http4k-connect-amazon-lambda : Introduction of invokeStreamFunction() action to allow for calling functions without. v3.2.0.1 \u00b6 http4k-connect-amazon-s3 : Fix S3 not returning LastModified value correctly in ListObjectsV2 v3.2.0.0 \u00b6 http4k-connect- * - Upgrade dependencies http4k-connect-amazon-dynamodb : [Slight break] BatchGetItem and BatchWriteItem actions had incorrect key names for response classes. v3.1.1.0 \u00b6 http4k-connect-amazon-cognito - [New module] Base actions for user client and pool creation are implemented, no fake as yet. v3.1.0.1 \u00b6 http4k-connect-amazon-dynamodb : Removed non-nullable field on ConsumedCapacity. v3.1.0.0 \u00b6 http4k-connect-amazon-s3 * : Add support for path-based bucket operations (ie. buckets with . in the name) http4k-connect-amazon-s3 * : [Rename break] Renamed *Key actions to match S3 API (now *Object ) http4k-connect-amazon-s3 * : [Slight break] Add headers to PutObject . v3.0.3.0 \u00b6 http4k-connect- * : Add convenience functions for getting AWS environmental variables from an http4k Environment object. v3.0.2.0 \u00b6 http4k-connect- * : Upgrade http4k. v3.0.1.0 \u00b6 http4k-connect- * : Add Moshi serializers for enums, making them compatible with GraalVM v3.0.0.0 \u00b6 http4k-connect- * : Major repackage of all model classes. Model package has been normalised to org.http4k.connect.amazon.<system>.model . All non-top level message objects have been moved from the org.http4k.connect.amazon.<system>.action package into org.http4k.connect.amazon.<system>.model . This is probably very annoying, and apologies in advance - hence the major version uptick. We are not proud of ourselves, but it needed to be done for our future plans... Also imports of generated adapter methods may need to be altered as some of them were in teh wrong place. v2.23.0.0 \u00b6 http4k-connect-amazon-dynamodb : [Slight break] Repackaging work of item types to reuse them for Dynamo event marshalling. v2.22.1.0 \u00b6 http4k-connect-amazon-dynamodb : Support Dynamo Events in marshalling layer. v2.22.0.1 \u00b6 http4k-connect-amazon-dynamodb : Fix incorrectly specified data type for OffsetDateTime attributes. v2.22.0.0 \u00b6 http4k-connect-amazon-dynamodb : [Breaking] Change value() method on Attribute to be typed. This only affects you if you are using values4k value classes for column mappings. v2.21.1.1 \u00b6 http4k-connect-amazon-dynamodb : Fix long value stored as a string. v2.21.1.0 \u00b6 http4k-connect- * : Add default values to all nullable response message fields. This is better for when stubbing/mocking out the responses. v2.21.0.0 \u00b6 http4k-connect- * : [Breaking] Repackaged Pagination classes (not just Amazon anymore). http4k-connect- * : [Breaking] Added pagination of results to relevant actions using xyzPaginated() actions. Removed usage of Listing classes. This is a more convenient API to use and is consistent throughout all modules. v2.21.1.1 \u00b6 http4k-connect-amazon-dynamodb : Fix bug with Long data type. @H/T @ToastShaman for the tip off. v2.20.1.0 \u00b6 http4k-connect-amazon-dynamodb : Added pagination of results v2.20.0.0 \u00b6 http4k-connect-amazon-dynamodb : More making API nicer and typesafe. v2.19.0.0 \u00b6 http4k-connect-amazon- * : [Breaking] Changed generated helper functions to not interfere with the names of the parameters. Simple rename will work here. http4k-connect- * : Friendlify JavaDocs. v2.18.1.0 \u00b6 http4k-connect-amazon-cloudfront : [New module] * http4k-connect-amazon-cloudfront-fake : [New module] v2.18.0.0 \u00b6 http4k-connect-amazon-dynamodb : Further tweaking of the Item and Key mapping typealiases to make API easier to use. v2.17.0.0 \u00b6 http4k-connect-amazon-dynamodb : Reworked DynamoDb API to be typesafe, tightened up types in responses, added Scan. v2.16.0.0 \u00b6 http4k-connect-amazon-dynamodb : [New module] New client module. No fake as yet. http4k-connect-amazon- * : [Break] Rename Base64Blob.encoded() -> Base64Blob.encode() for clarity. v2.15.4.0 \u00b6 http4k-connect-github : Add infra for main GitHub adapter. No custom actions implemented yet. v2.15.3.0 \u00b6 http4k-connect-github : [New module] Containing only basic callback infrastructure and Filters for checking requests. v2.15.2.0 \u00b6 http4k-connect- * : upgrade http4k. This should Fix #17 (Enable custom domain in S3). v2.15.1.0 \u00b6 http4k-connect- * : upgrade http4k, Kotlin. v2.15.0.1 \u00b6 Switch to Maven Central publishing as first options v2.15.0.0 \u00b6 http4k-connect-google-analytics : [Break] Harmonised interface with other adapters. TrackingId now moved to individual requests v2.14.2.0 \u00b6 http4k-connect- * : upgrade http4k, kotlin, others v2.14.1.0 \u00b6 http4k-connect- * : upgrade http4k http4k-connect-kapt-generator : Un-hardcode result type as per Action interface. v2.14.0.0 \u00b6 http4k-connect- * : [Breaking] Changed Result type on Action to be generic to support other programming models. This will only affect users who are implementing their own adapters. To fix, change: interface MyAdapter < R > : Action < R > // to interface MyAdapter < R > : Action < Result < R , RemoteFailure >> v2.13.0.1 \u00b6 * http4k-connect-amazon-s3-fake : Send response XML as well as status code on errors. v2.13.0.0 \u00b6 http4k-connect- * : Rejig of dependencies to be consistent. v2.12.0.0 \u00b6 http4k-connect-storage-core : New module, containing storage abstractions which can be used without the fakes. v2.11.0.0 \u00b6 http4k-connect-amazon-sns : [New module] * http4k-connect-amazon-sns-fake : [New module] http4k-connect- : Make all action classes Data classes so they are test friendly http4k-connect-amazon-sqs : [Breaking] Tags is now a List<Tag> instead of a Map<String, String> . v2.10.0.0 \u00b6 http4k-connect-amazon- : Add convenience functions to create clients from the system environment. http4k-connect-amazon- : Removed unused Payload type for various clients. http4k-connect- * : Upgrade values4k and http4k v2.9.2.0 \u00b6 http4k-connect-amazon- : Add convenience methods for constructing AWS clients v2.9.1.0 \u00b6 http4k-connect-amazon- : Expose Moshi to client API users for JSON-based systems v2.9.0.0 \u00b6 http4k-connect-amazon-sqs : Fixed SQS MessageAttributes as API is not as advertised... http4k-connect-amazon-fake : Extracting out endpoints for easier extension. v2.8.0.0 \u00b6 http4k-connect- * : Upgrade to http4k 4.X.X.X. v2.7.1.0 \u00b6 http4k-connect-amazon-systemsmanager : Refined model. http4k-connect-amazon- * : Fixed handling of ARNs. v2.7.0.0 \u00b6 http4k-connect-amazon- * : Refined ARN model. http4k-connect-amazon-s3 : Fix Delete Bucket action. v2.6.0.0 \u00b6 http4k-connect-amazon- * : API improvements for all AWS services. http4k-connect- * : defaultPort() -> defaultPort v2.5.1.0 \u00b6 * http4k-connect-amazon-lambda : Expose AutoMarshalling in extension function. v2.5.0.0 \u00b6 * http4k-connect-amazon-lambda : Expose AutoMarshalling for invoking functions. v2.4.0.0 \u00b6 http4k-connect- : Remove need for AWSCredentialScope - just use Region instead since each service already knows the scope required. v2.3.2.0 \u00b6 * http4k-connect-amazon-sqs : [New module] Client and fake. * http4k-connect-amazon-sqs-fake : [New module] See README for limitations of FakeSQS. * http4k-connect-amazon-sts : Added STSCredentialsProvider to refresh credentials when required. v2.3.1.1 \u00b6 http4k-connect- : Fix #11 thread safety of DocumentBuilderFactory. v2.3.1.0 \u00b6 * http4k-connect-amazon-lambda : [New module] Support for invoking AWS Lambda functions. * http4k-connect-amazon-lambda-fake : [New module] Includes FakeLambda runtime to run/deploy named HttpHandlers into. v2.3.0.0 \u00b6 http4k-connect- : Use Kotshi generated adapters instead of Kotlin Reflection, allowing removal of large Kotlin Reflection JAR. Note that the Kotlin-reflect dependency must be explicitly excluded due to transitivity in your projects. v2.2.2.0 \u00b6 http4k-connect- : Generate and ship extension functions for all actions. Rename S3.Bucket to S3Bucket . v2.2.1.0 \u00b6 http4k-connect- : Ship Javadoc. v2.2.0.0 \u00b6 http4k-connect- : Repackage all action classes. v2.1.0.0 \u00b6 http4k-connect- : Repackage all action classes. v2.0.2.1 \u00b6 http4k-connect- : Switch all interfaces to use new invoke() mechanism. v1.1.0.1 \u00b6 http4k-connect- : Upgrade http4k and Values4k. v1.0.1.0 \u00b6 http4k-connect-amazon-kms-fake : Simplify signing. v1.0.0.0 \u00b6 http4k-connect-amazon-kms : [New module] New client module. http4k-connect-amazon-kms-fake : [New module] New client fake module. http4k-connect-amazon-s3 : [New module] New client module. http4k-connect-amazon-s3-fake : [New module] New client fake module. http4k-connect-amazon-secretsmanager : [New module] New client module. http4k-connect-amazon-secretsmanager-fake : [New module] New client fake module. http4k-connect-amazon-systemsmanager : [New module] New client module. http4k-connect-amazon-systemsmanager-fake : [New module] New client fake module. http4k-connect-google-analytics : [New module] New client module. http4k-connect-storage-http : [New module] New storage module. http4k-connect-storage-jdbc : [New module] New storage module. http4k-connect-storage-redis : [New module] New storage module. http4k-connect-storage-s3 : [New module] New storage module. v0.20.0.0 \u00b6 Initial release.","title":"Changelog"},{"location":"changelog/#changelog","text":"This list is not intended to be all-encompassing - it will document major and breaking API changes with their rationale when appropriate. Given version A.B.C.D , breaking changes are to be expected in version number increments where changes in the A or B sections:","title":"Changelog"},{"location":"changelog/#v52100_uncut","text":"http4k-connect- * - Upgrade dependencies including Kotlin to 2.0.10 http4k-connect-ai-openai- ** - [Breaking] Model ResponseFormat as a sealed class hierarchy. Removed ResponseFormatType as now inherent in the JSON marshalling. Alpha support for json_schema response format, but it's just a map right now with no class structure.","title":"v5.21.0.0 (uncut)"},{"location":"changelog/#v52000","text":"http4k-connect- * - Upgrade dependencies, including Kotshi to 3.0.0. Version bump to highlight that this could be a breaking change if you are using the Kotshi annotation processor. http4k-connect-amazon-s3= * - Add CommonPrefixes field to S3 ListObjectsV2 response. H/T @kwydler","title":"v5.20.0.0"},{"location":"changelog/#v51902","text":"http4k-connect- * - [Fix] Add missing @JsonSerializable annotation to ReceiveMessage action","title":"v5.19.0.2"},{"location":"changelog/#v51901","text":"http4k-connect- * - [Fix] Add missing Kotshi adapter to Core Moshi adapter factory.","title":"v5.19.0.1"},{"location":"changelog/#v51900","text":"http4k-connect- * - Upgrade dependencies. http4k-connect- * - [Breaking] http4k has introduced a breaking change in 5.26.0.0. If you are using the typesafe configuration environment, you will need to update your code to use the repackaged Environment classes - these are now in org.http4k.config instead of org.http4k.cloudnative.env . Just updating your imports should be sufficient to fix this.","title":"v5.19.0.0"},{"location":"changelog/#v51800","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-cognito * - [Breaking] AWS Cognito: Add support for server side authentication ( AdminInitiateAuth and AdminRespondToAuthChallenge). H/T @markth0mas http4k-connect-ai- ** - [Breaking] Repackaged ModelName to common location. Just update imports! http4k-connect-ai-langchain - [Breaking] Added support for LmStudio chat and embedding models. Break is renamed: ChatModelOptions to OpenAiChatModelOptions . http4k-connect-ai-lmstudio * - [New module!] LmStudio adapter module and fake so you can connect to a locally running LLM server running any model.","title":"v5.18.0.0"},{"location":"changelog/#v51711","text":"http4k-connect-amazon-sqs- * - [Fix] Type of SQS ReceiveMessage waitTimeSeconds parameter was incorrect. H/T @oharaandrew314","title":"v5.17.1.1"},{"location":"changelog/#v51710","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-s3- * - Support all storage classes, including the restore lifecycle for glacier. H/T @oharaandrew314 http4k-connect-amazon-s3- * - Support S3 object tagging. H/T @oharaandrew314","title":"v5.17.1.0"},{"location":"changelog/#v51702","text":"http4k-connect-ai-openai - Choices are not optional in conversation completion. http4k-connect-ai-langchain - Fix streaming for OpenAiChatLanguageModel.","title":"v5.17.0.2"},{"location":"changelog/#v51701","text":"http4k-connect-ai-langchain - Added support for System messages in Ollama models","title":"v5.17.0.1"},{"location":"changelog/#v51700","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-ai- * - Migration of the various AI packages (OpenAI/Langchain) to http4k-ai- subpackage name. http4k-connect-ai-openai - [Breaking] Use FloatArray for embeddings instead of List<Float> http4k-connect-ai-ollama * - [New module!] Ollama adapter module so you can use Http4k-connect adapters in LangChain apps. http4k-connect-ai-langchain - Added support for Ollama models","title":"v5.17.0.0"},{"location":"changelog/#v51602","text":"http4k-connect-ai-langchain - Properly support all message types in OpenAI Adapter.","title":"v5.16.0.2"},{"location":"changelog/#v51601","text":"http4k-connect-langchain - Tools requests cannot be empty for chat completions in OpenAI Adapter.","title":"v5.16.0.1"},{"location":"changelog/#v51600","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-langchain - [New module!] LangChain adapter module so you can use Http4k-connect adapters in LangChain apps. Currently only OpenAI is supported. http4k-connect-openai- * - [Breaking] Support tool calls and more modern API version for ChatCompletion.","title":"v5.16.0.0"},{"location":"changelog/#v51500","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-sqs- - [Possible break] Implement JSON version of SQS in both fake and adapter. Ensure you are using an up-to-date version of the AWS SDK (which will support the JSON message format). Massive H/T @oharaandrew314","title":"v5.15.0.0"},{"location":"changelog/#v51400","text":"http4k-connect- * - Upgrade dependencies, including Kotlin to V2!","title":"v5.14.0.0"},{"location":"changelog/#v51300","text":"http4k-connect- * - Upgrade dependencies, including Kotlin to 1.9.24 http4k-connect-amazon-dynamodb * - Add StreamsEventResponse model. H/T @charlee-dev http4k-connect-evidently * - [Fix #405] Properly parse evidently project and features names from ARN. H/T @oharaandrew314","title":"v5.13.0.0"},{"location":"changelog/#v51220","text":"http4k-connect- * - Upgrade dependencies","title":"v5.12.2.0"},{"location":"changelog/#v51210","text":"http4k-connect- * - Upgrade dependencies","title":"v5.12.1.0"},{"location":"changelog/#v51200","text":"http4k-connect- * - Upgrade dependencies, and api changes to support new http4k version.","title":"v5.12.0.0"},{"location":"changelog/#v51100","text":"http4k-connect- * - Upgrade dependencies http4k-connect- * - [Breaking] Reordering of the parameters in adapter constructors to put overrideEndpoint at the end of the list, since it is the least commonly used. To fix, just reorder your parameters.","title":"v5.11.0.0"},{"location":"changelog/#v51010","text":"http4k-connect- * - Upgrade dependencies http4k-connect-amazon-dynamodb * - Align secondary index constructors in DynamoDbTableMapperSchema. H/T @obecker http4k-connect-amazon-dynamodb-fake - Validate reserved words in DynamoDB condition expressions. H/T @oharaandrew314","title":"v5.10.1.0"},{"location":"changelog/#v51000","text":"http4k-connect- * - Upgrade dependencies http4k-connect-amazon-dynamodb - [Breaking] DynamoDbIndexMapper now supports custom projections. Closes #391. H/T @oharaandrew314","title":"v5.10.0.0"},{"location":"changelog/#v5900","text":"http4k-connect-amazon-dynamodb - [Breaking] keyCondition in query DSL no longer accepts arbitrary attributes. Fixes #380. H/T @obecker","title":"v5.9.0.0"},{"location":"changelog/#v5800","text":"http4k-connect- * - Upgrade dependencies, including Kotlin to 1.9.23 http4k-connect-amazon-dynamodb - [Breaking] ExclusiveStartKey in DynamoDbIndexMapper functions is now an unconstrained Key . Fixes #372. H/T @oharaandrew314","title":"v5.8.0.0"},{"location":"changelog/#v5700","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-dynamodb - Query builder for DynamoDB. H/T @obecker http4k-connect-amazon-dynamodb - [Breaking] Query and Scan Select field is enum instead of String. To fix, just replace the hardcoded string with the enum! H/T @obecker http4k-connect-amazon-kms - Support for KeySpec property. H/T @oharaandrew314","title":"v5.7.0.0"},{"location":"changelog/#v56150","text":"http4k-connect-storage- * StoragePropertyBag allows storage-backed dynamic backing Read/WriteProperties. Extend StoragePropertyBag and declare typed properties with item<TYPE>() . Properties are stored into the backing storage using standard automarshalling.","title":"v5.6.15.0"},{"location":"changelog/#v56140","text":"http4k-connect- * - Upgrade dependencies. http4k-connect- * - Add optional endpoint parameter to all AWS service HTTP implementations. H/T @obecker","title":"v5.6.14.0"},{"location":"changelog/#v56130","text":"http4k-connect- * - Upgrade dependencies.","title":"v5.6.13.0"},{"location":"changelog/#v56120","text":"http4k-connect- * - Upgrade dependencies.","title":"v5.6.12.0"},{"location":"changelog/#v56110","text":"http4k-connect-amazon-core - SSO credentials provider now caches credentials until they expire. Stops re-login","title":"v5.6.11.0"},{"location":"changelog/#v56100","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-core - Simpler API for retrieving the AWS credentials of a custom profile. H/T @obecker http4k-connect-amazon-s3 * - Add parameter to force path-style requests to S3 buckets. H/T @obecker","title":"v5.6.10.0"},{"location":"changelog/#v5690","text":"http4k-connect-amazon-apprunner * - [New module] Client and fake","title":"v5.6.9.0"},{"location":"changelog/#v5682","text":"http4k-connect-amazon-containercredentials * - Add Kotshi adapter to Moshi instance.","title":"v5.6.8.2"},{"location":"changelog/#v5681","text":"http4k-connect- * - Fix AutoMarshalledPageAction not recognising arrays with whitespace.","title":"v5.6.8.1"},{"location":"changelog/#v5680","text":"http4k-connect- * - Upgrade dependencies.","title":"v5.6.8.0"},{"location":"changelog/#v5670","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-eventbridge * Events can be sent with the ARN and not just with the EventBusName","title":"v5.6.7.0"},{"location":"changelog/#v5660","text":"http4k-connect-amazon-dynamodb-client * - [Fix] #344 Handle failures in DynamoDbTableMapper.delete() H/T @obecker http4k-connect-amazon-evidently * Add updateFeature to Evidently. H/T @oharaandrew314","title":"v5.6.6.0"},{"location":"changelog/#v5650","text":"http4k-connect- * - Upgrade dependencies. http4k-connect- * - Fix AutomarshalledPagedAction so that it deals with pages of results which do not get returned inside a list but in an object wrapping a list.","title":"v5.6.5.0"},{"location":"changelog/#v5640","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon- ** - Added Amazon Presigner for creating pre-signed requests. H/T @oharaandrew314 http4k-connect-amazon-dynamodb-fake * - [Fix] #327 Query algorithm is slight wrong in fake dynamo. H/T @oharaandrew314","title":"v5.6.4.0"},{"location":"changelog/#v5630","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-systemsmanager-fake * - [Fix] #339 - Fake Systems Manager does not overwrite parameters - returns 400","title":"v5.6.3.0"},{"location":"changelog/#v5620","text":"http4k-connect- * - Upgrade dependencies.","title":"v5.6.2.0"},{"location":"changelog/#v5610","text":"http4k-connect- * - Upgrade dependencies.","title":"v5.6.1.0"},{"location":"changelog/#v5600","text":"http4k-connect- * - Upgrade dependencies, including Kotlin to 1.9.21 http4k-connect-amazon-dynamodb-fake - Add support for sparse indexes. H/T @obecker http4k-connect-openai [Fix] Optional fields in getModels call","title":"v5.6.0.0"},{"location":"changelog/#v5510","text":"http4k-connect- * - Upgrade dependencies http4k-connect-gitlab - [New module] Basic adapter module","title":"v5.5.1.0"},{"location":"changelog/#v5501","text":"http4k-connect-amazon-eventbridge - Support newline characters inside JSON","title":"v5.5.0.1"},{"location":"changelog/#v5500","text":"http4k-connect- * - Upgrade dependencies http4k-connect-amazon-iamidentitycenter - [Breaking] Browser infra moved to core. Simple reimport to fix.","title":"v5.5.0.0"},{"location":"changelog/#v5400","text":"http4k-connect- * - Upgrade dependencies, including Kotlin to 1.9.20.","title":"v5.4.0.0"},{"location":"changelog/#v5300","text":"http4k-connect- * - Upgrade dependencies. http4k-connect- * - [Breaking - dev] http4k-connect is now built with Java 21. http4k-connect-amazon-iamidentitycenter - [New module] Adapter and fake implementation, plus interactive SSO login via a browser.","title":"v5.3.0.0"},{"location":"changelog/#v5250","text":"http4k-connect- * - Upgrade dependencies. http4k-connect- * - Generated extension functions create defaults for collections types when they are defaulted in the core Action.","title":"v5.2.5.0"},{"location":"changelog/#v5240","text":"http4k-connect- * - Upgrade dependencies. http4k-connect- * - Prevent extra dependencies being published in maven artefacts.","title":"v5.2.4.0"},{"location":"changelog/#v5230","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-dynamodb-fake Support for TransactWriteItems","title":"v5.2.3.0"},{"location":"changelog/#v5220","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-dynamodb Present a more concise introduction to the DynamoDB table mapper. H/T @oharaandrew314 http4k-connect-amazon-cloudwatchlogs - [New module] Adapter and fake implementation.","title":"v5.2.2.0"},{"location":"changelog/#v5200","text":"http4k-connect- * - Upgrade dependencies including Kotlin to 1.9.10. http4k-connect-openai [Breaking change] Added support for Streaming version of ChatCPT completions to both library and fake implementation. http4k-connect-amazon-evidently [New module] Add support for this feature flagging service. H/T @oharaandrew314","title":"v5.2.0.0"},{"location":"changelog/#v5170","text":"http4k-connect-amazon-dynamodb-fake Add support for the entire update expression syntax. H/T @oharaandrew314","title":"v5.1.7.0"},{"location":"changelog/#v5162","text":"http4k-connect-amazon-eventbridge-fake * - [Fix] Add proper indexing to fake when sending events.","title":"v5.1.6.2"},{"location":"changelog/#v5161","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-firehose * - [Fix] Serialize DeliveryStreamName correctly in Moshi.","title":"v5.1.6.1"},{"location":"changelog/#v5160","text":"http4k-connect- * - Upgrade dependencies. http4k-connect- ** - Make generation of IDs more deterministic","title":"v5.1.6.0"},{"location":"changelog/#v5150","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-cognito- ** - Add ConfirmForgottenPassword. H/T @dmcg","title":"v5.1.5.0"},{"location":"changelog/#v5140","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-sqs - Add DeleteMessageBatch action. H/T @oharaandrew314 http4k-connect-amazon-containercredentials - Add container credentials chain @oharaandrew314 http4k-connect-amazon-cognito - Moshi config was incorrect for successful user password auth response H/T @time4tea","title":"v5.1.4.0"},{"location":"changelog/#v5130","text":"http4k-connect- * - Upgrade dependencies, including Kotlin to 1.9.0. http4k-connect-amazon-dynamodb - Add scanPage and queryPage operations to DynamoDb table mapper. Pagination can now be controlled by the caller. H/T @oharaandrew314 http4k-connect-amazon-dynamodb-fake - putItem now supports a ConditionExpression . http4k-connect-amazon-dynamodb-fake - [Fix] query and scan will now return the correct LastEvaluatedKey based on the current index. H/T @oharaandrew314 http4k-connect-amazon-dynamodb-fake - [Fix] Condition Expressions now support name substitutions in the attribute_exists and attribute_not_exists functions http4k-connect-amazon-containercredentials - [Fix] Handle ARN NOT_SUPPLIED when getting aws credentials and running on AWS AppRunner","title":"v5.1.3.0"},{"location":"changelog/#v5120","text":"http4k-connect-amazon-eventbridge - [New module] Adapter and fake implementation.","title":"v5.1.2.0"},{"location":"changelog/#v5110","text":"http4k-connect-amazon-firehose - [New module] Adapter and fake implementation.","title":"v5.1.1.0"},{"location":"changelog/#v5100","text":"http4k-connect- * - Upgrade dependencies, including Kotlin to 1.9.0. http4k-connect-amazon-kms-fake - Will now generate unique key pairs for each CMK. H/T @oharaandrew314 http4k-connect-amazon-kms-fake - [Fix] Getting the public key for an ECDSA CMK will now work as expected. H/T @oharaandrew314","title":"v5.1.0.0"},{"location":"changelog/#v5010","text":"http4k-connect- * - Upgrade dependencies","title":"v5.0.1.0"},{"location":"changelog/#v5000","text":"http4k-connect * : Upgrade to http4k platform v5 version. http4k-connect * : [Breaking] Remove all previous deprecations from all modules for v4. To upgrade cleanly, first upgrade to v3.43.0.0 and then re-upgrade to v5.0.0.0 . This will ensure that you only have to deal with Deprecations between the major versions. http4k-connect-kapt-generator : [Breaking] This generator module has been removed due to the replacement of Kapt with KSP. To fix, migrate to use the KSP gradle plugin with the http4k-connect-ksp-generator module instead. There are no more changes required as it is a drop-in replacement.","title":"v5.0.0.0"},{"location":"changelog/#v34310","text":"http4k-connect- * - Upgrade dependencies http4k-connect- * - [Fix] Code generation for pagination was broken when using AutomarshalledPagedAction","title":"v3.43.1.0"},{"location":"changelog/#v34300","text":"http4k-connect- * - Upgrade dependencies, including Kotlin to 1.8.22","title":"v3.43.0.0"},{"location":"changelog/#v34210","text":"http4k-connect-openai-fake - Support for NoAuth plugin installation.","title":"v3.42.1.0"},{"location":"changelog/#v34200","text":"http4k-connect-openai-plugin - [New module] OpenAI plugin development SDK. http4k-connect provides APIs to create plugins for all 3 plugin authorization types - User, Service and OAuth. http4k-connect-openai-fake - Plugins can now be installed into the FakeOpenAI server. All 3 plugin auth types are supported.","title":"v3.42.0.0"},{"location":"changelog/#v34100","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-openai - Properly support OAuth plugin types","title":"v3.41.0.0"},{"location":"changelog/#v34050","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.40.5.0"},{"location":"changelog/#v34040","text":"http4k-connect-openai - Small fixes.","title":"v3.40.4.0"},{"location":"changelog/#v34030","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-openai - Add CreateEmbeddings call.","title":"v3.40.3.0"},{"location":"changelog/#v34020","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-kms-fake * - [Fix] Encryption.decryption works with binary messages","title":"v3.40.2.0"},{"location":"changelog/#v34012","text":"http4k-connect-kakfa-rest * - Correct content type and trimming string for producing records to Kafka v3.","title":"v3.40.1.2"},{"location":"changelog/#v34011","text":"http4k-connect-kakfa-rest * - Add produceRecordsWithPartitions() for production and partitioning in V3 API.","title":"v3.40.1.1"},{"location":"changelog/#v34000","text":"http4k-connect- * - Upgrade dependencies. http4k-connect- * - Support for multiple action types in a single module. http4k-connect- * - [Deprecation] Action types have been moved to super-package. Custom Actions will need to be updated. http4k-connect-kakfa-rest * - [Breaking] Rearrangement of action modules and start to support V3 endpoints.","title":"v3.40.0.0"},{"location":"changelog/#v33920","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-dynamodb - Helper methods for creating sets and lists of value types.","title":"v3.39.2.0"},{"location":"changelog/#v33910","text":"http4k-connect-openai - Set a sensible limit on the number of max tokens in chat completions. http4k-connect-openai - [New module] Client and fake.","title":"v3.39.1.0"},{"location":"changelog/#v33901","text":"http4k-connect-kakfa-schemaregistry * - [Fix] Don't break on registering the same schema.","title":"v3.39.0.1"},{"location":"changelog/#v33900","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-mattermost * - [New module] Initial support for a couple of actions. H/T @tkint http4k-connect-kakfa-schemaregistry * - [Breaking] Added some actions and tightened up types. Breaks are purely primitive -> ValueType.","title":"v3.39.0.0"},{"location":"changelog/#v33810","text":"http4k-connect- * - Upgrade dependencies. http4k-connect- * - New release process.","title":"v3.38.1.0"},{"location":"changelog/#v33801","text":"http4k-connect- * - Add missing JsonSerializable annotation","title":"v3.38.0.1"},{"location":"changelog/#v33800","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.38.0.0"},{"location":"changelog/#v33710","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-dynamo-fake - Dynamodb query scan pagination. H/T @oharaandrew314","title":"v3.37.1.0"},{"location":"changelog/#v33701","text":"","title":"v3.37.0.1"},{"location":"changelog/#-_http4k-connect-amazon-dynamo_-_fixed_copy_so_that_it_does_not_stop_on_first_item","text":"","title":"- http4k-connect-amazon-dynamo* - Fixed copy() so that it does not stop on first item."},{"location":"changelog/#v33700","text":"http4k-connect- * - Upgrade dependencies, including Kotlin to 1.8.20 http4k-connect-amazon-dynamo * - Added copy() operation.","title":"v3.37.0.0"},{"location":"changelog/#v33600","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-kms-fake- * - Real fake keys are now used for signing and verifying bytes.","title":"v3.36.0.0"},{"location":"changelog/#v33500","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.35.0.0"},{"location":"changelog/#v33401","text":"http4k-connect- * - Fixed pagination to stop when a failure is encountered.","title":"v3.34.0.1"},{"location":"changelog/#v33400","text":"http4k-connect-github - Better name for GitHub webhook events","title":"v3.34.0.0"},{"location":"changelog/#v33340","text":"http4k-connect-amazon-secretsmanager- * - Support for ARNs in FakeSecretsManager and in API.","title":"v3.33.4.0"},{"location":"changelog/#v33330","text":"http4k-connect-kakfa-schemaregistry * - Changes to register schema version API contract.","title":"v3.33.3.0"},{"location":"changelog/#v33320","text":"http4k-connect-kakfa-rest * - Avro records can have non-Avro keys.","title":"v3.33.2.0"},{"location":"changelog/#v33310","text":"http4k-connect-kakfa-schemaregistry * - Changes to register schema version API contract.","title":"v3.33.1.0"},{"location":"changelog/#v33300","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-kakfa-schemaregistry * - [New module] Client and fake.","title":"v3.33.0.0"},{"location":"changelog/#v33200","text":"http4k-connect-kakfa-rest * - Add helpers for consuming and producing.","title":"v3.32.0.0"},{"location":"changelog/#v33110","text":"http4k-connect-kakfa-rest * - Adding message partitioning strategies.","title":"v3.31.1.0"},{"location":"changelog/#v33100","text":"http4k-connect-kakfa-rest * - [Break] Support for Avro message and Schema marshalling. Rework API for ease of use","title":"v3.31.0.0"},{"location":"changelog/#v33000","text":"http4k-connect-kakfa-rest * - [Rename Module] Fixes to binary message formats and auto-commit. Add Seeking for offsets.","title":"v3.30.0.0"},{"location":"changelog/#v32910","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-kakfa-http-proxy * - [New module] For sending messages to Kafka without the need for the entire Kafka broker infrastructure.","title":"v3.29.1.0"},{"location":"changelog/#v32900","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.29.0.0"},{"location":"changelog/#v32800","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-sns-fake * [Breaking] Change SNSMessage to include subject and attributes","title":"v3.28.0.0"},{"location":"changelog/#v32710","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-ksp-generator * - Generation of adapters is now done via KSP instead of KAPT.","title":"v3.27.1.0"},{"location":"changelog/#v32702","text":"http4k-connect-ksp-generator * - Support for Object action classes.","title":"v3.27.0.2"},{"location":"changelog/#v32701","text":"http4k-connect-amazon-containercredentials - [Fix] AWS_CONTAINER_AUTHORIZATION_TOKEN is optional.","title":"v3.27.0.1"},{"location":"changelog/#v32700","text":"http4k-connect- * - Upgrade dependencies, including Kotlin to 1.8.0 http4k-connect-ksp-generator * - [New module] A version of Action and Adapter code generator written using KSP. http4k-connect-amazon-instancemetadata - Add Amazon RegionProvider with environment, profile, and imds support. H/T @oharaandrew314","title":"v3.27.0.0"},{"location":"changelog/#v32640","text":"http4k-connect- * - Upgrade dependencies http4k-connect-amazon-instancemetadata - [New module] Query metadata and credentials from the current Amazon EC2 environment. H/T @oharaandrew314 http4k-connect-amazon-ec2credentials - Deprecated. Use the http4k-connect-amazon-instancemetadata module","title":"v3.26.4.0"},{"location":"changelog/#v32630","text":"http4k-connect-cognito - We now generate action code using Kapt, as per the other adapters. http4k-connect-cognito-fake - Fixes to login page.","title":"v3.26.3.0"},{"location":"changelog/#v32620","text":"http4k-connect- * - Upgrade dependencies http4k-connect-amazon-dynamodb - Add support for DynamoDb ImportTable and related actions. H/T @alex859","title":"v3.26.2.0"},{"location":"changelog/#v32610","text":"http4k-connect-amazon-dynamodb - Add tableMapper batchGet and batchDelete operations. H/T @oharaandrew314 http4k-connect-cognito-fake - Enforce matching of Client Secret as well as ClientId http4k-connect-cognito-fake - Make Fake support OIDC token endpoint parameters (client_credentials_basic)","title":"v3.26.1.0"},{"location":"changelog/#v32600","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-cognito * - Implement OAuth server with JWT signing and Well Known endpoint.","title":"v3.26.0.0"},{"location":"changelog/#v32550","text":"http4k-connect-amazon-containercredentials - Support passing of full CC URL and auth token header. This makes us compatible with AWS Snapstart http4k-connect-storage-http - Replace Swagger UI implementation. http4k-connect- * - Upgrade dependencies.","title":"v3.25.5.0"},{"location":"changelog/#v32540","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.25.4.0"},{"location":"changelog/#v32530","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.25.3.0"},{"location":"changelog/#v32520","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.25.2.0"},{"location":"changelog/#v32510","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.25.1.0"},{"location":"changelog/#v32500","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.25.0.0"},{"location":"changelog/#v32400","text":"http4k-connect-google-analytics * - [New module] Split Google Analytics clients to support UA and GA4.","title":"v3.24.0.0"},{"location":"changelog/#v32320","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.23.2.0"},{"location":"changelog/#v32310","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.23.1.0"},{"location":"changelog/#v32300","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.23.0.0"},{"location":"changelog/#v32220","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-dynamo * - Added some useful methods for mapping Attributes such as Attribute.map(BiDiMapping) and Attribute.list(BiDiMapping)","title":"v3.22.2.0"},{"location":"changelog/#v32210","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.22.1.0"},{"location":"changelog/#v32200","text":"http4k-connect- * - Upgrade dependencies, including Kotlin to 1.7.20.","title":"v3.22.0.0"},{"location":"changelog/#v32131","text":"http4k-connect- * - Republish of 3.21.3.0.","title":"v3.21.3.1"},{"location":"changelog/#v32130","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-core - Tweak to ProfileCredentialsProvider. H/T @oharaandrew314","title":"v3.21.3.0"},{"location":"changelog/#v32121","text":"http4k-connect- * - Republish of 3.21.2.0.","title":"v3.21.2.1"},{"location":"changelog/#v32120","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.21.2.0"},{"location":"changelog/#v32110","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.21.1.0"},{"location":"changelog/#v32100","text":"http4k-connect-amazon-sns-fake * - [Unlikely Break] FakeSNS now works on a single region only - so published messages need to match the region which the Fake was created with.","title":"v3.21.0.0"},{"location":"changelog/#v32000","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-sns-fake * - [Breaking] Enable setting of region - this now defaults to the test region ldn-north-1 , but you can override if you need to do so in your testing environment.","title":"v3.20.0.0"},{"location":"changelog/#v31920","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.19.2.0"},{"location":"changelog/#v31910","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.19.1.0"},{"location":"changelog/#v31900","text":"http4k-connect-amazon-ses - Allow both text and html body on emails.","title":"v3.19.0.0"},{"location":"changelog/#v31813","text":"http4k-connect-amazon-dynamodb-fake - Fix batchWriteItem with multiple requests per table. H/T @oharaandrew314","title":"v3.18.1.3"},{"location":"changelog/#v31812","text":"http4k-connect-amazon-dynamodb-fake - Fix request/response for fake dynamodb batch operations. H/T @oharaandrew314","title":"v3.18.1.2"},{"location":"changelog/#v31811","text":"http4k-connect-amazon-dynamodb-fake - PutItem now only replaces items with the correct Primary Key. H/T @oharaandrew314","title":"v3.18.1.1"},{"location":"changelog/#v31810","text":"http4k-connect- * - Upgrade dependencies. http4k-connect- * - Added convenience automarshalling for pagination. http4k-connect-amazon-dynamodb-fake - New actions supported: Query , Scan , Updateitem . H/T @oharaandrew314 for the contributions.","title":"v3.18.1.0"},{"location":"changelog/#v31800","text":"http4k-connect- * - Upgrade dependencies, including Kotlin to 1.7.0.","title":"v3.18.0.0"},{"location":"changelog/#v31731","text":"http4k-connect- * - Fix broken POMs which removed all runtime dependencies","title":"v3.17.3.1"},{"location":"changelog/#v31730","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.17.3.0"},{"location":"changelog/#v31720","text":"http4k-connect- * - Upgrade dependencies, including Kotlin to 1.6.21. http4k-connect-amazon-dynamodb- - Add auto Lens extensions for object mapping: Moshi.autoDynamoLens<AnObject>()","title":"v3.17.2.0"},{"location":"changelog/#v31710","text":"http4k-connect- * - Upgrade dependencies, including Kotlin to 1.6.20.","title":"v3.17.1.0"},{"location":"changelog/#v31700","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-containercredentials Added loading of credentials from Container Credentials service. http4k-connect-amazon-containercredentials-fake - [New module] Fake for the above. http4k-connect-amazon-sts- * - [Unlikely break] Repackaged Credentials to core.","title":"v3.17.0.0"},{"location":"changelog/#v31660","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.16.6.0"},{"location":"changelog/#v31650","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.16.5.0"},{"location":"changelog/#v31640","text":"http4k-connect-amazon-kms * - EncryptionAlgorithms in GetPublicKey is optional (but not according to the AWS docs... )","title":"v3.16.4.0"},{"location":"changelog/#v31630","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-sts - WebIdentityToken provider refreshes token from disc on re-auth.","title":"v3.16.3.0"},{"location":"changelog/#v31620","text":"http4k-connect- * - Upgrade dependencies.","title":"v3.16.2.0"},{"location":"changelog/#v31610","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon- * - Add missing exception message in the case of remote failure.","title":"v3.16.1.0"},{"location":"changelog/#v31600","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-storage-jdbc * - [Possible break] Due to upgrade of Exposed and H2SQL - API differences. Need to fix as required. http4k-connect-amazon.dynamodb - Support defaulted() for falling back to another column.","title":"v3.16.0.0"},{"location":"changelog/#v31521","text":"http4k-connect-amazon- * - AssumeRoleWithWebIdentity response has optional fields which are not documented. Grrrr.","title":"v3.15.2.1"},{"location":"changelog/#v31520","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon- * - Fix #105 - WebIdentityProvider to STS does not set host name when refreshing token.","title":"v3.15.2.0"},{"location":"changelog/#v31510","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon.dynamodb - [Fix] ConsumedCapacity is not a long","title":"v3.15.1.0"},{"location":"changelog/#v31500","text":"http4k-connect- * - [Breaking] Upgrade dependencies. The http4k upgrade must be done in lockstep with this version as there has been a breaking change in http4k.","title":"v3.15.0.0"},{"location":"changelog/#v31400","text":"http4k-connect- * - [Break] Upgrade of Forkhandles to v2.0.0.0 means some unfortunately exposed constructor methods have gone away. Simple to fix - deprecation warnings will take care of it. http4k-connect- * - Upgrade dependencies and Kotlin to 1.6.10.","title":"v3.14.0.0"},{"location":"changelog/#v31310","text":"http4k-connect- * - Upgrade dependencies. http4k-storage-redis- * - Vary lifetime of items.","title":"v3.13.1.0"},{"location":"changelog/#v31300","text":"http4k-connect- * - Upgrade dependencies and Kotlin to 1.6.0. http4k-connect- * - [Break] Changes to Kotshi mean that JsonFactories are now interfaces instead of abstract classes.","title":"v3.13.0.0"},{"location":"changelog/#v31220","text":"http4k-connect- * - Upgrade dependencies and Gradle.","title":"v3.12.2.0"},{"location":"changelog/#v31211","text":"http4k-connect- * - Fix Base64 decoding of ByteArrays(roundtripping).","title":"v3.12.1.1"},{"location":"changelog/#v31210","text":"http4k-connect-amazon-dynamodb * - Add defaulted() to Attribute Lenses","title":"v3.12.1.0"},{"location":"changelog/#v31200","text":"http4k-connect-amazon-dynamodb * - [Breaking] Fix TransactionGetItems to not blow up if item missing. Item is now nullable in response.","title":"v3.12.0.0"},{"location":"changelog/#v31120","text":"http4k-connect- * - Upgrade dependencies","title":"v3.11.2.0"},{"location":"changelog/#v31110","text":"http4k-connect- * - Upgrade dependencies http4k-amazon-ses * - [New module] client and Fake for SES. @H/T ToastShaman","title":"v3.11.1.0"},{"location":"changelog/#v31101","text":"http4k-connect- * - Upgrade dependencies http4k-connect-github - [Break] Replace Secret with GitHubToken in rest of API.","title":"v3.11.0.1"},{"location":"changelog/#v31001","text":"http4k-connect-amazon-sqs-fake - [Fix] Calculated attribute MD5 was incorrect.","title":"v3.10.0.1"},{"location":"changelog/#v31000","text":"http4k-connect-amazon-sqs - [Breaking] Parsing of message attributes in ReceiveMessage is implemented. SQS docs are wrong...","title":"v3.10.0.0"},{"location":"changelog/#v3900","text":"http4k-connect- * - Upgrade dependencies http4k-connect-github - [Break] Replace Secret with GitHubToken in filters.","title":"v3.9.0.0"},{"location":"changelog/#v3830","text":"http4k-connect- * - Upgrade dependencies http4k-connect-amazon-sqs- * - Support ListQueues.","title":"v3.8.3.0"},{"location":"changelog/#v3820","text":"http4k-connect- * - Upgrade dependencies http4k-connect-github - Fixing up to make 404s possible in the GitHub action.","title":"v3.8.2.0"},{"location":"changelog/#v3811","text":"http4k-connect-amazon-sqs-fake - Make MD5 of SQS messages pad right to 32 chars.","title":"v3.8.1.1"},{"location":"changelog/#v3810","text":"http4k-connect- * - Upgrade dependencies, including Kotlin to 1.5.30. http4k-connect-amazon-sts * - Added convenience functions for Credential Providers.","title":"v3.8.1.0"},{"location":"changelog/#v3800","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-sts * - Support STS (refreshing) Credential providers including by WebIdentityToken.","title":"v3.8.0.0"},{"location":"changelog/#v3700","text":"http4k-connect-amazon-sqs * - [Breaking] Change to use QueueUrl universally. This ia much more consistent and aligns with the behaviour of the standard AWS SDK. You will need to update your configurations to pass in the urls instead of the standard queue names/ARNs","title":"v3.7.0.0"},{"location":"changelog/#v3640","text":"http4k-connect-amazon-sqs * - Support GetQueueAttributes","title":"v3.6.4.0"},{"location":"changelog/#v3632","text":"http4k-connect- * - Upgrade dependencies. http4k-connect-amazon-sqs * - Fix ReceiveMessage to correctly return requested number of messages.","title":"v3.6.3.2"},{"location":"changelog/#v3631","text":"http4k-connect-amazon-sqs * - Fix ReceiveMessage to correctly handle multiple messages.","title":"v3.6.3.1"},{"location":"changelog/#v3630","text":"http4k-connect- * - Upgrade dependencies, including http4k to 4.11.0.1. http4k-connect-amazon-sqs * - Support for WaitTimeSeconds when receiving messages.","title":"v3.6.3.0"},{"location":"changelog/#v3620","text":"http4k-connect-amazon-s3 * - Add HeadBucket and HeadKey http4k-connect- * - Upgrade dependencies, including http4k to 4.10.1.0.","title":"v3.6.2.0"},{"location":"changelog/#v3610","text":"http4k-connect- * - Upgrade dependencies, including http4k to 4.10.0.1.","title":"v3.6.1.0"},{"location":"changelog/#v3600","text":"http4k-connect-amazon-s3-fake * - Fix FakeS3 CopyKey command. H/T @ToastShaman http4k-connect- * - Upgrade dependencies, including http4k to 4.9.10.0.","title":"v3.6.0.0"},{"location":"changelog/#v3510","text":"http4k-connect- * - Upgrade dependencies, including http4k to 4.9.9.0. http4k-connect-github : Fix token usage and add authScheme parameter.","title":"v3.5.1.0"},{"location":"changelog/#v3500","text":"http4k-connect- * - Upgrade dependencies, including http4k to 4.9.8.0. http4k-connect-*-fake [Breaking] Replaced usage of ChaosFake with the ChaoticHttpHandler from http4k. Nothing massive, but you may need to update some imports as they have moved","title":"v3.5.0.0"},{"location":"changelog/#v3420","text":"http4k-connect- * - Upgrade dependencies, including http4k to 4.9.7.0. http4k-connect-amazon-s3-fake - Fix #56 - S3(Fake): preserve encoding in bucketGetKey - H/T @tkint","title":"v3.4.2.0"},{"location":"changelog/#v3410","text":"http4k-connect-google-analytics - [New module] Added support for GA events.","title":"v3.4.1.0"},{"location":"changelog/#v3400","text":"http4k-connect-amazon- * - Region is now not reliant on default AWS format. This helps with on-prem installations with non-standard region format. http4k-connect-google-analytics - [Breaking] Moved Tracking ID out of pageView and into adapter as is global.","title":"v3.4.0.0"},{"location":"changelog/#v3330","text":"http4k-connect- * - Upgrade dependencies, including http4k to 4.9.5.0.","title":"v3.3.3.0"},{"location":"changelog/#v3320","text":"http4k-connect- * - Upgrade dependencies, including http4k to 4.9.3.1.","title":"v3.3.2.0"},{"location":"changelog/#v3310","text":"http4k-connect- * - Upgrade dependencies, including http4k to 4.9.1.0.","title":"v3.3.1.0"},{"location":"changelog/#v3300","text":"http4k-connect- * - Upgrade dependencies, including http4k to 4.9.0.2. http4k-connect-amazon-lambda : Introduction of invokeStreamFunction() action to allow for calling functions without.","title":"v3.3.0.0"},{"location":"changelog/#v3201","text":"http4k-connect-amazon-s3 : Fix S3 not returning LastModified value correctly in ListObjectsV2","title":"v3.2.0.1"},{"location":"changelog/#v3200","text":"http4k-connect- * - Upgrade dependencies http4k-connect-amazon-dynamodb : [Slight break] BatchGetItem and BatchWriteItem actions had incorrect key names for response classes.","title":"v3.2.0.0"},{"location":"changelog/#v3110","text":"http4k-connect-amazon-cognito - [New module] Base actions for user client and pool creation are implemented, no fake as yet.","title":"v3.1.1.0"},{"location":"changelog/#v3101","text":"http4k-connect-amazon-dynamodb : Removed non-nullable field on ConsumedCapacity.","title":"v3.1.0.1"},{"location":"changelog/#v3100","text":"http4k-connect-amazon-s3 * : Add support for path-based bucket operations (ie. buckets with . in the name) http4k-connect-amazon-s3 * : [Rename break] Renamed *Key actions to match S3 API (now *Object ) http4k-connect-amazon-s3 * : [Slight break] Add headers to PutObject .","title":"v3.1.0.0"},{"location":"changelog/#v3030","text":"http4k-connect- * : Add convenience functions for getting AWS environmental variables from an http4k Environment object.","title":"v3.0.3.0"},{"location":"changelog/#v3020","text":"http4k-connect- * : Upgrade http4k.","title":"v3.0.2.0"},{"location":"changelog/#v3010","text":"http4k-connect- * : Add Moshi serializers for enums, making them compatible with GraalVM","title":"v3.0.1.0"},{"location":"changelog/#v3000","text":"http4k-connect- * : Major repackage of all model classes. Model package has been normalised to org.http4k.connect.amazon.<system>.model . All non-top level message objects have been moved from the org.http4k.connect.amazon.<system>.action package into org.http4k.connect.amazon.<system>.model . This is probably very annoying, and apologies in advance - hence the major version uptick. We are not proud of ourselves, but it needed to be done for our future plans... Also imports of generated adapter methods may need to be altered as some of them were in teh wrong place.","title":"v3.0.0.0"},{"location":"changelog/#v22300","text":"http4k-connect-amazon-dynamodb : [Slight break] Repackaging work of item types to reuse them for Dynamo event marshalling.","title":"v2.23.0.0"},{"location":"changelog/#v22210","text":"http4k-connect-amazon-dynamodb : Support Dynamo Events in marshalling layer.","title":"v2.22.1.0"},{"location":"changelog/#v22201","text":"http4k-connect-amazon-dynamodb : Fix incorrectly specified data type for OffsetDateTime attributes.","title":"v2.22.0.1"},{"location":"changelog/#v22200","text":"http4k-connect-amazon-dynamodb : [Breaking] Change value() method on Attribute to be typed. This only affects you if you are using values4k value classes for column mappings.","title":"v2.22.0.0"},{"location":"changelog/#v22111","text":"http4k-connect-amazon-dynamodb : Fix long value stored as a string.","title":"v2.21.1.1"},{"location":"changelog/#v22110","text":"http4k-connect- * : Add default values to all nullable response message fields. This is better for when stubbing/mocking out the responses.","title":"v2.21.1.0"},{"location":"changelog/#v22100","text":"http4k-connect- * : [Breaking] Repackaged Pagination classes (not just Amazon anymore). http4k-connect- * : [Breaking] Added pagination of results to relevant actions using xyzPaginated() actions. Removed usage of Listing classes. This is a more convenient API to use and is consistent throughout all modules.","title":"v2.21.0.0"},{"location":"changelog/#v22111_1","text":"http4k-connect-amazon-dynamodb : Fix bug with Long data type. @H/T @ToastShaman for the tip off.","title":"v2.21.1.1"},{"location":"changelog/#v22010","text":"http4k-connect-amazon-dynamodb : Added pagination of results","title":"v2.20.1.0"},{"location":"changelog/#v22000","text":"http4k-connect-amazon-dynamodb : More making API nicer and typesafe.","title":"v2.20.0.0"},{"location":"changelog/#v21900","text":"http4k-connect-amazon- * : [Breaking] Changed generated helper functions to not interfere with the names of the parameters. Simple rename will work here. http4k-connect- * : Friendlify JavaDocs.","title":"v2.19.0.0"},{"location":"changelog/#v21810","text":"http4k-connect-amazon-cloudfront : [New module] * http4k-connect-amazon-cloudfront-fake : [New module]","title":"v2.18.1.0"},{"location":"changelog/#v21800","text":"http4k-connect-amazon-dynamodb : Further tweaking of the Item and Key mapping typealiases to make API easier to use.","title":"v2.18.0.0"},{"location":"changelog/#v21700","text":"http4k-connect-amazon-dynamodb : Reworked DynamoDb API to be typesafe, tightened up types in responses, added Scan.","title":"v2.17.0.0"},{"location":"changelog/#v21600","text":"http4k-connect-amazon-dynamodb : [New module] New client module. No fake as yet. http4k-connect-amazon- * : [Break] Rename Base64Blob.encoded() -> Base64Blob.encode() for clarity.","title":"v2.16.0.0"},{"location":"changelog/#v21540","text":"http4k-connect-github : Add infra for main GitHub adapter. No custom actions implemented yet.","title":"v2.15.4.0"},{"location":"changelog/#v21530","text":"http4k-connect-github : [New module] Containing only basic callback infrastructure and Filters for checking requests.","title":"v2.15.3.0"},{"location":"changelog/#v21520","text":"http4k-connect- * : upgrade http4k. This should Fix #17 (Enable custom domain in S3).","title":"v2.15.2.0"},{"location":"changelog/#v21510","text":"http4k-connect- * : upgrade http4k, Kotlin.","title":"v2.15.1.0"},{"location":"changelog/#v21501","text":"Switch to Maven Central publishing as first options","title":"v2.15.0.1"},{"location":"changelog/#v21500","text":"http4k-connect-google-analytics : [Break] Harmonised interface with other adapters. TrackingId now moved to individual requests","title":"v2.15.0.0"},{"location":"changelog/#v21420","text":"http4k-connect- * : upgrade http4k, kotlin, others","title":"v2.14.2.0"},{"location":"changelog/#v21410","text":"http4k-connect- * : upgrade http4k http4k-connect-kapt-generator : Un-hardcode result type as per Action interface.","title":"v2.14.1.0"},{"location":"changelog/#v21400","text":"http4k-connect- * : [Breaking] Changed Result type on Action to be generic to support other programming models. This will only affect users who are implementing their own adapters. To fix, change: interface MyAdapter < R > : Action < R > // to interface MyAdapter < R > : Action < Result < R , RemoteFailure >>","title":"v2.14.0.0"},{"location":"changelog/#v21301","text":"* http4k-connect-amazon-s3-fake : Send response XML as well as status code on errors.","title":"v2.13.0.1"},{"location":"changelog/#v21300","text":"http4k-connect- * : Rejig of dependencies to be consistent.","title":"v2.13.0.0"},{"location":"changelog/#v21200","text":"http4k-connect-storage-core : New module, containing storage abstractions which can be used without the fakes.","title":"v2.12.0.0"},{"location":"changelog/#v21100","text":"http4k-connect-amazon-sns : [New module] * http4k-connect-amazon-sns-fake : [New module] http4k-connect- : Make all action classes Data classes so they are test friendly http4k-connect-amazon-sqs : [Breaking] Tags is now a List<Tag> instead of a Map<String, String> .","title":"v2.11.0.0"},{"location":"changelog/#v21000","text":"http4k-connect-amazon- : Add convenience functions to create clients from the system environment. http4k-connect-amazon- : Removed unused Payload type for various clients. http4k-connect- * : Upgrade values4k and http4k","title":"v2.10.0.0"},{"location":"changelog/#v2920","text":"http4k-connect-amazon- : Add convenience methods for constructing AWS clients","title":"v2.9.2.0"},{"location":"changelog/#v2910","text":"http4k-connect-amazon- : Expose Moshi to client API users for JSON-based systems","title":"v2.9.1.0"},{"location":"changelog/#v2900","text":"http4k-connect-amazon-sqs : Fixed SQS MessageAttributes as API is not as advertised... http4k-connect-amazon-fake : Extracting out endpoints for easier extension.","title":"v2.9.0.0"},{"location":"changelog/#v2800","text":"http4k-connect- * : Upgrade to http4k 4.X.X.X.","title":"v2.8.0.0"},{"location":"changelog/#v2710","text":"http4k-connect-amazon-systemsmanager : Refined model. http4k-connect-amazon- * : Fixed handling of ARNs.","title":"v2.7.1.0"},{"location":"changelog/#v2700","text":"http4k-connect-amazon- * : Refined ARN model. http4k-connect-amazon-s3 : Fix Delete Bucket action.","title":"v2.7.0.0"},{"location":"changelog/#v2600","text":"http4k-connect-amazon- * : API improvements for all AWS services. http4k-connect- * : defaultPort() -> defaultPort","title":"v2.6.0.0"},{"location":"changelog/#v2510","text":"* http4k-connect-amazon-lambda : Expose AutoMarshalling in extension function.","title":"v2.5.1.0"},{"location":"changelog/#v2500","text":"* http4k-connect-amazon-lambda : Expose AutoMarshalling for invoking functions.","title":"v2.5.0.0"},{"location":"changelog/#v2400","text":"http4k-connect- : Remove need for AWSCredentialScope - just use Region instead since each service already knows the scope required.","title":"v2.4.0.0"},{"location":"changelog/#v2320","text":"* http4k-connect-amazon-sqs : [New module] Client and fake. * http4k-connect-amazon-sqs-fake : [New module] See README for limitations of FakeSQS. * http4k-connect-amazon-sts : Added STSCredentialsProvider to refresh credentials when required.","title":"v2.3.2.0"},{"location":"changelog/#v2311","text":"http4k-connect- : Fix #11 thread safety of DocumentBuilderFactory.","title":"v2.3.1.1"},{"location":"changelog/#v2310","text":"* http4k-connect-amazon-lambda : [New module] Support for invoking AWS Lambda functions. * http4k-connect-amazon-lambda-fake : [New module] Includes FakeLambda runtime to run/deploy named HttpHandlers into.","title":"v2.3.1.0"},{"location":"changelog/#v2300","text":"http4k-connect- : Use Kotshi generated adapters instead of Kotlin Reflection, allowing removal of large Kotlin Reflection JAR. Note that the Kotlin-reflect dependency must be explicitly excluded due to transitivity in your projects.","title":"v2.3.0.0"},{"location":"changelog/#v2220","text":"http4k-connect- : Generate and ship extension functions for all actions. Rename S3.Bucket to S3Bucket .","title":"v2.2.2.0"},{"location":"changelog/#v2210","text":"http4k-connect- : Ship Javadoc.","title":"v2.2.1.0"},{"location":"changelog/#v2200","text":"http4k-connect- : Repackage all action classes.","title":"v2.2.0.0"},{"location":"changelog/#v2100","text":"http4k-connect- : Repackage all action classes.","title":"v2.1.0.0"},{"location":"changelog/#v2021","text":"http4k-connect- : Switch all interfaces to use new invoke() mechanism.","title":"v2.0.2.1"},{"location":"changelog/#v1101","text":"http4k-connect- : Upgrade http4k and Values4k.","title":"v1.1.0.1"},{"location":"changelog/#v1010","text":"http4k-connect-amazon-kms-fake : Simplify signing.","title":"v1.0.1.0"},{"location":"changelog/#v1000","text":"http4k-connect-amazon-kms : [New module] New client module. http4k-connect-amazon-kms-fake : [New module] New client fake module. http4k-connect-amazon-s3 : [New module] New client module. http4k-connect-amazon-s3-fake : [New module] New client fake module. http4k-connect-amazon-secretsmanager : [New module] New client module. http4k-connect-amazon-secretsmanager-fake : [New module] New client fake module. http4k-connect-amazon-systemsmanager : [New module] New client module. http4k-connect-amazon-systemsmanager-fake : [New module] New client fake module. http4k-connect-google-analytics : [New module] New client module. http4k-connect-storage-http : [New module] New storage module. http4k-connect-storage-jdbc : [New module] New storage module. http4k-connect-storage-redis : [New module] New storage module. http4k-connect-storage-s3 : [New module] New storage module.","title":"v1.0.0.0"},{"location":"changelog/#v02000","text":"Initial release.","title":"v0.20.0.0"},{"location":"code-of-conduct/","text":"Contributor Covenant Code of Conduct \u00b6 Our Pledge \u00b6 We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards \u00b6 Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities \u00b6 Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope \u00b6 This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement \u00b6 Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at contact@http4k.org . All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident. Enforcement Guidelines \u00b6 Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 1. Correction \u00b6 Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2. Warning \u00b6 Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 3. Temporary Ban \u00b6 Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 4. Permanent Ban \u00b6 Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community. Attribution \u00b6 This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html. Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.","title":"Code of Conduct"},{"location":"code-of-conduct/#contributor_covenant_code_of_conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"code-of-conduct/#our_pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"code-of-conduct/#our_standards","text":"Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"code-of-conduct/#enforcement_responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"code-of-conduct/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"code-of-conduct/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at contact@http4k.org . All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.","title":"Enforcement"},{"location":"code-of-conduct/#enforcement_guidelines","text":"Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:","title":"Enforcement Guidelines"},{"location":"code-of-conduct/#1_correction","text":"Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.","title":"1. Correction"},{"location":"code-of-conduct/#2_warning","text":"Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.","title":"2. Warning"},{"location":"code-of-conduct/#3_temporary_ban","text":"Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.","title":"3. Temporary Ban"},{"location":"code-of-conduct/#4_permanent_ban","text":"Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community.","title":"4. Permanent Ban"},{"location":"code-of-conduct/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html. Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.","title":"Attribution"},{"location":"contributing/","text":"http4k-connect contributions \u00b6 Notes for adding a new Client & Fake \u00b6 Use the Example project client and fake as a template module. The naming of the modules is: http4k-connect-<vendor>-<system> . We are also grouping the systems by vendor in directory structure. To add the modules in the right place in settings.gradle.kts use the functions provided. The work for adding other http4k-connect Gradle dependencies is already done in the core build.gradle file. You just need to add external dependencies into the module gradle file if there are any. If not, feel free to omit it. Fakes should extend ChaoticHttpHandler , which adds in the misbehave() and behave() functions to enable the Chaotic behaviour. Each Fake should implement the FakeSystemContract . Tests against external systems should be added wherever possible to prove the contracts are in place, or adding Docker setup to run them. This is work in progress. Notes for adding Storage implementations \u00b6 The naming of the modules is: http4k-connect-storage-<type> . To add the module in the right place in settings.gradle.kts use the function provided. There is a contract StorageContract to prove that the implementation. Testcontainers can be used to prove out testing for various storage backends","title":"Contribute/support http4k"},{"location":"contributing/#http4k-connect_contributions","text":"","title":"http4k-connect contributions"},{"location":"contributing/#notes_for_adding_a_new_client_fake","text":"Use the Example project client and fake as a template module. The naming of the modules is: http4k-connect-<vendor>-<system> . We are also grouping the systems by vendor in directory structure. To add the modules in the right place in settings.gradle.kts use the functions provided. The work for adding other http4k-connect Gradle dependencies is already done in the core build.gradle file. You just need to add external dependencies into the module gradle file if there are any. If not, feel free to omit it. Fakes should extend ChaoticHttpHandler , which adds in the misbehave() and behave() functions to enable the Chaotic behaviour. Each Fake should implement the FakeSystemContract . Tests against external systems should be added wherever possible to prove the contracts are in place, or adding Docker setup to run them. This is work in progress.","title":"Notes for adding a new Client &amp; Fake"},{"location":"contributing/#notes_for_adding_storage_implementations","text":"The naming of the modules is: http4k-connect-storage-<type> . To add the module in the right place in settings.gradle.kts use the function provided. There is a contract StorageContract to prove that the implementation. Testcontainers can be used to prove out testing for various storage backends","title":"Notes for adding Storage implementations"},{"location":"documentation/","text":"http4k-connect is a set of lightweight API libraries for connecting to popular third-party cloud services and AI backends using http4k compatible APIs, along with Fake implementations for usage during local testing. These are all underpinned by a variation on the uniform Server as a Function model powered by the HttpHandler interface exposed by http4k , so you can: Take advantage of the simple and powerful SaaF model and APIs used in http4k. Plug everything together completely in-memory and take advantage of this powerful model. Have access to the underlying HTTP clients (and hence add metrics or logging). Run stateful Fake implementations of 3rd party systems locally or in test environments. Although centered around usage in http4k-based projects, http4k-connect does not require this and the libraries are usable from any JVM application. Rationale \u00b6 Although convenient, many client libraries introduce many heavyweight dependencies or contain a plethora of non-required functionality, which can have a large effect on binary size. As an alternative, http4k-connect provides lightweight versions of popular APIs covering standard use-cases. Concepts \u00b6 System Client Modules (named: http4k-{vendor}-{system}) \u00b6 Each system client is modelled as a single function with arity 1 (that is it takes only a single parameter) returning a Result4k Success/Failure monad type), which is known as an Action . The Client is responsible for managing the overall protocol with the remote system. There are also a set of extension methods generated to provide a more traditional function-based version of the same interface. Action classes are responsible for constructing the HTTP requests and unmarshalling their responses into the http4k-connect types. There are lots of common actions built-in, but you can provide your own by simply implementing the relevant Action interface. The recommended pattern in http4k-connect is to use a Result monad type (we use Result4k) to represent the result type, but you can use anything to suit your programming model. // Generic system interface interface Example { operator fun < R : Any > invoke ( request : ExampleAction < R > ): Result < R , RemoteFailure > } // System-specific action interface ExampleAction < R > : Action < Result < R , RemoteFailure >> // Action and response classes data class Echo ( val value : String ) : ExampleAction < Echoed > data class Echoed ( val value : String ) // Traditional function helpers fun Example . echo ( value : String ): Result < Echoed , RemoteFailure > = this ( Echo ( value )) Example usage \u00b6 // constructing and using the clients val example = Example . Http ( httpHandler ) val echoed : Result < Echoed , RemoteFailure > = example . echo ( \"hello world\" ) // or... val alsoEchoed : Result < Echoed , RemoteFailure > = example ( Echo ( \"hello world\" )) System Fake Modules (named http4k-{vendor}-{system}-fake) \u00b6 Each module comes with it's own Fake system which implements the remote HTTP interface. In like with the Server as a Function concept, this Fake class implements HttpHandler and: Can be used in in-memory tests as a swap-out replacement for an HTTP client Can be started and bound to a HTTP port - each Fake has it's own unique port Can be deployed into test environments as a replacement for the real thing. Can be used to simulate Chaotic behaviour using the built in OpenApi interface (see http://localhost: /chaos) Start the Fake with: FakeExample().start() > Started FakeExample on 22375 Installation \u00b6 dependencies { // install the platform... implementation platform ( \"org.http4k:http4k-connect-bom:5.20.0.0\" ) // ...then choose a client implementation \"org.http4k:http4k-connect-amazon-s3\" // ...a fake for testing testImplementation \"org.http4k:http4k-connect-amazon-s3-fake\" // ...and a storage backend (optional) testImplementation \"org.http4k:http4k-connect-storage-redis\" } Supported APIs and Fakes: \u00b6 AWS AppRunner -> \"org.http4k:http4k-connect-amazon-apprunner\" / \"org.http4k:http4k-connect-amazon-apprunner-fake\" CloudFront -> \"org.http4k:http4k-connect-amazon-cloudfront\" / \"org.http4k:http4k-connect-amazon-cloudfront-fake\" CloudWatchLogs -> \"org.http4k:http4k-connect-amazon-cloudwatchlogs\" / \"org.http4k:http4k-connect-amazon-cloudwatchlogs-fake\" DynamoDb -> \"org.http4k:http4k-connect-amazon-dynamodb\" / \"org.http4k:http4k-connect-amazon-dynamodb-fake\" EventBridge -> \"org.http4k:http4k-connect-amazon-eventbridge\" / \"org.http4k:http4k-connect-amazon-eventbridge-fake\" Evidently -> \"org.http4k:http4k-connect-amazon-evidently\" / \"org.http4k:http4k-connect-amazon-evidently-fake\" Firehose -> \"org.http4k:http4k-connect-amazon-firehose\" / \"org.http4k:http4k-connect-amazon-firehose-fake\" IAM Identity Center -> \"org.http4k:http4k-connect-amazon-iamidentitycenter\" / \"org.http4k:http4k-connect-amazon-iamidentitycenter-fake\" InstanceMetadataService -> \"org.http4k:http4k-connect-amazon-instancemetadata\" / \"org.http4k:http4k-connect-amazon-instancemetadata-fake\" KMS -> \"org.http4k:http4k-connect-amazon-kms\" / \"org.http4k:http4k-connect-amazon-kms-fake\" Lambda -> \"org.http4k:http4k-connect-amazon-lambda\" / \"org.http4k:http4k-connect-amazon-lambda-fake\" S3 -> \"org.http4k:http4k-connect-amazon-s3\" / \"org.http4k:http4k-connect-amazon-s3-fake\" SecretsManager -> \"org.http4k:http4k-connect-amazon-secretsmanager\" / \"org.http4k:http4k-connect-amazon-secretsmanager-fake\" SES -> \"org.http4k:http4k-connect-amazon-ses\" / \"org.http4k:http4k-connect-amazon-ses-fake\" SNS -> \"org.http4k:http4k-connect-amazon-sns\" / \"org.http4k:http4k-connect-amazon-sns-fake\" SQS -> \"org.http4k:http4k-connect-amazon-sqs\" / \"org.http4k:http4k-connect-amazon-sqs-fake\" STS -> \"org.http4k:http4k-connect-amazon-sts\" / \"org.http4k:http4k-connect-amazon-sts-fake\" SystemsManager -> \"org.http4k:http4k-connect-amazon-systemsmanager\" / \"org.http4k:http4k-connect-amazon-systemsmanager-fake\" GitHub V3, App, Callback -> \"org.http4k:http4k-connect-github\" Google Analytics GA4 -> \"org.http4k:http4k-connect-google-analytics-ga4\" / \"org.http4k:http4k-connect-google-analytic-ga4-fake\" UA -> \"org.http4k:http4k-connect-google-analytics-ua\" / \"org.http4k:http4k-connect-google-analytic-ua-fake\" Kafka Rest Proxy -> \"org.http4k:http4k-connect-kafka-rest\" / \"org.http4k:http4k-connect-kafka-rest-fake\" Schema Registry -> \"org.http4k:http4k-connect-kafka-schemaregistry\" / \"org.http4k:http4k-connect-kafka-schemaregistry-fake\" Mattermost Webhook -> \"org.http4k:http4k-connect-mattermost\" / \"org.http4k:http4k-connect-mattermost-fake\" AI: LangChain4J -> \"org.http4k:http4k-connect-ai-langchain\" LmStudio -> \"org.http4k:http4k-connect-ai-lmstudio\" / \"org.http4k:http4k-connect-ai-lmstudio-fake\" OpenAI -> \"org.http4k:http4k-connect-ai-openai\" / \"org.http4k:http4k-connect-ai-openai-plugin\" / \"org.http4k:http4k-connect-ai-openai-fake\" Ollama -> \"org.http4k:http4k-connect-ai-ollama\" / \"org.http4k:http4k-connect-ai-ollama-fake\" Example Template -> \"org.http4k:http4k-connect-example\" / \"org.http4k:http4k-connect-example-fake\" Supported Storage backends (named http4k-connect-storage-{technology}>) \u00b6 In-Memory (included with all Fakes) File-Based (included with all Fakes) JDBC -> org.http4k:http4k-connect-storage-jdbc Redis -> org.http4k:http4k-connect-storage-redis S3 -> org.http4k:http4k-connect-storage-s3 Implementing your own adapters \u00b6 It is very easy to implement your own adapters to follow the pattern. For the system MySystem , you would need to: Depend on the http4k-connect-core artifact Add an Action interface and implementation: interface MySystemAction < R > : Action < R > data class Echo ( val value : String ) : MySystemAction < Echoed > { override fun toRequest () = Request ( GET , \"echo\" ). body ( value ) override fun toResult ( response : Response ) = Echoed ( response . bodyString ()) } data class Echoed ( val value : String ) Add your adapter interface and HTTP implementation: interface MySystem { operator fun < R : Any > invoke ( action : MySystemAction < R > ): R companion object } fun MySystem . Companion . Http ( http : HttpHandler ) = object : MySystem { override fun < R : Any > invoke ( action : MySystemAction < R > ) = action . toResult ( http ( action . toRequest ())) } Want to add a new system or Storage backend? Read the guide . \u00b6","title":"Introduction"},{"location":"documentation/#rationale","text":"Although convenient, many client libraries introduce many heavyweight dependencies or contain a plethora of non-required functionality, which can have a large effect on binary size. As an alternative, http4k-connect provides lightweight versions of popular APIs covering standard use-cases.","title":"Rationale"},{"location":"documentation/#concepts","text":"","title":"Concepts"},{"location":"documentation/#system_client_modules_named_http4k-vendor-system","text":"Each system client is modelled as a single function with arity 1 (that is it takes only a single parameter) returning a Result4k Success/Failure monad type), which is known as an Action . The Client is responsible for managing the overall protocol with the remote system. There are also a set of extension methods generated to provide a more traditional function-based version of the same interface. Action classes are responsible for constructing the HTTP requests and unmarshalling their responses into the http4k-connect types. There are lots of common actions built-in, but you can provide your own by simply implementing the relevant Action interface. The recommended pattern in http4k-connect is to use a Result monad type (we use Result4k) to represent the result type, but you can use anything to suit your programming model. // Generic system interface interface Example { operator fun < R : Any > invoke ( request : ExampleAction < R > ): Result < R , RemoteFailure > } // System-specific action interface ExampleAction < R > : Action < Result < R , RemoteFailure >> // Action and response classes data class Echo ( val value : String ) : ExampleAction < Echoed > data class Echoed ( val value : String ) // Traditional function helpers fun Example . echo ( value : String ): Result < Echoed , RemoteFailure > = this ( Echo ( value ))","title":"System Client Modules (named: http4k-{vendor}-{system})"},{"location":"documentation/#example_usage","text":"// constructing and using the clients val example = Example . Http ( httpHandler ) val echoed : Result < Echoed , RemoteFailure > = example . echo ( \"hello world\" ) // or... val alsoEchoed : Result < Echoed , RemoteFailure > = example ( Echo ( \"hello world\" ))","title":"Example usage"},{"location":"documentation/#system_fake_modules_named_http4k-vendor-system-fake","text":"Each module comes with it's own Fake system which implements the remote HTTP interface. In like with the Server as a Function concept, this Fake class implements HttpHandler and: Can be used in in-memory tests as a swap-out replacement for an HTTP client Can be started and bound to a HTTP port - each Fake has it's own unique port Can be deployed into test environments as a replacement for the real thing. Can be used to simulate Chaotic behaviour using the built in OpenApi interface (see http://localhost: /chaos) Start the Fake with: FakeExample().start() > Started FakeExample on 22375","title":"System Fake Modules (named http4k-{vendor}-{system}-fake)"},{"location":"documentation/#installation","text":"dependencies { // install the platform... implementation platform ( \"org.http4k:http4k-connect-bom:5.20.0.0\" ) // ...then choose a client implementation \"org.http4k:http4k-connect-amazon-s3\" // ...a fake for testing testImplementation \"org.http4k:http4k-connect-amazon-s3-fake\" // ...and a storage backend (optional) testImplementation \"org.http4k:http4k-connect-storage-redis\" }","title":"Installation"},{"location":"documentation/#supported_apis_and_fakes","text":"AWS AppRunner -> \"org.http4k:http4k-connect-amazon-apprunner\" / \"org.http4k:http4k-connect-amazon-apprunner-fake\" CloudFront -> \"org.http4k:http4k-connect-amazon-cloudfront\" / \"org.http4k:http4k-connect-amazon-cloudfront-fake\" CloudWatchLogs -> \"org.http4k:http4k-connect-amazon-cloudwatchlogs\" / \"org.http4k:http4k-connect-amazon-cloudwatchlogs-fake\" DynamoDb -> \"org.http4k:http4k-connect-amazon-dynamodb\" / \"org.http4k:http4k-connect-amazon-dynamodb-fake\" EventBridge -> \"org.http4k:http4k-connect-amazon-eventbridge\" / \"org.http4k:http4k-connect-amazon-eventbridge-fake\" Evidently -> \"org.http4k:http4k-connect-amazon-evidently\" / \"org.http4k:http4k-connect-amazon-evidently-fake\" Firehose -> \"org.http4k:http4k-connect-amazon-firehose\" / \"org.http4k:http4k-connect-amazon-firehose-fake\" IAM Identity Center -> \"org.http4k:http4k-connect-amazon-iamidentitycenter\" / \"org.http4k:http4k-connect-amazon-iamidentitycenter-fake\" InstanceMetadataService -> \"org.http4k:http4k-connect-amazon-instancemetadata\" / \"org.http4k:http4k-connect-amazon-instancemetadata-fake\" KMS -> \"org.http4k:http4k-connect-amazon-kms\" / \"org.http4k:http4k-connect-amazon-kms-fake\" Lambda -> \"org.http4k:http4k-connect-amazon-lambda\" / \"org.http4k:http4k-connect-amazon-lambda-fake\" S3 -> \"org.http4k:http4k-connect-amazon-s3\" / \"org.http4k:http4k-connect-amazon-s3-fake\" SecretsManager -> \"org.http4k:http4k-connect-amazon-secretsmanager\" / \"org.http4k:http4k-connect-amazon-secretsmanager-fake\" SES -> \"org.http4k:http4k-connect-amazon-ses\" / \"org.http4k:http4k-connect-amazon-ses-fake\" SNS -> \"org.http4k:http4k-connect-amazon-sns\" / \"org.http4k:http4k-connect-amazon-sns-fake\" SQS -> \"org.http4k:http4k-connect-amazon-sqs\" / \"org.http4k:http4k-connect-amazon-sqs-fake\" STS -> \"org.http4k:http4k-connect-amazon-sts\" / \"org.http4k:http4k-connect-amazon-sts-fake\" SystemsManager -> \"org.http4k:http4k-connect-amazon-systemsmanager\" / \"org.http4k:http4k-connect-amazon-systemsmanager-fake\" GitHub V3, App, Callback -> \"org.http4k:http4k-connect-github\" Google Analytics GA4 -> \"org.http4k:http4k-connect-google-analytics-ga4\" / \"org.http4k:http4k-connect-google-analytic-ga4-fake\" UA -> \"org.http4k:http4k-connect-google-analytics-ua\" / \"org.http4k:http4k-connect-google-analytic-ua-fake\" Kafka Rest Proxy -> \"org.http4k:http4k-connect-kafka-rest\" / \"org.http4k:http4k-connect-kafka-rest-fake\" Schema Registry -> \"org.http4k:http4k-connect-kafka-schemaregistry\" / \"org.http4k:http4k-connect-kafka-schemaregistry-fake\" Mattermost Webhook -> \"org.http4k:http4k-connect-mattermost\" / \"org.http4k:http4k-connect-mattermost-fake\" AI: LangChain4J -> \"org.http4k:http4k-connect-ai-langchain\" LmStudio -> \"org.http4k:http4k-connect-ai-lmstudio\" / \"org.http4k:http4k-connect-ai-lmstudio-fake\" OpenAI -> \"org.http4k:http4k-connect-ai-openai\" / \"org.http4k:http4k-connect-ai-openai-plugin\" / \"org.http4k:http4k-connect-ai-openai-fake\" Ollama -> \"org.http4k:http4k-connect-ai-ollama\" / \"org.http4k:http4k-connect-ai-ollama-fake\" Example Template -> \"org.http4k:http4k-connect-example\" / \"org.http4k:http4k-connect-example-fake\"","title":"Supported APIs and Fakes:"},{"location":"documentation/#supported_storage_backends_named_http4k-connect-storage-technology","text":"In-Memory (included with all Fakes) File-Based (included with all Fakes) JDBC -> org.http4k:http4k-connect-storage-jdbc Redis -> org.http4k:http4k-connect-storage-redis S3 -> org.http4k:http4k-connect-storage-s3","title":"Supported Storage backends (named http4k-connect-storage-{technology}&gt;)"},{"location":"documentation/#implementing_your_own_adapters","text":"It is very easy to implement your own adapters to follow the pattern. For the system MySystem , you would need to: Depend on the http4k-connect-core artifact Add an Action interface and implementation: interface MySystemAction < R > : Action < R > data class Echo ( val value : String ) : MySystemAction < Echoed > { override fun toRequest () = Request ( GET , \"echo\" ). body ( value ) override fun toResult ( response : Response ) = Echoed ( response . bodyString ()) } data class Echoed ( val value : String ) Add your adapter interface and HTTP implementation: interface MySystem { operator fun < R : Any > invoke ( action : MySystemAction < R > ): R companion object } fun MySystem . Companion . Http ( http : HttpHandler ) = object : MySystem { override fun < R : Any > invoke ( action : MySystemAction < R > ) = action . toResult ( http ( action . toRequest ())) }","title":"Implementing your own adapters"},{"location":"documentation/#want_to_add_a_new_system_or_storage_backend_read_the_guide","text":"","title":"Want to add a new system or Storage backend? Read the guide."},{"location":"reference/","text":"http4k-connect is a set of lightweight API libraries for connecting to popular third-party cloud services and AI backends using http4k compatible APIs, along with Fake implementations for usage during local testing. These are all underpinned by a variation on the uniform Server as a Function model powered by the HttpHandler interface exposed by http4k , so you can: Take advantage of the simple and powerful SaaF model and APIs used in http4k. Plug everything together completely in-memory and take advantage of this powerful model. Have access to the underlying HTTP clients (and hence add metrics or logging). Run stateful Fake implementations of 3rd party systems locally or in test environments. Although centered around usage in http4k-based projects, http4k-connect does not require this and the libraries are usable from any JVM application. Rationale \u00b6 Although convenient, many client libraries introduce many heavyweight dependencies or contain a plethora of non-required functionality, which can have a large effect on binary size. As an alternative, http4k-connect provides lightweight versions of popular APIs covering standard use-cases. Concepts \u00b6 System Client Modules (named: http4k-{vendor}-{system}) \u00b6 Each system client is modelled as a single function with arity 1 (that is it takes only a single parameter) returning a Result4k Success/Failure monad type), which is known as an Action . The Client is responsible for managing the overall protocol with the remote system. There are also a set of extension methods generated to provide a more traditional function-based version of the same interface. Action classes are responsible for constructing the HTTP requests and unmarshalling their responses into the http4k-connect types. There are lots of common actions built-in, but you can provide your own by simply implementing the relevant Action interface. The recommended pattern in http4k-connect is to use a Result monad type (we use Result4k) to represent the result type, but you can use anything to suit your programming model. // Generic system interface interface Example { operator fun < R : Any > invoke ( request : ExampleAction < R > ): Result < R , RemoteFailure > } // System-specific action interface ExampleAction < R > : Action < Result < R , RemoteFailure >> // Action and response classes data class Echo ( val value : String ) : ExampleAction < Echoed > data class Echoed ( val value : String ) // Traditional function helpers fun Example . echo ( value : String ): Result < Echoed , RemoteFailure > = this ( Echo ( value )) Example usage \u00b6 // constructing and using the clients val example = Example . Http ( httpHandler ) val echoed : Result < Echoed , RemoteFailure > = example . echo ( \"hello world\" ) // or... val alsoEchoed : Result < Echoed , RemoteFailure > = example ( Echo ( \"hello world\" )) System Fake Modules (named http4k-{vendor}-{system}-fake) \u00b6 Each module comes with it's own Fake system which implements the remote HTTP interface. In like with the Server as a Function concept, this Fake class implements HttpHandler and: Can be used in in-memory tests as a swap-out replacement for an HTTP client Can be started and bound to a HTTP port - each Fake has it's own unique port Can be deployed into test environments as a replacement for the real thing. Can be used to simulate Chaotic behaviour using the built in OpenApi interface (see http://localhost: /chaos) Start the Fake with: FakeExample().start() > Started FakeExample on 22375 Installation \u00b6 dependencies { // install the platform... implementation platform ( \"org.http4k:http4k-connect-bom:5.20.0.0\" ) // ...then choose a client implementation \"org.http4k:http4k-connect-amazon-s3\" // ...a fake for testing testImplementation \"org.http4k:http4k-connect-amazon-s3-fake\" // ...and a storage backend (optional) testImplementation \"org.http4k:http4k-connect-storage-redis\" } Supported APIs and Fakes: \u00b6 AWS AppRunner -> \"org.http4k:http4k-connect-amazon-apprunner\" / \"org.http4k:http4k-connect-amazon-apprunner-fake\" CloudFront -> \"org.http4k:http4k-connect-amazon-cloudfront\" / \"org.http4k:http4k-connect-amazon-cloudfront-fake\" CloudWatchLogs -> \"org.http4k:http4k-connect-amazon-cloudwatchlogs\" / \"org.http4k:http4k-connect-amazon-cloudwatchlogs-fake\" DynamoDb -> \"org.http4k:http4k-connect-amazon-dynamodb\" / \"org.http4k:http4k-connect-amazon-dynamodb-fake\" EventBridge -> \"org.http4k:http4k-connect-amazon-eventbridge\" / \"org.http4k:http4k-connect-amazon-eventbridge-fake\" Evidently -> \"org.http4k:http4k-connect-amazon-evidently\" / \"org.http4k:http4k-connect-amazon-evidently-fake\" Firehose -> \"org.http4k:http4k-connect-amazon-firehose\" / \"org.http4k:http4k-connect-amazon-firehose-fake\" IAM Identity Center -> \"org.http4k:http4k-connect-amazon-iamidentitycenter\" / \"org.http4k:http4k-connect-amazon-iamidentitycenter-fake\" InstanceMetadataService -> \"org.http4k:http4k-connect-amazon-instancemetadata\" / \"org.http4k:http4k-connect-amazon-instancemetadata-fake\" KMS -> \"org.http4k:http4k-connect-amazon-kms\" / \"org.http4k:http4k-connect-amazon-kms-fake\" Lambda -> \"org.http4k:http4k-connect-amazon-lambda\" / \"org.http4k:http4k-connect-amazon-lambda-fake\" S3 -> \"org.http4k:http4k-connect-amazon-s3\" / \"org.http4k:http4k-connect-amazon-s3-fake\" SecretsManager -> \"org.http4k:http4k-connect-amazon-secretsmanager\" / \"org.http4k:http4k-connect-amazon-secretsmanager-fake\" SES -> \"org.http4k:http4k-connect-amazon-ses\" / \"org.http4k:http4k-connect-amazon-ses-fake\" SNS -> \"org.http4k:http4k-connect-amazon-sns\" / \"org.http4k:http4k-connect-amazon-sns-fake\" SQS -> \"org.http4k:http4k-connect-amazon-sqs\" / \"org.http4k:http4k-connect-amazon-sqs-fake\" STS -> \"org.http4k:http4k-connect-amazon-sts\" / \"org.http4k:http4k-connect-amazon-sts-fake\" SystemsManager -> \"org.http4k:http4k-connect-amazon-systemsmanager\" / \"org.http4k:http4k-connect-amazon-systemsmanager-fake\" GitHub V3, App, Callback -> \"org.http4k:http4k-connect-github\" Google Analytics GA4 -> \"org.http4k:http4k-connect-google-analytics-ga4\" / \"org.http4k:http4k-connect-google-analytic-ga4-fake\" UA -> \"org.http4k:http4k-connect-google-analytics-ua\" / \"org.http4k:http4k-connect-google-analytic-ua-fake\" Kafka Rest Proxy -> \"org.http4k:http4k-connect-kafka-rest\" / \"org.http4k:http4k-connect-kafka-rest-fake\" Schema Registry -> \"org.http4k:http4k-connect-kafka-schemaregistry\" / \"org.http4k:http4k-connect-kafka-schemaregistry-fake\" Mattermost Webhook -> \"org.http4k:http4k-connect-mattermost\" / \"org.http4k:http4k-connect-mattermost-fake\" AI: LangChain4J -> \"org.http4k:http4k-connect-ai-langchain\" LmStudio -> \"org.http4k:http4k-connect-ai-lmstudio\" / \"org.http4k:http4k-connect-ai-lmstudio-fake\" OpenAI -> \"org.http4k:http4k-connect-ai-openai\" / \"org.http4k:http4k-connect-ai-openai-plugin\" / \"org.http4k:http4k-connect-ai-openai-fake\" Ollama -> \"org.http4k:http4k-connect-ai-ollama\" / \"org.http4k:http4k-connect-ai-ollama-fake\" Example Template -> \"org.http4k:http4k-connect-example\" / \"org.http4k:http4k-connect-example-fake\" Supported Storage backends (named http4k-connect-storage-{technology}>) \u00b6 In-Memory (included with all Fakes) File-Based (included with all Fakes) JDBC -> org.http4k:http4k-connect-storage-jdbc Redis -> org.http4k:http4k-connect-storage-redis S3 -> org.http4k:http4k-connect-storage-s3 Implementing your own adapters \u00b6 It is very easy to implement your own adapters to follow the pattern. For the system MySystem , you would need to: Depend on the http4k-connect-core artifact Add an Action interface and implementation: interface MySystemAction < R > : Action < R > data class Echo ( val value : String ) : MySystemAction < Echoed > { override fun toRequest () = Request ( GET , \"echo\" ). body ( value ) override fun toResult ( response : Response ) = Echoed ( response . bodyString ()) } data class Echoed ( val value : String ) Add your adapter interface and HTTP implementation: interface MySystem { operator fun < R : Any > invoke ( action : MySystemAction < R > ): R companion object } fun MySystem . Companion . Http ( http : HttpHandler ) = object : MySystem { override fun < R : Any > invoke ( action : MySystemAction < R > ) = action . toResult ( http ( action . toRequest ())) } Want to add a new system or Storage backend? Read the guide . \u00b6","title":"Index"},{"location":"reference/#rationale","text":"Although convenient, many client libraries introduce many heavyweight dependencies or contain a plethora of non-required functionality, which can have a large effect on binary size. As an alternative, http4k-connect provides lightweight versions of popular APIs covering standard use-cases.","title":"Rationale"},{"location":"reference/#concepts","text":"","title":"Concepts"},{"location":"reference/#system_client_modules_named_http4k-vendor-system","text":"Each system client is modelled as a single function with arity 1 (that is it takes only a single parameter) returning a Result4k Success/Failure monad type), which is known as an Action . The Client is responsible for managing the overall protocol with the remote system. There are also a set of extension methods generated to provide a more traditional function-based version of the same interface. Action classes are responsible for constructing the HTTP requests and unmarshalling their responses into the http4k-connect types. There are lots of common actions built-in, but you can provide your own by simply implementing the relevant Action interface. The recommended pattern in http4k-connect is to use a Result monad type (we use Result4k) to represent the result type, but you can use anything to suit your programming model. // Generic system interface interface Example { operator fun < R : Any > invoke ( request : ExampleAction < R > ): Result < R , RemoteFailure > } // System-specific action interface ExampleAction < R > : Action < Result < R , RemoteFailure >> // Action and response classes data class Echo ( val value : String ) : ExampleAction < Echoed > data class Echoed ( val value : String ) // Traditional function helpers fun Example . echo ( value : String ): Result < Echoed , RemoteFailure > = this ( Echo ( value ))","title":"System Client Modules (named: http4k-{vendor}-{system})"},{"location":"reference/#example_usage","text":"// constructing and using the clients val example = Example . Http ( httpHandler ) val echoed : Result < Echoed , RemoteFailure > = example . echo ( \"hello world\" ) // or... val alsoEchoed : Result < Echoed , RemoteFailure > = example ( Echo ( \"hello world\" ))","title":"Example usage"},{"location":"reference/#system_fake_modules_named_http4k-vendor-system-fake","text":"Each module comes with it's own Fake system which implements the remote HTTP interface. In like with the Server as a Function concept, this Fake class implements HttpHandler and: Can be used in in-memory tests as a swap-out replacement for an HTTP client Can be started and bound to a HTTP port - each Fake has it's own unique port Can be deployed into test environments as a replacement for the real thing. Can be used to simulate Chaotic behaviour using the built in OpenApi interface (see http://localhost: /chaos) Start the Fake with: FakeExample().start() > Started FakeExample on 22375","title":"System Fake Modules (named http4k-{vendor}-{system}-fake)"},{"location":"reference/#installation","text":"dependencies { // install the platform... implementation platform ( \"org.http4k:http4k-connect-bom:5.20.0.0\" ) // ...then choose a client implementation \"org.http4k:http4k-connect-amazon-s3\" // ...a fake for testing testImplementation \"org.http4k:http4k-connect-amazon-s3-fake\" // ...and a storage backend (optional) testImplementation \"org.http4k:http4k-connect-storage-redis\" }","title":"Installation"},{"location":"reference/#supported_apis_and_fakes","text":"AWS AppRunner -> \"org.http4k:http4k-connect-amazon-apprunner\" / \"org.http4k:http4k-connect-amazon-apprunner-fake\" CloudFront -> \"org.http4k:http4k-connect-amazon-cloudfront\" / \"org.http4k:http4k-connect-amazon-cloudfront-fake\" CloudWatchLogs -> \"org.http4k:http4k-connect-amazon-cloudwatchlogs\" / \"org.http4k:http4k-connect-amazon-cloudwatchlogs-fake\" DynamoDb -> \"org.http4k:http4k-connect-amazon-dynamodb\" / \"org.http4k:http4k-connect-amazon-dynamodb-fake\" EventBridge -> \"org.http4k:http4k-connect-amazon-eventbridge\" / \"org.http4k:http4k-connect-amazon-eventbridge-fake\" Evidently -> \"org.http4k:http4k-connect-amazon-evidently\" / \"org.http4k:http4k-connect-amazon-evidently-fake\" Firehose -> \"org.http4k:http4k-connect-amazon-firehose\" / \"org.http4k:http4k-connect-amazon-firehose-fake\" IAM Identity Center -> \"org.http4k:http4k-connect-amazon-iamidentitycenter\" / \"org.http4k:http4k-connect-amazon-iamidentitycenter-fake\" InstanceMetadataService -> \"org.http4k:http4k-connect-amazon-instancemetadata\" / \"org.http4k:http4k-connect-amazon-instancemetadata-fake\" KMS -> \"org.http4k:http4k-connect-amazon-kms\" / \"org.http4k:http4k-connect-amazon-kms-fake\" Lambda -> \"org.http4k:http4k-connect-amazon-lambda\" / \"org.http4k:http4k-connect-amazon-lambda-fake\" S3 -> \"org.http4k:http4k-connect-amazon-s3\" / \"org.http4k:http4k-connect-amazon-s3-fake\" SecretsManager -> \"org.http4k:http4k-connect-amazon-secretsmanager\" / \"org.http4k:http4k-connect-amazon-secretsmanager-fake\" SES -> \"org.http4k:http4k-connect-amazon-ses\" / \"org.http4k:http4k-connect-amazon-ses-fake\" SNS -> \"org.http4k:http4k-connect-amazon-sns\" / \"org.http4k:http4k-connect-amazon-sns-fake\" SQS -> \"org.http4k:http4k-connect-amazon-sqs\" / \"org.http4k:http4k-connect-amazon-sqs-fake\" STS -> \"org.http4k:http4k-connect-amazon-sts\" / \"org.http4k:http4k-connect-amazon-sts-fake\" SystemsManager -> \"org.http4k:http4k-connect-amazon-systemsmanager\" / \"org.http4k:http4k-connect-amazon-systemsmanager-fake\" GitHub V3, App, Callback -> \"org.http4k:http4k-connect-github\" Google Analytics GA4 -> \"org.http4k:http4k-connect-google-analytics-ga4\" / \"org.http4k:http4k-connect-google-analytic-ga4-fake\" UA -> \"org.http4k:http4k-connect-google-analytics-ua\" / \"org.http4k:http4k-connect-google-analytic-ua-fake\" Kafka Rest Proxy -> \"org.http4k:http4k-connect-kafka-rest\" / \"org.http4k:http4k-connect-kafka-rest-fake\" Schema Registry -> \"org.http4k:http4k-connect-kafka-schemaregistry\" / \"org.http4k:http4k-connect-kafka-schemaregistry-fake\" Mattermost Webhook -> \"org.http4k:http4k-connect-mattermost\" / \"org.http4k:http4k-connect-mattermost-fake\" AI: LangChain4J -> \"org.http4k:http4k-connect-ai-langchain\" LmStudio -> \"org.http4k:http4k-connect-ai-lmstudio\" / \"org.http4k:http4k-connect-ai-lmstudio-fake\" OpenAI -> \"org.http4k:http4k-connect-ai-openai\" / \"org.http4k:http4k-connect-ai-openai-plugin\" / \"org.http4k:http4k-connect-ai-openai-fake\" Ollama -> \"org.http4k:http4k-connect-ai-ollama\" / \"org.http4k:http4k-connect-ai-ollama-fake\" Example Template -> \"org.http4k:http4k-connect-example\" / \"org.http4k:http4k-connect-example-fake\"","title":"Supported APIs and Fakes:"},{"location":"reference/#supported_storage_backends_named_http4k-connect-storage-technology","text":"In-Memory (included with all Fakes) File-Based (included with all Fakes) JDBC -> org.http4k:http4k-connect-storage-jdbc Redis -> org.http4k:http4k-connect-storage-redis S3 -> org.http4k:http4k-connect-storage-s3","title":"Supported Storage backends (named http4k-connect-storage-{technology}&gt;)"},{"location":"reference/#implementing_your_own_adapters","text":"It is very easy to implement your own adapters to follow the pattern. For the system MySystem , you would need to: Depend on the http4k-connect-core artifact Add an Action interface and implementation: interface MySystemAction < R > : Action < R > data class Echo ( val value : String ) : MySystemAction < Echoed > { override fun toRequest () = Request ( GET , \"echo\" ). body ( value ) override fun toResult ( response : Response ) = Echoed ( response . bodyString ()) } data class Echoed ( val value : String ) Add your adapter interface and HTTP implementation: interface MySystem { operator fun < R : Any > invoke ( action : MySystemAction < R > ): R companion object } fun MySystem . Companion . Http ( http : HttpHandler ) = object : MySystem { override fun < R : Any > invoke ( action : MySystemAction < R > ) = action . toResult ( http ( action . toRequest ())) }","title":"Implementing your own adapters"},{"location":"reference/#want_to_add_a_new_system_or_storage_backend_read_the_guide","text":"","title":"Want to add a new system or Storage backend? Read the guide."},{"location":"reference/ai/langchain/","text":"LangChain \u00b6 LangChain4J is a versatile library that simplifies the creation and management of language processing workflows., It provides many integrations but does not allow for using http4k clients or http4k-connect adapters. This module gives you some of these integrations by providing LangChain model adapters. Current adapters support http4k client integrations for the following models, allowing you to use them in your http4k applications: OpenAI OpenAiChatLanguageModel OpenAiChatImageModel OpenAiChatEmbeddingModel Ollama OllamaChatLanguageModel OllamaChatImageModel OllamaChatEmbeddingModel S3 Document Loaders Using these adapters is as simple as: val model : ChatLanguageModel = OpenAiChatLanguageModel ( OpenAI . Http ( OpenAIToken . of ( \"hello\" ), FakeOpenAI ())) val chat : Response < AiMessage > = model . generate ( \"hello kitty\" )","title":"LangChain"},{"location":"reference/ai/langchain/#langchain","text":"LangChain4J is a versatile library that simplifies the creation and management of language processing workflows., It provides many integrations but does not allow for using http4k clients or http4k-connect adapters. This module gives you some of these integrations by providing LangChain model adapters. Current adapters support http4k client integrations for the following models, allowing you to use them in your http4k applications: OpenAI OpenAiChatLanguageModel OpenAiChatImageModel OpenAiChatEmbeddingModel Ollama OllamaChatLanguageModel OllamaChatImageModel OllamaChatEmbeddingModel S3 Document Loaders Using these adapters is as simple as: val model : ChatLanguageModel = OpenAiChatLanguageModel ( OpenAI . Http ( OpenAIToken . of ( \"hello\" ), FakeOpenAI ())) val chat : Response < AiMessage > = model . generate ( \"hello kitty\" )","title":"LangChain"},{"location":"reference/ai/lmstudio/","text":"LmStudio \u00b6 The http4k-connect LmStudio integration provides: LmStudio API client FakeLmStudio server which can be used as testing harness for either API client LmStudio API connector \u00b6 The LmStudio connector provides the following Actions: GetModels ChatCompletion CreateEmbeddings New actions can be created easily using the same transport. The client APIs utilise the LmStudio API Key (Bearer Auth). There is no reflection used anywhere in the library, so this is perfect for deploying to a Serverless function. Example usage \u00b6 const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeLmStudio () // create a client val client = LmStudio . Http ( http . debug ()) // all operations return a Result monad of the API type val result : Result < Models , RemoteFailure > = client . getModels () println ( result ) } Other examples can be found here . Fake LmStudio Server \u00b6 The Fake LmStudio provides the below actions and can be spun up as a server, meaning it is perfect for using in test environments without using up valuable request tokens! GetModels ChatCompletion Generation of responses \u00b6 By default, a random LoremIpsum generator creates chat completion responses for the Fake. This behaviour can be overridden to generate custom response formats (eg. structured responses) if required. To do so, create instances of the ChatCompletionGenerator interface and return as appropriate. Default Fake port: 58438 \u00b6 To start: FakeLmStudio().start()","title":"LMStudio"},{"location":"reference/ai/lmstudio/#lmstudio","text":"The http4k-connect LmStudio integration provides: LmStudio API client FakeLmStudio server which can be used as testing harness for either API client","title":"LmStudio"},{"location":"reference/ai/lmstudio/#lmstudio_api_connector","text":"The LmStudio connector provides the following Actions: GetModels ChatCompletion CreateEmbeddings New actions can be created easily using the same transport. The client APIs utilise the LmStudio API Key (Bearer Auth). There is no reflection used anywhere in the library, so this is perfect for deploying to a Serverless function.","title":"LmStudio API connector"},{"location":"reference/ai/lmstudio/#example_usage","text":"const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeLmStudio () // create a client val client = LmStudio . Http ( http . debug ()) // all operations return a Result monad of the API type val result : Result < Models , RemoteFailure > = client . getModels () println ( result ) } Other examples can be found here .","title":"Example usage"},{"location":"reference/ai/lmstudio/#fake_lmstudio_server","text":"The Fake LmStudio provides the below actions and can be spun up as a server, meaning it is perfect for using in test environments without using up valuable request tokens! GetModels ChatCompletion","title":"Fake LmStudio Server"},{"location":"reference/ai/lmstudio/#generation_of_responses","text":"By default, a random LoremIpsum generator creates chat completion responses for the Fake. This behaviour can be overridden to generate custom response formats (eg. structured responses) if required. To do so, create instances of the ChatCompletionGenerator interface and return as appropriate.","title":"Generation of responses"},{"location":"reference/ai/lmstudio/#default_fake_port_58438","text":"To start: FakeLmStudio().start()","title":"Default Fake port: 58438"},{"location":"reference/ai/ollama/","text":"Ollama \u00b6 The http4k-connect Ollama integration provides: - Ollama API client - FakeOllama server which can be used as testing harness Ollama API connector \u00b6 The Ollama connector provides the following Actions: GetModels ChatCompletion CreateEmbeddings GenerateImage New actions can be created easily using the same transport. The client APIs utilise the Ollama API Key (Bearer Auth). There is no reflection used anywhere in the library, so this is perfect for deploying to a Serverless function. Example usage \u00b6 const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeOllama () // create a client val client = Ollama . Http ( http . debug ()) // all operations return a Result monad of the API type val result : Result < ModelList , RemoteFailure > = client . getModels () println ( result ) } Other examples can be found here . Fake Ollama Server \u00b6 The Fake Ollama provides the below actions and can be spun up as a server, meaning it is perfect for using in test environments without using up valuable request tokens! GetModels ChatCompletion Completion PullModel CreateEmbeddings Generation of responses \u00b6 By default, a random LoremIpsum generator creates chat completion responses for the Fake. This behaviour can be overridden to generate custom response formats (eg. structured responses) if required. To do so, create instances of the ChatCompletionGenerator interface and return as appropriate. Default Fake port: 31193 \u00b6 To start: FakeOllama().start()","title":"Ollama"},{"location":"reference/ai/ollama/#ollama","text":"The http4k-connect Ollama integration provides: - Ollama API client - FakeOllama server which can be used as testing harness","title":"Ollama"},{"location":"reference/ai/ollama/#ollama_api_connector","text":"The Ollama connector provides the following Actions: GetModels ChatCompletion CreateEmbeddings GenerateImage New actions can be created easily using the same transport. The client APIs utilise the Ollama API Key (Bearer Auth). There is no reflection used anywhere in the library, so this is perfect for deploying to a Serverless function.","title":"Ollama API connector"},{"location":"reference/ai/ollama/#example_usage","text":"const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeOllama () // create a client val client = Ollama . Http ( http . debug ()) // all operations return a Result monad of the API type val result : Result < ModelList , RemoteFailure > = client . getModels () println ( result ) } Other examples can be found here .","title":"Example usage"},{"location":"reference/ai/ollama/#fake_ollama_server","text":"The Fake Ollama provides the below actions and can be spun up as a server, meaning it is perfect for using in test environments without using up valuable request tokens! GetModels ChatCompletion Completion PullModel CreateEmbeddings","title":"Fake Ollama Server"},{"location":"reference/ai/ollama/#generation_of_responses","text":"By default, a random LoremIpsum generator creates chat completion responses for the Fake. This behaviour can be overridden to generate custom response formats (eg. structured responses) if required. To do so, create instances of the ChatCompletionGenerator interface and return as appropriate.","title":"Generation of responses"},{"location":"reference/ai/ollama/#default_fake_port_31193","text":"To start: FakeOllama().start()","title":"Default Fake port: 31193"},{"location":"reference/ai/openai/","text":"OpenAI \u00b6 The http4k-connect OpenAI integration provides: - OpenAI API client - Plugin SDK for developing OpenAI plugins - FakeOpenAI server which can be used as testing harness for either API client or OpenAI plugins OpenAI API connector \u00b6 The OpenAI connector provides the following Actions: GetModels ChatCompletion CreateEmbeddings GenerateImage New actions can be created easily using the same transport. The client APIs utilise the OpenAI API Key (Bearer Auth). There is no reflection used anywhere in the library, so this is perfect for deploying to a Serverless function. Example usage \u00b6 const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeOpenAI () // create a client val client = OpenAI . Http ( OpenAIToken . of ( \"foobar\" ), http . debug ()) // all operations return a Result monad of the API type val result : Result < Models , RemoteFailure > = client . getModels () println ( result ) } Other examples can be found here . OpenAI Plugin SDK \u00b6 The OpenAPI Plugin SDK provides APIs to simply write OpenAI compliant plugins with the minimum of fuss. Simply use the openAiPlugin() function to compose your function, adding the configuration for the authorization and the contract endpoints which expose the API to OpenAI. The following plugin types are supported: - Service - the Plugin developer provides credentials to the OpenAI UI which are used for auth. No personalisation of responses is possible. - User - the OpenAI user provides credentials to the OpenAI UI which are used for auth. Prinicpals are tracked so the API responses can be personalised. - OAuth - users login to the Plugin application using an AuthorizationCode grant and an experience defined by the Plugin developer. The SDK provides all features required by the OpenAI platform: - A manifest endpoint for the plugin, with all of the required configuration - An OpenAPI specification endpoint for OpenAI to interrogate your API - Security on the API endpoints as defined on construction. Supported auth methods are: - Basic Auth - Bearer Auth - OAuth (Authorization flow) - with security endpoints. Plugins are just HttpHandlers and as such can be mixed into existing applications or started alone. Example: openAiPlugin ( info ( apiVersion = \"1.0\" , humanDescription = \"addressbook\" to \"my great plugin\" , pluginUrl = Uri . of ( \"http://localhost:9000\" ), contactEmail = Email . of ( \"foo@bar\" ), ), UserLevelAuth ( PluginAuthToken . Basic ( \"realm\" ) { it : Credentials -> it == credentials } ), Path . of ( \"foo\" ) / Path . of ( \"bar\" ) meta { summary = \"A great api endpoint\" } bindContract GET to { foo , bar -> { _ : Request -> Response ( OK ). with ( Body . auto < Message > (). toLens () of Message ( \"hello $ foo $ bar \" )) } } ) The FakeOpenAI server also provides support for running plugins locally and interacting with them as \"installed\" in the fake. There is a full working example of how to create and deploy plugins in the examples repository . Fake OpenAI Server \u00b6 The Fake OpenAI provides the below actions and can be spun up as a server, meaning it is perfect for using in test environments without using up valuable request tokens! GetModels ChatCompletion GenerateImage Security \u00b6 The Fake server endpoints are secured with a BearerToken header, but the value is not checked for anything other than presence. Image generation \u00b6 Image generation also can be set to either URL or base-64 data return. In the case of URLs, the Fake also doubles as a webserver for serving the images (so you can request an image and then load it from the server). Resolution PNG images of 256x/512x/1024x are supported. Generation of responses \u00b6 By default, a random LoremIpsum generator creates chat completion responses for the Fake. This behaviour can be overridden to generate custom response formats (eg. structured responses) if required. To do so, create instances of the ChatCompletionGenerator interface and return as appropriate. Running plugins in the FakeOpenAI \u00b6 http4k-connect OpenAI Plugins can be run locally and also \"installed\" into the FakeOpenAI. To install a plugin, pass the configured PluginIntegration instances into the fake at construction time. The FakeOpenAI will then use the configuration to negotiate the connection to the plugin. Both the Fake and the Plugin should be running on different local ports. FakeOpenAI ( plugins = arrayOf ( ServicePluginIntegration ( BearerAuth ( \"openai api key\" ), OpenAIPluginId . of ( \"serviceplugin\" ), Uri . of ( \"http://localhost:10000\" ) ) ) ). start () To test the Plugin locally, start and browse to the FakeOpenAI instance. The list of installed plugins will be displayed and can be clicked through to an authenticated OpenAPI UI which can be used to interact with the exposed Plugin API. Default Fake port: 45674 \u00b6 To start: FakeOpenAI().start()","title":"OpenAI"},{"location":"reference/ai/openai/#openai","text":"The http4k-connect OpenAI integration provides: - OpenAI API client - Plugin SDK for developing OpenAI plugins - FakeOpenAI server which can be used as testing harness for either API client or OpenAI plugins","title":"OpenAI"},{"location":"reference/ai/openai/#openai_api_connector","text":"The OpenAI connector provides the following Actions: GetModels ChatCompletion CreateEmbeddings GenerateImage New actions can be created easily using the same transport. The client APIs utilise the OpenAI API Key (Bearer Auth). There is no reflection used anywhere in the library, so this is perfect for deploying to a Serverless function.","title":"OpenAI API connector"},{"location":"reference/ai/openai/#example_usage","text":"const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeOpenAI () // create a client val client = OpenAI . Http ( OpenAIToken . of ( \"foobar\" ), http . debug ()) // all operations return a Result monad of the API type val result : Result < Models , RemoteFailure > = client . getModels () println ( result ) } Other examples can be found here .","title":"Example usage"},{"location":"reference/ai/openai/#openai_plugin_sdk","text":"The OpenAPI Plugin SDK provides APIs to simply write OpenAI compliant plugins with the minimum of fuss. Simply use the openAiPlugin() function to compose your function, adding the configuration for the authorization and the contract endpoints which expose the API to OpenAI. The following plugin types are supported: - Service - the Plugin developer provides credentials to the OpenAI UI which are used for auth. No personalisation of responses is possible. - User - the OpenAI user provides credentials to the OpenAI UI which are used for auth. Prinicpals are tracked so the API responses can be personalised. - OAuth - users login to the Plugin application using an AuthorizationCode grant and an experience defined by the Plugin developer. The SDK provides all features required by the OpenAI platform: - A manifest endpoint for the plugin, with all of the required configuration - An OpenAPI specification endpoint for OpenAI to interrogate your API - Security on the API endpoints as defined on construction. Supported auth methods are: - Basic Auth - Bearer Auth - OAuth (Authorization flow) - with security endpoints. Plugins are just HttpHandlers and as such can be mixed into existing applications or started alone. Example: openAiPlugin ( info ( apiVersion = \"1.0\" , humanDescription = \"addressbook\" to \"my great plugin\" , pluginUrl = Uri . of ( \"http://localhost:9000\" ), contactEmail = Email . of ( \"foo@bar\" ), ), UserLevelAuth ( PluginAuthToken . Basic ( \"realm\" ) { it : Credentials -> it == credentials } ), Path . of ( \"foo\" ) / Path . of ( \"bar\" ) meta { summary = \"A great api endpoint\" } bindContract GET to { foo , bar -> { _ : Request -> Response ( OK ). with ( Body . auto < Message > (). toLens () of Message ( \"hello $ foo $ bar \" )) } } ) The FakeOpenAI server also provides support for running plugins locally and interacting with them as \"installed\" in the fake. There is a full working example of how to create and deploy plugins in the examples repository .","title":"OpenAI Plugin SDK"},{"location":"reference/ai/openai/#fake_openai_server","text":"The Fake OpenAI provides the below actions and can be spun up as a server, meaning it is perfect for using in test environments without using up valuable request tokens! GetModels ChatCompletion GenerateImage","title":"Fake OpenAI Server"},{"location":"reference/ai/openai/#security","text":"The Fake server endpoints are secured with a BearerToken header, but the value is not checked for anything other than presence.","title":"Security"},{"location":"reference/ai/openai/#image_generation","text":"Image generation also can be set to either URL or base-64 data return. In the case of URLs, the Fake also doubles as a webserver for serving the images (so you can request an image and then load it from the server). Resolution PNG images of 256x/512x/1024x are supported.","title":"Image generation"},{"location":"reference/ai/openai/#generation_of_responses","text":"By default, a random LoremIpsum generator creates chat completion responses for the Fake. This behaviour can be overridden to generate custom response formats (eg. structured responses) if required. To do so, create instances of the ChatCompletionGenerator interface and return as appropriate.","title":"Generation of responses"},{"location":"reference/ai/openai/#running_plugins_in_the_fakeopenai","text":"http4k-connect OpenAI Plugins can be run locally and also \"installed\" into the FakeOpenAI. To install a plugin, pass the configured PluginIntegration instances into the fake at construction time. The FakeOpenAI will then use the configuration to negotiate the connection to the plugin. Both the Fake and the Plugin should be running on different local ports. FakeOpenAI ( plugins = arrayOf ( ServicePluginIntegration ( BearerAuth ( \"openai api key\" ), OpenAIPluginId . of ( \"serviceplugin\" ), Uri . of ( \"http://localhost:10000\" ) ) ) ). start () To test the Plugin locally, start and browse to the FakeOpenAI instance. The list of installed plugins will be displayed and can be clicked through to an authenticated OpenAPI UI which can be used to interact with the exposed Plugin API.","title":"Running plugins in the FakeOpenAI"},{"location":"reference/ai/openai/#default_fake_port_45674","text":"To start: FakeOpenAI().start()","title":"Default Fake port: 45674"},{"location":"reference/amazon/","text":"AWS Services \u00b6 http4k-connect provides a standardised mechanism to connect to the following AWS services: CloudFront Cloudwatch Logs Cognito Container Credentials DynamoDB EventBridge Evidently Firehose IAM Identity Center Instance Metadata Service KMS Lambda S3 SecretsManager SES SNS SQS STS SystemsManager Auth \u00b6 Authing into AWS services is possible with a few different mechanisms based on the environmental variables passed to your app. Under the covers, there is a CredentialProvider implementation which is switchable depending on your use-case: Static AWS AccessKey/Secret authorisation uses: \u00b6 AWS_REGION AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_SESSION_TOKEN This is the default mechanism, so no special action is required: val sqs = SQS . Http () STS authorisation uses: \u00b6 AWS_REGION AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_SESSION_TOKEN This auth method uses the STS AssumeRole action to retrieve the rotating credentials from STS using auth from the environmental variables. This requires overriding the credentials provider used when constructing the adapter: val sqs = SQS . Http ( credentialsProvider = CredentialsProvider . STS ()) STS WebIdentity authorisation uses: \u00b6 AWS_ROLE_ARN AWS_WEB_IDENTITY_TOKEN_FILE This auth method uses the STS AssumeRoleWithWebIdentity action to retrieve the rotating credentials from STS using the Web Identity JWT from the file path contained in the env variable. This requires overriding the credentials provider used when constructing the adapter: val sqs = SQS . Http ( credentialsProvider = CredentialsProvider . STSWebIdentity ())","title":"AWS Services"},{"location":"reference/amazon/#aws_services","text":"http4k-connect provides a standardised mechanism to connect to the following AWS services: CloudFront Cloudwatch Logs Cognito Container Credentials DynamoDB EventBridge Evidently Firehose IAM Identity Center Instance Metadata Service KMS Lambda S3 SecretsManager SES SNS SQS STS SystemsManager","title":"AWS Services"},{"location":"reference/amazon/#auth","text":"Authing into AWS services is possible with a few different mechanisms based on the environmental variables passed to your app. Under the covers, there is a CredentialProvider implementation which is switchable depending on your use-case:","title":"Auth"},{"location":"reference/amazon/#static_aws_accesskeysecret_authorisation_uses","text":"AWS_REGION AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_SESSION_TOKEN This is the default mechanism, so no special action is required: val sqs = SQS . Http ()","title":"Static AWS AccessKey/Secret authorisation uses:"},{"location":"reference/amazon/#sts_authorisation_uses","text":"AWS_REGION AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_SESSION_TOKEN This auth method uses the STS AssumeRole action to retrieve the rotating credentials from STS using auth from the environmental variables. This requires overriding the credentials provider used when constructing the adapter: val sqs = SQS . Http ( credentialsProvider = CredentialsProvider . STS ())","title":"STS authorisation uses:"},{"location":"reference/amazon/#sts_webidentity_authorisation_uses","text":"AWS_ROLE_ARN AWS_WEB_IDENTITY_TOKEN_FILE This auth method uses the STS AssumeRoleWithWebIdentity action to retrieve the rotating credentials from STS using the Web Identity JWT from the file path contained in the env variable. This requires overriding the credentials provider used when constructing the adapter: val sqs = SQS . Http ( credentialsProvider = CredentialsProvider . STSWebIdentity ())","title":"STS WebIdentity authorisation uses:"},{"location":"reference/amazon/apprunner/","text":"AppRunner \u00b6 The AppRunner connector provides the following Actions: * CreateService * DeleteService * ListServices Example usage \u00b6 const val USE_REAL_CLIENT = false fun main () { val deployedLambda = FunctionName ( \"http4kLambda\" ) val fakeAppRunner = FakeAppRunner ( ) // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else fakeAppRunner // create a client val client = AppRunner . Http ( Region . of ( \"us-east-1\" ), { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) // all operations return a Result monad of the API type println ( client . listServices ()) } The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor. Default Fake port: 62628 \u00b6 To start: FakeAppRunner().start()","title":"App Runner"},{"location":"reference/amazon/apprunner/#apprunner","text":"The AppRunner connector provides the following Actions: * CreateService * DeleteService * ListServices","title":"AppRunner"},{"location":"reference/amazon/apprunner/#example_usage","text":"const val USE_REAL_CLIENT = false fun main () { val deployedLambda = FunctionName ( \"http4kLambda\" ) val fakeAppRunner = FakeAppRunner ( ) // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else fakeAppRunner // create a client val client = AppRunner . Http ( Region . of ( \"us-east-1\" ), { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) // all operations return a Result monad of the API type println ( client . listServices ()) } The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor.","title":"Example usage"},{"location":"reference/amazon/apprunner/#default_fake_port_62628","text":"To start: FakeAppRunner().start()","title":"Default Fake port: 62628"},{"location":"reference/amazon/cloudfront/","text":"CloudFront \u00b6 The CloudFront connector provides the following Actions: * CreateInvalidation The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor. Example usage \u00b6 const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeCloudFront () // create a client val client = CloudFront . Http ({ AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) // all operations return a Result monad of the API type val result : Result < Unit , RemoteFailure > = client . createInvalidation ( DistributionId . of ( \"a-distribution-id\" ), listOf ( \"/path\" ), 1 , random ()) } Default Fake port: 15420 \u00b6 To start: FakeCloudFront().start()","title":"Cloudfront"},{"location":"reference/amazon/cloudfront/#cloudfront","text":"The CloudFront connector provides the following Actions: * CreateInvalidation The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor.","title":"CloudFront"},{"location":"reference/amazon/cloudfront/#example_usage","text":"const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeCloudFront () // create a client val client = CloudFront . Http ({ AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) // all operations return a Result monad of the API type val result : Result < Unit , RemoteFailure > = client . createInvalidation ( DistributionId . of ( \"a-distribution-id\" ), listOf ( \"/path\" ), 1 , random ()) }","title":"Example usage"},{"location":"reference/amazon/cloudfront/#default_fake_port_15420","text":"To start: FakeCloudFront().start()","title":"Default Fake port: 15420"},{"location":"reference/amazon/cloudwatchlogs/","text":"CloudWatchLogs \u00b6 The CloudWatchLogs connector provides the following Actions: CreateLogGroup CreateLogStream DeleteLogGroup DeleteLogStream FilterLogEvents PutLogEvents The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor. Example usage \u00b6 const val USE_REAL_CLIENT = false val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeCloudWatchLogs () // creatxe a client val cloudWatchLogs = CloudWatchLogs . Http ( Region . US_EAST_1 , { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) val result : Result < PutLogEventsResponse , RemoteFailure > = cloudWatchLogs . putLogEvents ( LogGroupName . of ( \"foobar\" ), LogStreamName . of ( \"stream\" ), emptyList () ) println ( result ) Default Fake port: 56514 \u00b6 To start: FakeCloudWatchLogs().start()","title":"Cloudwatch Logs"},{"location":"reference/amazon/cloudwatchlogs/#cloudwatchlogs","text":"The CloudWatchLogs connector provides the following Actions: CreateLogGroup CreateLogStream DeleteLogGroup DeleteLogStream FilterLogEvents PutLogEvents The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor.","title":"CloudWatchLogs"},{"location":"reference/amazon/cloudwatchlogs/#example_usage","text":"const val USE_REAL_CLIENT = false val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeCloudWatchLogs () // creatxe a client val cloudWatchLogs = CloudWatchLogs . Http ( Region . US_EAST_1 , { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) val result : Result < PutLogEventsResponse , RemoteFailure > = cloudWatchLogs . putLogEvents ( LogGroupName . of ( \"foobar\" ), LogStreamName . of ( \"stream\" ), emptyList () ) println ( result )","title":"Example usage"},{"location":"reference/amazon/cloudwatchlogs/#default_fake_port_56514","text":"To start: FakeCloudWatchLogs().start()","title":"Default Fake port: 56514"},{"location":"reference/amazon/cognito/","text":"Cognito \u00b6 The Cognito connector provides the following Actions: AdminCreateUser AdminDeleteUser AdminDisableUser AdminEnableUser AdminGetUser AdminResetUserPassword AdminSetUserPassword AssociateSoftwareToken ConfirmForgotPassword CreateResourceServer CreateUserPool CreateUserPoolClient CreateUserPoolDomain DeleteUserPool DeleteUserPoolClient DeleteUserPoolDomain ForgotPassword GetJwks ListUserPools InitiateAuth RespondToAuthChallenge VerifySoftwareToken # Fake \u00b6 The Cognito Fake has very limited functionality for creating User Pools and User Pool Clients only. It can act as an OAuthServer for created User Pool Clients. It supports the ClientCredentials and Authorization Code grants and returns JWTs which have been signed with a private key. The matching public key can be retrieved from the following endpoint: http://<server:port>/<user pool id>/.well-known/jwks.json Note that there are 2 keys returned by the JWKs endpoint - the first is \"expired\" and not used, the second is the one used to sign the JWTs. Default Fake port: 37192 \u00b6 To start: FakeCloudFront().start()","title":"Cognito"},{"location":"reference/amazon/cognito/#cognito","text":"The Cognito connector provides the following Actions: AdminCreateUser AdminDeleteUser AdminDisableUser AdminEnableUser AdminGetUser AdminResetUserPassword AdminSetUserPassword AssociateSoftwareToken ConfirmForgotPassword CreateResourceServer CreateUserPool CreateUserPoolClient CreateUserPoolDomain DeleteUserPool DeleteUserPoolClient DeleteUserPoolDomain ForgotPassword GetJwks ListUserPools InitiateAuth RespondToAuthChallenge VerifySoftwareToken","title":"Cognito"},{"location":"reference/amazon/cognito/#fake","text":"The Cognito Fake has very limited functionality for creating User Pools and User Pool Clients only. It can act as an OAuthServer for created User Pool Clients. It supports the ClientCredentials and Authorization Code grants and returns JWTs which have been signed with a private key. The matching public key can be retrieved from the following endpoint: http://<server:port>/<user pool id>/.well-known/jwks.json Note that there are 2 keys returned by the JWKs endpoint - the first is \"expired\" and not used, the second is the one used to sign the JWTs.","title":"# Fake"},{"location":"reference/amazon/cognito/#default_fake_port_37192","text":"To start: FakeCloudFront().start()","title":"Default Fake port: 37192"},{"location":"reference/amazon/containercredentials/","text":"Container Credentials \u00b6 The Container Credentials connector provides the following Actions: * GetCredentials The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor. Default Fake port: 63556 \u00b6 To start: FakeContainerCredentials().start()","title":"Container Credentials"},{"location":"reference/amazon/containercredentials/#container_credentials","text":"The Container Credentials connector provides the following Actions: * GetCredentials The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor.","title":"Container Credentials"},{"location":"reference/amazon/containercredentials/#default_fake_port_63556","text":"To start: FakeContainerCredentials().start()","title":"Default Fake port: 63556"},{"location":"reference/amazon/dynamodb/","text":"DynamoDb \u00b6 The DynamoDb connector provides the following Actions: * CreateTable * DeleteTable * DescribeTable * ListTables * UpdateTable * DeleteItem * GetItem * PutItem * Query * Scan * UpdateItem * TransactGetItems * TransactWriteItems * BatchGetItem * BatchWriteItem * ExecuteTransaction * ExecuteStatement * BatchExecuteStatement Note that the FakeDynamo supports the majority of the Dynamo operations with the following exceptions. You can use DynamoDB local instead to provide these functions: * BatchExecuteStatement * ExecuteStatement * ExecuteTransaction The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor. Typesafe Items & Keys \u00b6 Most of the http4k-connect DynamoDb API is fairly simple, but one addition which may warrant further explanation is the http4k Lens system which is layered on top provide a typesafe API to the Item/Key objects (used for getting/setting record attributes and for defining key structures). This is useful because of the unique way in which Dynamo handles the structure of the stored items. AttributeName - is just a data class for a named attribute in an item/key AttributeValue is the on-the-wire format of an attribute with it's requisite type. Examples of this are: { \"S\": \"hello\" } or { \"BOOL\": true } or { \"NS\": [\"123\"] } . Construction of these AttributeValues can be done using factory functions such as AttributeValue.Str(\"string\") . AttributeValues can be primitives (BOOL, S, N), Sets (NS, BS), or collections of other AttributeValues (L, M). Item and Key are just typealiases for Map<AttributeName, AttributeValue> . They have convenience construction methods Item() and Key() . These are sent to and returned in the messages between a client and DynamoDb. When constructing Actions or deconstructing their responses for Items/Keys, we can populate or interrogate the Map returned manually, but we may be unsure of the types. To that end, the http4k Lens system has been used to create a typesafe binding between the names and types of the AttributeValues. This system supports all of types available in the Dynamo type system, and also provides mapping for both common JDK types (including popular Java Datetime types) and required/optional attributes (ie. String vs String? ). Typesafe lens-based Dynamo Object Mapper \u00b6 Using the lens system and http4k automapping facilities, http4k-connect also supports dynamic flattening of objects into the DynamoDB schema with zero boilerplate. Simply create a lens and apply it to your object to inject values into the DynamoDB Item. the structure of maps and lists are preserved by collapsing them into a single DynamoDB field. This is implemented as a standard extension function on any of the http4k automarshalling object mappers (Jackson, Moshi, GSON etc..): data class AnObject(val str: String, val num: Int) val input = AnObject(\"foobar\", 123) val lens = Moshi.autoDynamoLens <AnObject> () val item: Item = Item().with(lens of input) val extracted: AnObject = lens(item) Example \u00b6 Given that a record in Dynamo will have many typed values, we first define a set of attributes which are relevant for the case in question. These methods construct Lenses which can be used to inject or extract typed values safely: val attrS = Attribute . string (). optional ( \"theNull\" ) val attrBool = Attribute . boolean (). required ( \"theBool\" ) val attrN = Attribute . int (). optional ( \"theNum\" ) val attrI = Attribute . instant (). required ( \"theInstant\" ) val attrM = Attribute . map (). required ( \"theMap\" ) To construct an Item or Key to send to Dynamo, we can bind the values at the same time: val item = Item ( attrS of \"hello\" , attrN of null , attrM of Item ( attrI of Instant . now ()) ) To deconstruct an Item or Key to send to Dynamo, we simply apply the attributes as functions to the container: val string : String? = attrS ( item ) val boolean : Boolean = attrBool ( item ) val instant : Instant = attrI ( attrM ( item )) On missing or invalid value, an exception is thrown. To counter this we can use the built in Result4k monad marshalling: val boolean : Result < Boolean , LensFailure > = attrBool . asResult ()( item ) It is also possible to map() lenses to provide marshalling into your own types. Null handling and sparse indexes \u00b6 The default mapping for null values of manually mapped optional attributes in DynamoDB will assign them to an explicit null attribute: val attrS = Attribute . string (). optional ( \"optS\" ) val item = Item ( attrS of null ) // item now contains \"optS\": { \"NULL\": true } When utilizing an optional attribute as a key in a secondary index (creating a sparse index), the attribute must be absent rather than null. To achieve this, set ignoreNull to true in the attribute definition. val attrS = Attribute . string (). optional ( \"optS\" , ignoreNull = true ) When incorporating this attribute into the secondary index schema, it is necessary to convert it into a mandatory (non-optional) attribute. // attrS is of type Attribute<String?> attrS . asRequired () // will be of type Attribute<String> Note: null properties of automapped objects (using autoDynamoLens() ) will be ignored by default. DynamoDB Table Repository \u00b6 A simplified API for mapping documents to and from a single table with get , put , scan , query , etc. private const val USE_REAL_CLIENT = false // define our data class private data class Person ( val name : String , val id : UUID = UUID . randomUUID () ) private val john = Person ( \"John\" ) private val jane = Person ( \"Jane\" ) fun main () { // build client (real or fake) val http = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeDynamoDb () val dynamoDb = DynamoDb . Http ( Region . CA_CENTRAL_1 , { AwsCredentials ( \"id\" , \"secret\" ) }, http . debug ()) // defined table mapper val table = dynamoDb . tableMapper < Person , UUID , Unit > ( tableName = TableName . of ( \"people\" ), hashKeyAttribute = Attribute . uuid (). required ( \"id\" ) ) // create table table . createTable () // save table . save ( john ) table . save ( jane ) // get val johnAgain = table . get ( john . id ) // scan val people = table . primaryIndex (). scan (). take ( 10 ) // delete table . delete ( john ) } See another example with secondary indices. Complex scan or query expressions may be constructed using functions from the KeyConditionBuilder and FilterExpressionBuilder classes (which therefore provide a scan/query DSL). This DSL is not complete, however it should cover most of the common use cases. Examples: val idAttr = Attribute . uuid (). required ( \"id\" ) val nameAttr = Attribute . string (). required ( \"name\" ) // scan with filter val people = table . primaryIndex (). scan { filterExpression { ( nameAttr beginsWith \"J\" ) and not ( nameAttr eq \"Jimmy\" ) } } // query with key condition (doesn't actually make much sense is this example) val anotherJohn = table . primaryIndex (). query { keyCondition { hashKey eq john . id } } General query pattern with combined key condition and filter expression table . primaryIndex (). query { keyCondition { ( hashKey eq hashValue ) and ( sortKey gt sortValue ) } filterExpression { ( fooAttr ne \"foo\" ) or ( barAttr isIn listOf ( 5 , 6 , 7 )) and ( bazAttr lt quzAttr ) } } Notes: - hashKey and sortKey are special identifiers to be used in the keyCondition that represent the actual key attributes of the current index - the hash key condition must use the eq operator (no other operators allowed), - in the sort key condition the following operators are supported: eq gt , ge , lt , le (for = , > , >= , < , <= ), beginsWith , and the sortKey.between(val1, val2) function - in the filter expression concrete attributes must be used instead of hashKey or sortKey - the filter expression supports all of the above operators plus ne ( <> ), isIn , contains , attributeExists(attr) , and attributeNotExists(attr) - in a filter expression the first operand in a comparison must be an attribute, the second operand is either a value or another attribute of the same type (so xAttr eq 42 and xAttr ne yAttr are supported, but 42 eq xAttr is not) - the logical operators and and or in this DSL are always evaluated from left to right (i.e. there is no higher precedence for and ), you should use parenthesis to change the order of evaluation - if an operand of a logical operator is null it will simply be omitted. This allows building queries with optional conditions: filterExpression { val nameFilter = name ?. let { nameAttr eq it } val sizeFilter = size ?. let { sizeAttr eq it } // results in either a filter for name, a filter for size, a filter for both, or in no filter at all nameFilter and sizeFilter } General example usage of API client \u00b6 // we can connect to the real service val http : HttpHandler = JavaHttpClient () // create a client val client = DynamoDb . Http ( Region . of ( \"us-east-1\" ), { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) val table = TableName . of ( \"myTable\" ) // we can bind values to the attributes client . putItem ( table , Item = mapOf ( attrS to \"foobar\" , attrBool to true , attrB to Base64Blob . encode ( \"foo\" ), attrBS to setOf ( Base64Blob . encode ( \"bar\" )), attrN to 123 , attrNS to setOf ( 123 , 12.34 ), attrL to listOf ( List ( listOf ( AttributeValue . Str ( \"foo\" ))), Num ( 123 ), Null () ), attrM to mapOf ( attrS to \"foo\" , attrBool to false ), attrSS to setOf ( \"345\" , \"567\" ), attrNL to null ) ) // lookup an item from the database val item = client . getItem ( table , key = mapOf ( attrS to \"hello\" )). valueOrNull () !! . item !! val str : String? = attrS ( item ) // all operations return a Result monad of the API type val deleteResult : Result < TableDescriptionResponse , RemoteFailure > = client . deleteTable ( table ) println ( deleteResult )","title":"DynamoDB"},{"location":"reference/amazon/dynamodb/#dynamodb","text":"The DynamoDb connector provides the following Actions: * CreateTable * DeleteTable * DescribeTable * ListTables * UpdateTable * DeleteItem * GetItem * PutItem * Query * Scan * UpdateItem * TransactGetItems * TransactWriteItems * BatchGetItem * BatchWriteItem * ExecuteTransaction * ExecuteStatement * BatchExecuteStatement Note that the FakeDynamo supports the majority of the Dynamo operations with the following exceptions. You can use DynamoDB local instead to provide these functions: * BatchExecuteStatement * ExecuteStatement * ExecuteTransaction The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor.","title":"DynamoDb"},{"location":"reference/amazon/dynamodb/#typesafe_items_keys","text":"Most of the http4k-connect DynamoDb API is fairly simple, but one addition which may warrant further explanation is the http4k Lens system which is layered on top provide a typesafe API to the Item/Key objects (used for getting/setting record attributes and for defining key structures). This is useful because of the unique way in which Dynamo handles the structure of the stored items. AttributeName - is just a data class for a named attribute in an item/key AttributeValue is the on-the-wire format of an attribute with it's requisite type. Examples of this are: { \"S\": \"hello\" } or { \"BOOL\": true } or { \"NS\": [\"123\"] } . Construction of these AttributeValues can be done using factory functions such as AttributeValue.Str(\"string\") . AttributeValues can be primitives (BOOL, S, N), Sets (NS, BS), or collections of other AttributeValues (L, M). Item and Key are just typealiases for Map<AttributeName, AttributeValue> . They have convenience construction methods Item() and Key() . These are sent to and returned in the messages between a client and DynamoDb. When constructing Actions or deconstructing their responses for Items/Keys, we can populate or interrogate the Map returned manually, but we may be unsure of the types. To that end, the http4k Lens system has been used to create a typesafe binding between the names and types of the AttributeValues. This system supports all of types available in the Dynamo type system, and also provides mapping for both common JDK types (including popular Java Datetime types) and required/optional attributes (ie. String vs String? ).","title":"Typesafe Items &amp; Keys"},{"location":"reference/amazon/dynamodb/#typesafe_lens-based_dynamo_object_mapper","text":"Using the lens system and http4k automapping facilities, http4k-connect also supports dynamic flattening of objects into the DynamoDB schema with zero boilerplate. Simply create a lens and apply it to your object to inject values into the DynamoDB Item. the structure of maps and lists are preserved by collapsing them into a single DynamoDB field. This is implemented as a standard extension function on any of the http4k automarshalling object mappers (Jackson, Moshi, GSON etc..): data class AnObject(val str: String, val num: Int) val input = AnObject(\"foobar\", 123) val lens = Moshi.autoDynamoLens <AnObject> () val item: Item = Item().with(lens of input) val extracted: AnObject = lens(item)","title":"Typesafe lens-based Dynamo Object Mapper"},{"location":"reference/amazon/dynamodb/#example","text":"Given that a record in Dynamo will have many typed values, we first define a set of attributes which are relevant for the case in question. These methods construct Lenses which can be used to inject or extract typed values safely: val attrS = Attribute . string (). optional ( \"theNull\" ) val attrBool = Attribute . boolean (). required ( \"theBool\" ) val attrN = Attribute . int (). optional ( \"theNum\" ) val attrI = Attribute . instant (). required ( \"theInstant\" ) val attrM = Attribute . map (). required ( \"theMap\" ) To construct an Item or Key to send to Dynamo, we can bind the values at the same time: val item = Item ( attrS of \"hello\" , attrN of null , attrM of Item ( attrI of Instant . now ()) ) To deconstruct an Item or Key to send to Dynamo, we simply apply the attributes as functions to the container: val string : String? = attrS ( item ) val boolean : Boolean = attrBool ( item ) val instant : Instant = attrI ( attrM ( item )) On missing or invalid value, an exception is thrown. To counter this we can use the built in Result4k monad marshalling: val boolean : Result < Boolean , LensFailure > = attrBool . asResult ()( item ) It is also possible to map() lenses to provide marshalling into your own types.","title":"Example"},{"location":"reference/amazon/dynamodb/#null_handling_and_sparse_indexes","text":"The default mapping for null values of manually mapped optional attributes in DynamoDB will assign them to an explicit null attribute: val attrS = Attribute . string (). optional ( \"optS\" ) val item = Item ( attrS of null ) // item now contains \"optS\": { \"NULL\": true } When utilizing an optional attribute as a key in a secondary index (creating a sparse index), the attribute must be absent rather than null. To achieve this, set ignoreNull to true in the attribute definition. val attrS = Attribute . string (). optional ( \"optS\" , ignoreNull = true ) When incorporating this attribute into the secondary index schema, it is necessary to convert it into a mandatory (non-optional) attribute. // attrS is of type Attribute<String?> attrS . asRequired () // will be of type Attribute<String> Note: null properties of automapped objects (using autoDynamoLens() ) will be ignored by default.","title":"Null handling and sparse indexes"},{"location":"reference/amazon/dynamodb/#dynamodb_table_repository","text":"A simplified API for mapping documents to and from a single table with get , put , scan , query , etc. private const val USE_REAL_CLIENT = false // define our data class private data class Person ( val name : String , val id : UUID = UUID . randomUUID () ) private val john = Person ( \"John\" ) private val jane = Person ( \"Jane\" ) fun main () { // build client (real or fake) val http = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeDynamoDb () val dynamoDb = DynamoDb . Http ( Region . CA_CENTRAL_1 , { AwsCredentials ( \"id\" , \"secret\" ) }, http . debug ()) // defined table mapper val table = dynamoDb . tableMapper < Person , UUID , Unit > ( tableName = TableName . of ( \"people\" ), hashKeyAttribute = Attribute . uuid (). required ( \"id\" ) ) // create table table . createTable () // save table . save ( john ) table . save ( jane ) // get val johnAgain = table . get ( john . id ) // scan val people = table . primaryIndex (). scan (). take ( 10 ) // delete table . delete ( john ) } See another example with secondary indices. Complex scan or query expressions may be constructed using functions from the KeyConditionBuilder and FilterExpressionBuilder classes (which therefore provide a scan/query DSL). This DSL is not complete, however it should cover most of the common use cases. Examples: val idAttr = Attribute . uuid (). required ( \"id\" ) val nameAttr = Attribute . string (). required ( \"name\" ) // scan with filter val people = table . primaryIndex (). scan { filterExpression { ( nameAttr beginsWith \"J\" ) and not ( nameAttr eq \"Jimmy\" ) } } // query with key condition (doesn't actually make much sense is this example) val anotherJohn = table . primaryIndex (). query { keyCondition { hashKey eq john . id } } General query pattern with combined key condition and filter expression table . primaryIndex (). query { keyCondition { ( hashKey eq hashValue ) and ( sortKey gt sortValue ) } filterExpression { ( fooAttr ne \"foo\" ) or ( barAttr isIn listOf ( 5 , 6 , 7 )) and ( bazAttr lt quzAttr ) } } Notes: - hashKey and sortKey are special identifiers to be used in the keyCondition that represent the actual key attributes of the current index - the hash key condition must use the eq operator (no other operators allowed), - in the sort key condition the following operators are supported: eq gt , ge , lt , le (for = , > , >= , < , <= ), beginsWith , and the sortKey.between(val1, val2) function - in the filter expression concrete attributes must be used instead of hashKey or sortKey - the filter expression supports all of the above operators plus ne ( <> ), isIn , contains , attributeExists(attr) , and attributeNotExists(attr) - in a filter expression the first operand in a comparison must be an attribute, the second operand is either a value or another attribute of the same type (so xAttr eq 42 and xAttr ne yAttr are supported, but 42 eq xAttr is not) - the logical operators and and or in this DSL are always evaluated from left to right (i.e. there is no higher precedence for and ), you should use parenthesis to change the order of evaluation - if an operand of a logical operator is null it will simply be omitted. This allows building queries with optional conditions: filterExpression { val nameFilter = name ?. let { nameAttr eq it } val sizeFilter = size ?. let { sizeAttr eq it } // results in either a filter for name, a filter for size, a filter for both, or in no filter at all nameFilter and sizeFilter }","title":"DynamoDB Table Repository"},{"location":"reference/amazon/dynamodb/#general_example_usage_of_api_client","text":"// we can connect to the real service val http : HttpHandler = JavaHttpClient () // create a client val client = DynamoDb . Http ( Region . of ( \"us-east-1\" ), { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) val table = TableName . of ( \"myTable\" ) // we can bind values to the attributes client . putItem ( table , Item = mapOf ( attrS to \"foobar\" , attrBool to true , attrB to Base64Blob . encode ( \"foo\" ), attrBS to setOf ( Base64Blob . encode ( \"bar\" )), attrN to 123 , attrNS to setOf ( 123 , 12.34 ), attrL to listOf ( List ( listOf ( AttributeValue . Str ( \"foo\" ))), Num ( 123 ), Null () ), attrM to mapOf ( attrS to \"foo\" , attrBool to false ), attrSS to setOf ( \"345\" , \"567\" ), attrNL to null ) ) // lookup an item from the database val item = client . getItem ( table , key = mapOf ( attrS to \"hello\" )). valueOrNull () !! . item !! val str : String? = attrS ( item ) // all operations return a Result monad of the API type val deleteResult : Result < TableDescriptionResponse , RemoteFailure > = client . deleteTable ( table ) println ( deleteResult )","title":"General example usage of API client"},{"location":"reference/amazon/eventbridge/","text":"EventBridge \u00b6 The EventBridge connector provides the following Actions: * CreateEventBus * DeleteEventBus * DescribeEventBus * PutEvents Example usage \u00b6 The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor. Default Fake port: 13577 \u00b6 To start: FakeEventBridge().start()","title":"EventBridge"},{"location":"reference/amazon/eventbridge/#eventbridge","text":"The EventBridge connector provides the following Actions: * CreateEventBus * DeleteEventBus * DescribeEventBus * PutEvents","title":"EventBridge"},{"location":"reference/amazon/eventbridge/#example_usage","text":"The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor.","title":"Example usage"},{"location":"reference/amazon/eventbridge/#default_fake_port_13577","text":"To start: FakeEventBridge().start()","title":"Default Fake port: 13577"},{"location":"reference/amazon/evidently/","text":"Cloudwatch Evidently \u00b6 The Evidently connector provides the following Actions: * CreateProject * CreateFeature * EvaluateFeature * BatchEvaluateFeature * DeleteFeature * DeleteProject Example usage \u00b6 const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeEvidently () // create a client val client = Evidently . Http ( Region . of ( \"us-east-1\" ), { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) val projectName = ProjectName . of ( \"acme-service\" ) val featureName = FeatureName . of ( \"take-over-the-world\" ) // create project client . createProject ( projectName ) . onFailure { it . reason . throwIt () } // create feature client . createFeature ( project = projectName , name = featureName , defaultVariation = VariationName . of ( \"bide-our-time\" ), variations = mapOf ( VariationName . of ( \"bide-our-time\" ) to VariableValue ( false ), VariationName . of ( \"it-is-time\" ) to VariableValue ( true ) ), entityOverrides = mapOf ( EntityId . of ( \"test-subject-1\" ) to VariationName . of ( \"it-is-time\" ) ) ). onFailure { it . reason . throwIt () } // evaluate feature val result = client . evaluateFeature ( projectName , featureName , EntityId . of ( \"test-subject-2\" )) . onFailure { it . reason . throwIt () } println ( result ) } The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor. Default Fake port: 45011 \u00b6 To start: FakeEvidently().start()","title":"Evidently"},{"location":"reference/amazon/evidently/#cloudwatch_evidently","text":"The Evidently connector provides the following Actions: * CreateProject * CreateFeature * EvaluateFeature * BatchEvaluateFeature * DeleteFeature * DeleteProject","title":"Cloudwatch Evidently"},{"location":"reference/amazon/evidently/#example_usage","text":"const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeEvidently () // create a client val client = Evidently . Http ( Region . of ( \"us-east-1\" ), { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) val projectName = ProjectName . of ( \"acme-service\" ) val featureName = FeatureName . of ( \"take-over-the-world\" ) // create project client . createProject ( projectName ) . onFailure { it . reason . throwIt () } // create feature client . createFeature ( project = projectName , name = featureName , defaultVariation = VariationName . of ( \"bide-our-time\" ), variations = mapOf ( VariationName . of ( \"bide-our-time\" ) to VariableValue ( false ), VariationName . of ( \"it-is-time\" ) to VariableValue ( true ) ), entityOverrides = mapOf ( EntityId . of ( \"test-subject-1\" ) to VariationName . of ( \"it-is-time\" ) ) ). onFailure { it . reason . throwIt () } // evaluate feature val result = client . evaluateFeature ( projectName , featureName , EntityId . of ( \"test-subject-2\" )) . onFailure { it . reason . throwIt () } println ( result ) } The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor.","title":"Example usage"},{"location":"reference/amazon/evidently/#default_fake_port_45011","text":"To start: FakeEvidently().start()","title":"Default Fake port: 45011"},{"location":"reference/amazon/firehose/","text":"Firehose \u00b6 The Firehose connector provides the following Actions: * CreateDeliveryStream * DeleteDeliveryStream * ListDeliveryStreams * PutRecord * PutRecordBatch Example usage \u00b6 The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor. Default Fake port: 30879 \u00b6 To start: FakeFirehose().start()","title":"Firehose"},{"location":"reference/amazon/firehose/#firehose","text":"The Firehose connector provides the following Actions: * CreateDeliveryStream * DeleteDeliveryStream * ListDeliveryStreams * PutRecord * PutRecordBatch","title":"Firehose"},{"location":"reference/amazon/firehose/#example_usage","text":"The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor.","title":"Example usage"},{"location":"reference/amazon/firehose/#default_fake_port_30879","text":"To start: FakeFirehose().start()","title":"Default Fake port: 30879"},{"location":"reference/amazon/iamidentitycenter/","text":"IAM Identity Center \u00b6 The IAMIdentityCenter connector provides the following Fakes: OIDC \u00b6 Actions: * RegisterClient * StartDeviceAuthentication * CreateToken Default Fake port: 34160 \u00b6 To start: FakeOIDC().start() SSO \u00b6 Actions: * SSO: GetFederatedCredentials Default Fake port: 25813 \u00b6 To start: FakeSSO().start() Interactive CLI login \u00b6 The module provides a CredentialsProvider to do interactive login to val provider = CredentialsProvider . SSO ( SSOProfile ( AwsAccount . of ( \"01234567890\" ), RoleName . of ( \"hello\" ), Region . US_EAST_1 , Uri . of ( \"http://foobar\" ), ) )","title":"IAM Identity Center"},{"location":"reference/amazon/iamidentitycenter/#iam_identity_center","text":"The IAMIdentityCenter connector provides the following Fakes:","title":"IAM Identity Center"},{"location":"reference/amazon/iamidentitycenter/#oidc","text":"Actions: * RegisterClient * StartDeviceAuthentication * CreateToken","title":"OIDC"},{"location":"reference/amazon/iamidentitycenter/#default_fake_port_34160","text":"To start: FakeOIDC().start()","title":"Default Fake port: 34160"},{"location":"reference/amazon/iamidentitycenter/#sso","text":"Actions: * SSO: GetFederatedCredentials","title":"SSO"},{"location":"reference/amazon/iamidentitycenter/#default_fake_port_25813","text":"To start: FakeSSO().start()","title":"Default Fake port: 25813"},{"location":"reference/amazon/iamidentitycenter/#interactive_cli_login","text":"The module provides a CredentialsProvider to do interactive login to val provider = CredentialsProvider . SSO ( SSOProfile ( AwsAccount . of ( \"01234567890\" ), RoleName . of ( \"hello\" ), Region . US_EAST_1 , Uri . of ( \"http://foobar\" ), ) )","title":"Interactive CLI login"},{"location":"reference/amazon/instancemetadata/","text":"Instance Metadata Service \u00b6 The Instance Metadata Service V1 connector provides the following Actions: * GetAmiId * GetHostName * GetInstanceIdentityDocument * GetInstanceType * GetLocalHostName * GetLocalIpv4 * GetPublicHostName * GetPublicIpv4 * GetSecurityCredentials * ListSecurityCredentials Example usage \u00b6 const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeInstanceMetadataService () // create a client val client = InstanceMetadataService . Http ( http . debug ()) // get local ip address val localIp = client . getLocalIpv4 () println ( localIp ) // get identity document val identityDocument = client . getInstanceIdentityDocument () println ( identityDocument ) } Credentials Provider \u00b6 The Instance Metadata Service also offers a CredentialsProvider . If the application is running inside an Amazon EC2 environment, this provider can authorize AWS requests using credentials from the instance profile. fun main () { // build a credentials provider that will attempt to load AWS credentials from the EC2's instance profile val credentialsProvider = CredentialsProvider . Ec2InstanceProfile () // build a client that will authorize requests with the instance profile credentials val sns = SNS . Http ( Region . US_EAST_1 , credentialsProvider ) // send a request val topics = sns . listTopics () println ( topics ) } :warning: The Ec2InstanceProfile provider should always be last in the chain, since it will time out if not in an Amazon EC2 environment. Region Provider \u00b6 The Instance Metadata Service also offers a RegionProvider . If the application is running inside an Amazon EC2 environment, this provider can detect the current AWS region. fun main () { // we can connect to the real service or the fake (drop in replacement) val imdsHttp : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeInstanceMetadataService () val snsHttp : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeSNS () /* * Build a RegionProvider chain with the following steps: * 1. Try to get region from AWS_REGION environment variable * 2. Try to get region from profile credentials file * 3. Try to get region from EC2 Instance Metadata Service */ val regionProviderChain = RegionProvider . Environment ( Environment . ENV ) orElse RegionProvider . Profile ( Environment . ENV ) orElse RegionProvider . Ec2InstanceProfile ( imdsHttp ) // Invoking the chain will return a region if one was found val optionalRegion : Region? = regionProviderChain () println ( optionalRegion ) // orElseThrow will return a region or throw an exception if onr was not found val region : Region = regionProviderChain . orElseThrow () println ( region ) // create and use an Amazon client with the resolved region val sns = SNS . Http ( region , { fakeAwsCredentials }, snsHttp ) val topics = sns . listTopics () println ( topics ) } :warning: The Ec2InstanceProfile provider should always be last in the chain, since it will time out if not in an Amazon EC2 environment. Default Fake port: 63407 \u00b6 To start: FakeInstanceMetadataService().start()","title":"Instance Metadata"},{"location":"reference/amazon/instancemetadata/#instance_metadata_service","text":"The Instance Metadata Service V1 connector provides the following Actions: * GetAmiId * GetHostName * GetInstanceIdentityDocument * GetInstanceType * GetLocalHostName * GetLocalIpv4 * GetPublicHostName * GetPublicIpv4 * GetSecurityCredentials * ListSecurityCredentials","title":"Instance Metadata Service"},{"location":"reference/amazon/instancemetadata/#example_usage","text":"const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeInstanceMetadataService () // create a client val client = InstanceMetadataService . Http ( http . debug ()) // get local ip address val localIp = client . getLocalIpv4 () println ( localIp ) // get identity document val identityDocument = client . getInstanceIdentityDocument () println ( identityDocument ) }","title":"Example usage"},{"location":"reference/amazon/instancemetadata/#credentials_provider","text":"The Instance Metadata Service also offers a CredentialsProvider . If the application is running inside an Amazon EC2 environment, this provider can authorize AWS requests using credentials from the instance profile. fun main () { // build a credentials provider that will attempt to load AWS credentials from the EC2's instance profile val credentialsProvider = CredentialsProvider . Ec2InstanceProfile () // build a client that will authorize requests with the instance profile credentials val sns = SNS . Http ( Region . US_EAST_1 , credentialsProvider ) // send a request val topics = sns . listTopics () println ( topics ) } :warning: The Ec2InstanceProfile provider should always be last in the chain, since it will time out if not in an Amazon EC2 environment.","title":"Credentials Provider"},{"location":"reference/amazon/instancemetadata/#region_provider","text":"The Instance Metadata Service also offers a RegionProvider . If the application is running inside an Amazon EC2 environment, this provider can detect the current AWS region. fun main () { // we can connect to the real service or the fake (drop in replacement) val imdsHttp : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeInstanceMetadataService () val snsHttp : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeSNS () /* * Build a RegionProvider chain with the following steps: * 1. Try to get region from AWS_REGION environment variable * 2. Try to get region from profile credentials file * 3. Try to get region from EC2 Instance Metadata Service */ val regionProviderChain = RegionProvider . Environment ( Environment . ENV ) orElse RegionProvider . Profile ( Environment . ENV ) orElse RegionProvider . Ec2InstanceProfile ( imdsHttp ) // Invoking the chain will return a region if one was found val optionalRegion : Region? = regionProviderChain () println ( optionalRegion ) // orElseThrow will return a region or throw an exception if onr was not found val region : Region = regionProviderChain . orElseThrow () println ( region ) // create and use an Amazon client with the resolved region val sns = SNS . Http ( region , { fakeAwsCredentials }, snsHttp ) val topics = sns . listTopics () println ( topics ) } :warning: The Ec2InstanceProfile provider should always be last in the chain, since it will time out if not in an Amazon EC2 environment.","title":"Region Provider"},{"location":"reference/amazon/instancemetadata/#default_fake_port_63407","text":"To start: FakeInstanceMetadataService().start()","title":"Default Fake port: 63407"},{"location":"reference/amazon/kms/","text":"KMS \u00b6 The KMS connector provides the following Actions: * CreateKey * DescribeKey * Decrypt * Encrypt * GetPublicKey * ListKeys * ScheduleKeyDeletion * Sign * Verify Example usage \u00b6 const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeKMS () // create a client val client = KMS . Http ( Region . of ( \"us-east-1\" ), { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) // all operations return a Result monad of the API type val createdKeyResult : Result < KeyCreated , RemoteFailure > = client . createKey ( ECC_NIST_P384 , ENCRYPT_DECRYPT ) val key : KeyCreated = createdKeyResult . valueOrNull () !! println ( key ) // we can encrypt some text... val encrypted : Encrypted = client . encrypt ( keyId = key . KeyMetadata . KeyId , Base64Blob . encoded ( \"hello\" )) . valueOrNull () !! println ( encrypted . CiphertextBlob . decoded ()) // and decrypt it again! val decrypted : Decrypted = client . decrypt ( keyId = key . KeyMetadata . KeyId , encrypted . CiphertextBlob ). valueOrNull () !! println ( decrypted . Plaintext . decoded ()) } The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor. The FakeKMS implementation currently does not properly encrypt/decrypt or sign/verify the contents of messages - it uses a trivially simple (and fast) reversible algorithm which simulates this functionality. Default Fake port: 45302 \u00b6 To start: FakeKMS().start()","title":"KMS"},{"location":"reference/amazon/kms/#kms","text":"The KMS connector provides the following Actions: * CreateKey * DescribeKey * Decrypt * Encrypt * GetPublicKey * ListKeys * ScheduleKeyDeletion * Sign * Verify","title":"KMS"},{"location":"reference/amazon/kms/#example_usage","text":"const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeKMS () // create a client val client = KMS . Http ( Region . of ( \"us-east-1\" ), { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) // all operations return a Result monad of the API type val createdKeyResult : Result < KeyCreated , RemoteFailure > = client . createKey ( ECC_NIST_P384 , ENCRYPT_DECRYPT ) val key : KeyCreated = createdKeyResult . valueOrNull () !! println ( key ) // we can encrypt some text... val encrypted : Encrypted = client . encrypt ( keyId = key . KeyMetadata . KeyId , Base64Blob . encoded ( \"hello\" )) . valueOrNull () !! println ( encrypted . CiphertextBlob . decoded ()) // and decrypt it again! val decrypted : Decrypted = client . decrypt ( keyId = key . KeyMetadata . KeyId , encrypted . CiphertextBlob ). valueOrNull () !! println ( decrypted . Plaintext . decoded ()) } The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor. The FakeKMS implementation currently does not properly encrypt/decrypt or sign/verify the contents of messages - it uses a trivially simple (and fast) reversible algorithm which simulates this functionality.","title":"Example usage"},{"location":"reference/amazon/kms/#default_fake_port_45302","text":"To start: FakeKMS().start()","title":"Default Fake port: 45302"},{"location":"reference/amazon/lambda/","text":"Lambda \u00b6 The Lambda connector provides the following Actions: * InvokeFunction Example usage \u00b6 const val USE_REAL_CLIENT = false fun main () { val deployedLambda = FunctionName ( \"http4kLambda\" ) val fakeLambda = FakeLambda ( deployedLambda to { req : Request -> val request = Moshi . asA < Req > ( req . bodyString ()) Response ( OK ) . body ( Moshi . asFormatString ( Resp ( request . value ))) } ) // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else fakeLambda // create a client val client = Lambda . Http ( Region . of ( \"us-east-1\" ), { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) // all operations return a Result monad of the API type val invokeResult : Result < Resp , RemoteFailure > = client . invokeFunction ( deployedLambda , Req ( \"hello\" ), Moshi ) println ( invokeResult ) } Note that the http4k-connect Fake Lambda implementation is designed to provide a runtime environment for function HttpHandlers that will be invoked directly using the Lambda URL pattern ( https://lambda.${scope.region}.amazonaws.com/2015-03-31/functions/$name/invocations ), rather than being deployed behind APIGateway (where you have total control over the URL pattern where the lambda can be invoked). The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor. Default Fake port: 50322 \u00b6 To start: FakeLambda().start()","title":"Lambda"},{"location":"reference/amazon/lambda/#lambda","text":"The Lambda connector provides the following Actions: * InvokeFunction","title":"Lambda"},{"location":"reference/amazon/lambda/#example_usage","text":"const val USE_REAL_CLIENT = false fun main () { val deployedLambda = FunctionName ( \"http4kLambda\" ) val fakeLambda = FakeLambda ( deployedLambda to { req : Request -> val request = Moshi . asA < Req > ( req . bodyString ()) Response ( OK ) . body ( Moshi . asFormatString ( Resp ( request . value ))) } ) // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else fakeLambda // create a client val client = Lambda . Http ( Region . of ( \"us-east-1\" ), { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) // all operations return a Result monad of the API type val invokeResult : Result < Resp , RemoteFailure > = client . invokeFunction ( deployedLambda , Req ( \"hello\" ), Moshi ) println ( invokeResult ) } Note that the http4k-connect Fake Lambda implementation is designed to provide a runtime environment for function HttpHandlers that will be invoked directly using the Lambda URL pattern ( https://lambda.${scope.region}.amazonaws.com/2015-03-31/functions/$name/invocations ), rather than being deployed behind APIGateway (where you have total control over the URL pattern where the lambda can be invoked). The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor.","title":"Example usage"},{"location":"reference/amazon/lambda/#default_fake_port_50322","text":"To start: FakeLambda().start()","title":"Default Fake port: 50322"},{"location":"reference/amazon/s3/","text":"S3 \u00b6 The S3 connector consists of 2 interfaces: S3 for global operations, providing the following Actions: CreateBucket HeadBucket ListBuckets S3Bucket for bucket level operations, providing the following Actions: CopyObject CreateObject DeleteBucket DeleteObject DeleteObjectTagging GetObject GetObjectTagging HeadObject ListObjectsV2 PutObject PutObjectTagging RestoreObject Example usage \u00b6 const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeS3 () val bucketName = BucketName . of ( \"foobar\" ) val bucketKey = BucketKey . of ( \"keyName\" ) val region = Region . of ( \"us-east-1\" ) // create global and bucket level clients val s3 = S3 . Http ({ AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) val s3Bucket = S3Bucket . Http ( bucketName , region , { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) // all operations return a Result monad of the API type val createResult : Result < Unit , RemoteFailure > = s3 . createBucket ( bucketName , region ) createResult . valueOrNull () !! // we can store some content in the bucket... val putResult : Result < Unit , RemoteFailure > = s3Bucket . putObject ( bucketKey , \"hellothere\" . byteInputStream ()) putResult . valueOrNull () !! // and get back the content which we stored val getResult : Result < InputStream?, RemoteFailure > = s3Bucket . get ( bucketKey ) val content : InputStream = getResult . valueOrNull () !! println ( content . reader (). readText ()) } The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor. How the Fake works with bucket-level operations \u00b6 S3 is a bit of a strange beast in that it each bucket gets its own virtual hostname. This makes running a Fake an interesting challenge without messing around with DNS and hostname files. This implementation supports both global and bucket level operations by inspecting the subdomain of the X-Forwarded-For header, which is populated by the S3 client built into this module. In the case of a missing header (if for instance a non-http4k client attempts to push some data into it without the x-forwarded-for header), it creates a global bucket which is then used to store all of the data for these unknown requests. Default Fake ports: \u00b6 Global: default port: 26467 Bucket: default port: 42628 FakeS3().start() Connecting to a local S3 emulator \u00b6 Services like LocalStack or MinIO can emulate AWS services locally. However, for S3 bucket operations you either need to use a specific pre-configured bucket hostname like http://<bucket-name>.s3.localhost.localstack.cloud:4566 , or you configure the S3Bucket to always perform path-style requests like this: val s3Bucket = S3Bucket . Http ( bucketName = bucketName , bucketRegion = region , credentialsProvider = { credentials }, overrideEndpoint = Uri . of ( \"http://localhost:4566\" ), forcePathStyle = true // always use path-style requests ) Pre-Signed Requests \u00b6 Http4k supports pre-signed requests with the generic AwsRequestPreSigner class. However, http4k-connect provides a simplified interface for common S3 Bucket operations with the S3BucketPresigner . fun main () { // create pre-signer val preSigner = S3BucketPreSigner ( bucketName = BucketName . of ( \"foobar\" ), region = Region . of ( \"us-east-1\" ), credentials = AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) ) val key = BucketKey . of ( \"keyName\" ) // create a pre-signed PUT val put = preSigner . put ( key = key , duration = Duration . ofMinutes ( 5 ), // how long the URL is valid for headers = listOf ( \"content-type\" to \"application.json\" ) // add optional signed headers ) println ( put . uri ) // create a pre-signed GET val get = preSigner . get ( key = key , duration = Duration . ofMinutes ( 5 ) ) println ( get ) // share these URIs to your clients so they can perform the operations without credentials }","title":"S3"},{"location":"reference/amazon/s3/#s3","text":"The S3 connector consists of 2 interfaces: S3 for global operations, providing the following Actions: CreateBucket HeadBucket ListBuckets S3Bucket for bucket level operations, providing the following Actions: CopyObject CreateObject DeleteBucket DeleteObject DeleteObjectTagging GetObject GetObjectTagging HeadObject ListObjectsV2 PutObject PutObjectTagging RestoreObject","title":"S3"},{"location":"reference/amazon/s3/#example_usage","text":"const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeS3 () val bucketName = BucketName . of ( \"foobar\" ) val bucketKey = BucketKey . of ( \"keyName\" ) val region = Region . of ( \"us-east-1\" ) // create global and bucket level clients val s3 = S3 . Http ({ AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) val s3Bucket = S3Bucket . Http ( bucketName , region , { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) // all operations return a Result monad of the API type val createResult : Result < Unit , RemoteFailure > = s3 . createBucket ( bucketName , region ) createResult . valueOrNull () !! // we can store some content in the bucket... val putResult : Result < Unit , RemoteFailure > = s3Bucket . putObject ( bucketKey , \"hellothere\" . byteInputStream ()) putResult . valueOrNull () !! // and get back the content which we stored val getResult : Result < InputStream?, RemoteFailure > = s3Bucket . get ( bucketKey ) val content : InputStream = getResult . valueOrNull () !! println ( content . reader (). readText ()) } The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor.","title":"Example usage"},{"location":"reference/amazon/s3/#how_the_fake_works_with_bucket-level_operations","text":"S3 is a bit of a strange beast in that it each bucket gets its own virtual hostname. This makes running a Fake an interesting challenge without messing around with DNS and hostname files. This implementation supports both global and bucket level operations by inspecting the subdomain of the X-Forwarded-For header, which is populated by the S3 client built into this module. In the case of a missing header (if for instance a non-http4k client attempts to push some data into it without the x-forwarded-for header), it creates a global bucket which is then used to store all of the data for these unknown requests.","title":"How the Fake works with bucket-level operations"},{"location":"reference/amazon/s3/#default_fake_ports","text":"Global: default port: 26467 Bucket: default port: 42628 FakeS3().start()","title":"Default Fake ports:"},{"location":"reference/amazon/s3/#connecting_to_a_local_s3_emulator","text":"Services like LocalStack or MinIO can emulate AWS services locally. However, for S3 bucket operations you either need to use a specific pre-configured bucket hostname like http://<bucket-name>.s3.localhost.localstack.cloud:4566 , or you configure the S3Bucket to always perform path-style requests like this: val s3Bucket = S3Bucket . Http ( bucketName = bucketName , bucketRegion = region , credentialsProvider = { credentials }, overrideEndpoint = Uri . of ( \"http://localhost:4566\" ), forcePathStyle = true // always use path-style requests )","title":"Connecting to a local S3 emulator"},{"location":"reference/amazon/s3/#pre-signed_requests","text":"Http4k supports pre-signed requests with the generic AwsRequestPreSigner class. However, http4k-connect provides a simplified interface for common S3 Bucket operations with the S3BucketPresigner . fun main () { // create pre-signer val preSigner = S3BucketPreSigner ( bucketName = BucketName . of ( \"foobar\" ), region = Region . of ( \"us-east-1\" ), credentials = AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) ) val key = BucketKey . of ( \"keyName\" ) // create a pre-signed PUT val put = preSigner . put ( key = key , duration = Duration . ofMinutes ( 5 ), // how long the URL is valid for headers = listOf ( \"content-type\" to \"application.json\" ) // add optional signed headers ) println ( put . uri ) // create a pre-signed GET val get = preSigner . get ( key = key , duration = Duration . ofMinutes ( 5 ) ) println ( get ) // share these URIs to your clients so they can perform the operations without credentials }","title":"Pre-Signed Requests"},{"location":"reference/amazon/secretsmanager/","text":"Secrets Manager \u00b6 The Secrets Manager connector provides the following Actions: * CreateSecret * DeleteSecret * GetSecretValue * ListSecrets * PutSecretValue * UpdateSecret Example usage \u00b6 const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeSecretsManager () // create a client val client = SecretsManager . Http ( Region . of ( \"us-east-1\" ), { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) val secretId = SecretId . of ( \"a-secret-id\" ) // all operations return a Result monad of the API type val createdSecretResult : Result < CreatedSecret , RemoteFailure > = client . createSecret ( secretId . value , UUID . randomUUID (), \"value\" ) println ( createdSecretResult . valueOrNull ()) // get the secret value back println ( client . getSecretValue ( secretId ). valueOrNull ()) } The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor. Default Fake port: 58194 \u00b6 To start: FakeSecretsManager().start()","title":"Secrets Manager"},{"location":"reference/amazon/secretsmanager/#secrets_manager","text":"The Secrets Manager connector provides the following Actions: * CreateSecret * DeleteSecret * GetSecretValue * ListSecrets * PutSecretValue * UpdateSecret","title":"Secrets Manager"},{"location":"reference/amazon/secretsmanager/#example_usage","text":"const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeSecretsManager () // create a client val client = SecretsManager . Http ( Region . of ( \"us-east-1\" ), { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) val secretId = SecretId . of ( \"a-secret-id\" ) // all operations return a Result monad of the API type val createdSecretResult : Result < CreatedSecret , RemoteFailure > = client . createSecret ( secretId . value , UUID . randomUUID (), \"value\" ) println ( createdSecretResult . valueOrNull ()) // get the secret value back println ( client . getSecretValue ( secretId ). valueOrNull ()) } The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor.","title":"Example usage"},{"location":"reference/amazon/secretsmanager/#default_fake_port_58194","text":"To start: FakeSecretsManager().start()","title":"Default Fake port: 58194"},{"location":"reference/amazon/ses/","text":"Simple Email Service \u00b6 The SES connector provides the following Actions: SendEmail The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor. Example usage \u00b6 Default Fake port: 59920 \u00b6 To start: FakeSES().start()","title":"SES"},{"location":"reference/amazon/ses/#simple_email_service","text":"The SES connector provides the following Actions: SendEmail The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor.","title":"Simple Email Service"},{"location":"reference/amazon/ses/#example_usage","text":"","title":"Example usage"},{"location":"reference/amazon/ses/#default_fake_port_59920","text":"To start: FakeSES().start()","title":"Default Fake port: 59920"},{"location":"reference/amazon/sns/","text":"Simple Notification Service \u00b6 The SNS connector provides the following Actions: CreateTopic DeleteTopic ListTopics Publish PublishBatch The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor. Example usage \u00b6 Default Fake port: 58430 \u00b6 To start: FakeSNS().start()","title":"SNS"},{"location":"reference/amazon/sns/#simple_notification_service","text":"The SNS connector provides the following Actions: CreateTopic DeleteTopic ListTopics Publish PublishBatch The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor.","title":"Simple Notification Service"},{"location":"reference/amazon/sns/#example_usage","text":"","title":"Example usage"},{"location":"reference/amazon/sns/#default_fake_port_58430","text":"To start: FakeSNS().start()","title":"Default Fake port: 58430"},{"location":"reference/amazon/sqs/","text":"Simple Queue Service \u00b6 The SQS connector provides the following Actions: * CreateQueue * DeleteMessage * DeleteQueue * GetQueueAttributes * ListQueues * ReceiveMessage * SendMessage The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor. Example usage \u00b6 const val USE_REAL_CLIENT = false fun main () { val region = Region . of ( \"us-east-1\" ) val queueName = QueueName . of ( \"myqueue\" ) val queueArn = ARN . of ( SQS . awsService , region , AwsAccount . of ( \"000000001\" ), queueName ) // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeSQS () // create a client val client = SQS . Http ( region , { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) // all operations return a Result monad of the API type val createdQueueResult : Result < CreatedQueue , RemoteFailure > = client . createQueue ( queueName , emptyMap (), emptyMap ()) println ( createdQueueResult . valueOrNull () !! ) // send a message println ( client . sendMessage ( queueArn , \"hello\" )) // and receive it.. println ( client . receiveMessage ( queueArn )) } Note that the FakeSQS is only suitable for very simple scenarios (testing and deployment for single consumer only) and does NOT implement real SQS semantics such as VisibilityTimeout or maximum number of retrieved messages (it delivers all undeleted messages to each consumer). Fake SQS queues are, as such, all inherently FIFO queues. Default Fake port: 37391 \u00b6 To start: FakeSQS().start()","title":"SQS"},{"location":"reference/amazon/sqs/#simple_queue_service","text":"The SQS connector provides the following Actions: * CreateQueue * DeleteMessage * DeleteQueue * GetQueueAttributes * ListQueues * ReceiveMessage * SendMessage The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor.","title":"Simple Queue Service"},{"location":"reference/amazon/sqs/#example_usage","text":"const val USE_REAL_CLIENT = false fun main () { val region = Region . of ( \"us-east-1\" ) val queueName = QueueName . of ( \"myqueue\" ) val queueArn = ARN . of ( SQS . awsService , region , AwsAccount . of ( \"000000001\" ), queueName ) // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeSQS () // create a client val client = SQS . Http ( region , { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) // all operations return a Result monad of the API type val createdQueueResult : Result < CreatedQueue , RemoteFailure > = client . createQueue ( queueName , emptyMap (), emptyMap ()) println ( createdQueueResult . valueOrNull () !! ) // send a message println ( client . sendMessage ( queueArn , \"hello\" )) // and receive it.. println ( client . receiveMessage ( queueArn )) } Note that the FakeSQS is only suitable for very simple scenarios (testing and deployment for single consumer only) and does NOT implement real SQS semantics such as VisibilityTimeout or maximum number of retrieved messages (it delivers all undeleted messages to each consumer). Fake SQS queues are, as such, all inherently FIFO queues.","title":"Example usage"},{"location":"reference/amazon/sqs/#default_fake_port_37391","text":"To start: FakeSQS().start()","title":"Default Fake port: 37391"},{"location":"reference/amazon/sts/","text":"Security Token Service \u00b6 The STS connector provides the following Actions: * AssumeRole * AssumeRoleWithWebIdentity The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor. Example usage \u00b6 const val USE_REAL_CLIENT = false fun main () { val region = Region . of ( \"us-east-1\" ) val roleArn = ARN . of ( \"arn:aws:sts:us-east-1:000000000001:role:myrole\" ) // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeSTS () // create a client val client = STS . Http ( region , { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) // all operations return a Result monad of the API type val assumeRoleResult : Result < AssumedRole , RemoteFailure > = client . assumeRole ( roleArn , \"sessionId\" ) println ( assumeRoleResult ) } Default Fake port: 20434 \u00b6 To start: FakeSTS().start()","title":"STS"},{"location":"reference/amazon/sts/#security_token_service","text":"The STS connector provides the following Actions: * AssumeRole * AssumeRoleWithWebIdentity The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor.","title":"Security Token Service"},{"location":"reference/amazon/sts/#example_usage","text":"const val USE_REAL_CLIENT = false fun main () { val region = Region . of ( \"us-east-1\" ) val roleArn = ARN . of ( \"arn:aws:sts:us-east-1:000000000001:role:myrole\" ) // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeSTS () // create a client val client = STS . Http ( region , { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) // all operations return a Result monad of the API type val assumeRoleResult : Result < AssumedRole , RemoteFailure > = client . assumeRole ( roleArn , \"sessionId\" ) println ( assumeRoleResult ) }","title":"Example usage"},{"location":"reference/amazon/sts/#default_fake_port_20434","text":"To start: FakeSTS().start()","title":"Default Fake port: 20434"},{"location":"reference/amazon/systemsmanager/","text":"Systems Manager \u00b6 The Systems Manager connector provides the following Actions: * DeleteParameter * GetParameter * PutParameter Example usage \u00b6 const val USE_REAL_CLIENT = false fun main () { val paramName = SSMParameterName . of ( \"name\" ) // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeSystemsManager () // create a client val client = SystemsManager . Http ( Region . of ( \"us-east-1\" ), { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) // all operations return a Result monad of the API type val putParameterResult : Result < PutParameterResult , RemoteFailure > = client . putParameter ( paramName , \"value\" , ParameterType . String ) println ( putParameterResult ) // get the parameter back again println ( client . getParameter ( paramName )) } The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor. Default Fake port: 42551 \u00b6 To start: FakeSecretsManager().start()","title":"Systems Manager"},{"location":"reference/amazon/systemsmanager/#systems_manager","text":"The Systems Manager connector provides the following Actions: * DeleteParameter * GetParameter * PutParameter","title":"Systems Manager"},{"location":"reference/amazon/systemsmanager/#example_usage","text":"const val USE_REAL_CLIENT = false fun main () { val paramName = SSMParameterName . of ( \"name\" ) // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeSystemsManager () // create a client val client = SystemsManager . Http ( Region . of ( \"us-east-1\" ), { AwsCredentials ( \"accessKeyId\" , \"secretKey\" ) }, http . debug ()) // all operations return a Result monad of the API type val putParameterResult : Result < PutParameterResult , RemoteFailure > = client . putParameter ( paramName , \"value\" , ParameterType . String ) println ( putParameterResult ) // get the parameter back again println ( client . getParameter ( paramName )) } The client APIs utilise the http4k-aws module for request signing, which means no dependencies on the incredibly fat Amazon-SDK JARs. This means this integration is perfect for running Serverless Lambdas where binary size is a performance factor.","title":"Example usage"},{"location":"reference/amazon/systemsmanager/#default_fake_port_42551","text":"To start: FakeSecretsManager().start()","title":"Default Fake port: 42551"},{"location":"reference/example/","text":"Example Service \u00b6 The Example connector provides the following Actions: * Echo Example usage \u00b6 const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeExample () // create a client val example = Example . Http ( http . debug ()) // all operations return a Result monad of the API type val echoedResult : Result < Echoed , RemoteFailure > = example . echo ( \"hello\" ) println ( echoedResult ) } Default Fake port: 22375 \u00b6 To start: FakeExample().start()","title":"Example Service"},{"location":"reference/example/#example_service","text":"The Example connector provides the following Actions: * Echo","title":"Example Service"},{"location":"reference/example/#example_usage","text":"const val USE_REAL_CLIENT = false fun main () { // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeExample () // create a client val example = Example . Http ( http . debug ()) // all operations return a Result monad of the API type val echoedResult : Result < Echoed , RemoteFailure > = example . echo ( \"hello\" ) println ( echoedResult ) }","title":"Example usage"},{"location":"reference/example/#default_fake_port_22375","text":"To start: FakeExample().start()","title":"Default Fake port: 22375"},{"location":"reference/github/","text":"GitHub \u00b6 The GitHub connector currently provides basic action interfaces and support for verifying webhook signatures only.","title":"GitHub"},{"location":"reference/github/#github","text":"The GitHub connector currently provides basic action interfaces and support for verifying webhook signatures only.","title":"GitHub"},{"location":"reference/gitlab/","text":"GitLab \u00b6 The GitLab connector currently provides basic action interfaces.","title":"GitLab"},{"location":"reference/gitlab/#gitlab","text":"The GitLab connector currently provides basic action interfaces.","title":"GitLab"},{"location":"reference/google/analytics-ga4/","text":"Google Analytics \u00b6 The GA connector provides the following Actions: * PageView * Event Default Fake port: 35628 \u00b6 To start: FakeGoogleAnalytics().start()","title":"Analytics V4"},{"location":"reference/google/analytics-ga4/#google_analytics","text":"The GA connector provides the following Actions: * PageView * Event","title":"Google Analytics"},{"location":"reference/google/analytics-ga4/#default_fake_port_35628","text":"To start: FakeGoogleAnalytics().start()","title":"Default Fake port: 35628"},{"location":"reference/google/analytics-ua/","text":"Google Analytics \u00b6 The GA connector provides the following Actions: * PageView * Event Default Fake port: 35628 \u00b6 To start: FakeGoogleAnalytics().start()","title":"Analytics UA"},{"location":"reference/google/analytics-ua/#google_analytics","text":"The GA connector provides the following Actions: * PageView * Event","title":"Google Analytics"},{"location":"reference/google/analytics-ua/#default_fake_port_35628","text":"To start: FakeGoogleAnalytics().start()","title":"Default Fake port: 35628"},{"location":"reference/kafka/rest/","text":"Kafka Rest Proxy \u00b6 There are 2 distinct APIs in the Rest proxy: v2 \u00b6 The main KafkaRest connector provides the following v2 Actions: CreateConsumer DeleteConsumer GetOffsets GetPartitions SeekOffsets CommitOffsets ConsumeRecords ProduceMessages SubscribeToTopics In addition, you can use a KafkaRestConsumer which provides the following Actions: ConsumeRecords Delete GetOffsets SeekOffsets CommitOffsets SubscribeToTopics Record formats \u00b6 The following formats of Kafka records are supported currently. Partition keys are optional and null by default: JSON \u00b6 All keys and messages will be auto-marshalled to JSON using the standard Moshi instance (which supports most common JDK types): Records . Json ( listOf ( Record ( \"123\" , \"value\" , PartitionId . of ( 123 )))) AVRO \u00b6 Support for GenericContainer classes (auto-generated from schema). The Key and Value schemas will be extracted from the Key and Value and sent with the message automatically. Records . Avro ( listOf ( Record ( RandomEvent ( UUID . nameUUIDFromBytes ( it . toByteArray ())), RandomEvent ( UUID ( 0 , 0 ), PartitionId . of ( 123 )) ) ) ) Binary \u00b6 Record contents are specified using Base64 type for wire transport: Records . Binary ( listOf ( Record ( Base64Blob . encode ( \"123\" ), Base64Blob . encode ( \"456\" ), PartitionId . of ( 123 )))) Notes on message production \u00b6 Messages can be sent to the broker with or without PartitionIds. If you want to use a strategy for partitioning, the Partitioner interface can be implemented and used as below. RoundRobin and Sticky (key-hash % Partitions) strategies come out of the box. val kafkaRest = KafkaRest . Http ( Credentials ( \"user\" , \"password\" ), Uri . of ( \"http://restproxy\" ), JavaHttpClient () ) kafkaRest . produceMessages ( Topic . of ( \"topic\" ), Records . Json ( listOf ( Record ( \"123\" , \"\" ))), :: RoundRobinRecordPartitioner ) To keep things simple with respect to partition allocation and rebalancing, the above code will fetch the available partitions on each send to the REST proxy using the /topics/$topic/partitions call. This is obviously not very efficient, but can be reimplemented as needed using any caching strategy which you might wish to implement. v3 (Confluent API) \u00b6 The main KafkaRest connector provides the following v2 Actions: GetPartitions GetTopic GetTopics ProduceRecords Record formats \u00b6 The following formats of Kafka records are supported currently. Partition keys are optional and null by default: JSON \u00b6 All keys and messages will be auto-marshalled to JSON using the standard Moshi instance (which supports most common JDK types): Record ( Json ( mapOf ( \"key\" to \"value\" ))) Binary \u00b6 Record contents are specified using Base64 type for wire transport: Record ( Binary ( Base64Blob . encode ( \"foo1\" ))) Notes on message production \u00b6 Messages can be sent to the broker with or without PartitionIds. If you want to use a strategy for partitioning, the Partitioner interface can be implemented and used as below. RoundRobin and Sticky (key-hash % Partitions) strategies come out of the box. val kafkaRest = KafkaRest . Http ( Credentials ( \"user\" , \"password\" ), Uri . of ( \"http://restproxy\" ), JavaHttpClient () ) kafkaRest . produceRecordsWithPartitions ( topic , clusterId , listOf ( Record ( Binary ( Base64Blob . encode ( \"foo1\" ))),), :: RoundRobinRecordPartitioner ) To keep things simple with respect to partition allocation and rebalancing, the above code will fetch the available partitions on each send to the REST proxy using the /kafka/v3/clusters/$id/topics/$topic/partitions call. This is obviously not very efficient, but can be reimplemented as needed using any caching strategy which you might wish to implement. Fake \u00b6 The Fake provides the all of the above endpoints listed for v2 and v3, which is enough for basic consumer lifecycle and production and consumption of records. Note that consumers by default will start at the start of the topic stream, although they can be committed to. \"auto.commit.enable\" is enabled by default but can be set to \"false\" for manual committing of offsets. Default Fake port: 30091 \u00b6 To start: FakeKafkaRest().start()","title":"REST Gateway"},{"location":"reference/kafka/rest/#kafka_rest_proxy","text":"There are 2 distinct APIs in the Rest proxy:","title":"Kafka Rest Proxy"},{"location":"reference/kafka/rest/#v2","text":"The main KafkaRest connector provides the following v2 Actions: CreateConsumer DeleteConsumer GetOffsets GetPartitions SeekOffsets CommitOffsets ConsumeRecords ProduceMessages SubscribeToTopics In addition, you can use a KafkaRestConsumer which provides the following Actions: ConsumeRecords Delete GetOffsets SeekOffsets CommitOffsets SubscribeToTopics","title":"v2"},{"location":"reference/kafka/rest/#record_formats","text":"The following formats of Kafka records are supported currently. Partition keys are optional and null by default:","title":"Record formats"},{"location":"reference/kafka/rest/#json","text":"All keys and messages will be auto-marshalled to JSON using the standard Moshi instance (which supports most common JDK types): Records . Json ( listOf ( Record ( \"123\" , \"value\" , PartitionId . of ( 123 ))))","title":"JSON"},{"location":"reference/kafka/rest/#avro","text":"Support for GenericContainer classes (auto-generated from schema). The Key and Value schemas will be extracted from the Key and Value and sent with the message automatically. Records . Avro ( listOf ( Record ( RandomEvent ( UUID . nameUUIDFromBytes ( it . toByteArray ())), RandomEvent ( UUID ( 0 , 0 ), PartitionId . of ( 123 )) ) ) )","title":"AVRO"},{"location":"reference/kafka/rest/#binary","text":"Record contents are specified using Base64 type for wire transport: Records . Binary ( listOf ( Record ( Base64Blob . encode ( \"123\" ), Base64Blob . encode ( \"456\" ), PartitionId . of ( 123 ))))","title":"Binary"},{"location":"reference/kafka/rest/#notes_on_message_production","text":"Messages can be sent to the broker with or without PartitionIds. If you want to use a strategy for partitioning, the Partitioner interface can be implemented and used as below. RoundRobin and Sticky (key-hash % Partitions) strategies come out of the box. val kafkaRest = KafkaRest . Http ( Credentials ( \"user\" , \"password\" ), Uri . of ( \"http://restproxy\" ), JavaHttpClient () ) kafkaRest . produceMessages ( Topic . of ( \"topic\" ), Records . Json ( listOf ( Record ( \"123\" , \"\" ))), :: RoundRobinRecordPartitioner ) To keep things simple with respect to partition allocation and rebalancing, the above code will fetch the available partitions on each send to the REST proxy using the /topics/$topic/partitions call. This is obviously not very efficient, but can be reimplemented as needed using any caching strategy which you might wish to implement.","title":"Notes on message production"},{"location":"reference/kafka/rest/#v3_confluent_api","text":"The main KafkaRest connector provides the following v2 Actions: GetPartitions GetTopic GetTopics ProduceRecords","title":"v3 (Confluent API)"},{"location":"reference/kafka/rest/#record_formats_1","text":"The following formats of Kafka records are supported currently. Partition keys are optional and null by default:","title":"Record formats"},{"location":"reference/kafka/rest/#json_1","text":"All keys and messages will be auto-marshalled to JSON using the standard Moshi instance (which supports most common JDK types): Record ( Json ( mapOf ( \"key\" to \"value\" )))","title":"JSON"},{"location":"reference/kafka/rest/#binary_1","text":"Record contents are specified using Base64 type for wire transport: Record ( Binary ( Base64Blob . encode ( \"foo1\" )))","title":"Binary"},{"location":"reference/kafka/rest/#notes_on_message_production_1","text":"Messages can be sent to the broker with or without PartitionIds. If you want to use a strategy for partitioning, the Partitioner interface can be implemented and used as below. RoundRobin and Sticky (key-hash % Partitions) strategies come out of the box. val kafkaRest = KafkaRest . Http ( Credentials ( \"user\" , \"password\" ), Uri . of ( \"http://restproxy\" ), JavaHttpClient () ) kafkaRest . produceRecordsWithPartitions ( topic , clusterId , listOf ( Record ( Binary ( Base64Blob . encode ( \"foo1\" ))),), :: RoundRobinRecordPartitioner ) To keep things simple with respect to partition allocation and rebalancing, the above code will fetch the available partitions on each send to the REST proxy using the /kafka/v3/clusters/$id/topics/$topic/partitions call. This is obviously not very efficient, but can be reimplemented as needed using any caching strategy which you might wish to implement.","title":"Notes on message production"},{"location":"reference/kafka/rest/#fake","text":"The Fake provides the all of the above endpoints listed for v2 and v3, which is enough for basic consumer lifecycle and production and consumption of records. Note that consumers by default will start at the start of the topic stream, although they can be committed to. \"auto.commit.enable\" is enabled by default but can be set to \"false\" for manual committing of offsets.","title":"Fake"},{"location":"reference/kafka/rest/#default_fake_port_30091","text":"To start: FakeKafkaRest().start()","title":"Default Fake port: 30091"},{"location":"reference/kafka/schemaregistry/","text":"Kafka Schema Registry \u00b6 The main SchemaRegistry connector provides the following Actions: CheckSchemaRegistered GetSchemaById GetSubjects GetSubjectVersion GetSubjectVersions RegisterSchema Fake \u00b6 The Fake provides the above actions. Default Fake port: 41466 \u00b6 To start: FakeSchemaRegistry().start()","title":"Schema Registry"},{"location":"reference/kafka/schemaregistry/#kafka_schema_registry","text":"The main SchemaRegistry connector provides the following Actions: CheckSchemaRegistered GetSchemaById GetSubjects GetSubjectVersion GetSubjectVersions RegisterSchema","title":"Kafka Schema Registry"},{"location":"reference/kafka/schemaregistry/#fake","text":"The Fake provides the above actions.","title":"Fake"},{"location":"reference/kafka/schemaregistry/#default_fake_port_41466","text":"To start: FakeSchemaRegistry().start()","title":"Default Fake port: 41466"},{"location":"reference/mattermost/","text":"Mattermost Service \u00b6 The Mattermost connector provides the following Actions: TriggerWebhook Example usage \u00b6 const val USE_REAL_CLIENT = false fun main () { val payloads = Storage . InMemory < List < TriggerWebhookPayload >> () // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeMattermost ( payloads ) // create a client val mattermost = Mattermost . Http ( baseUri = Uri . of ( \"https://mattermost.com\" ), http = http . debug () ) val payload = TriggerWebhookPayload ( text = \"Hello world\" , iconUrl = \"http://icon.url\" , ) // all operations return a Result monad of the API type val result : Result < String , RemoteFailure > = mattermost . triggerWebhook ( key = UUID . randomUUID (). toString (), payload = payload , ) println ( result ) println ( payloads ) } Default Fake port: 54786 \u00b6 To start: FakeMattermost (). start ()","title":"Mattermost"},{"location":"reference/mattermost/#mattermost_service","text":"The Mattermost connector provides the following Actions: TriggerWebhook","title":"Mattermost Service"},{"location":"reference/mattermost/#example_usage","text":"const val USE_REAL_CLIENT = false fun main () { val payloads = Storage . InMemory < List < TriggerWebhookPayload >> () // we can connect to the real service or the fake (drop in replacement) val http : HttpHandler = if ( USE_REAL_CLIENT ) JavaHttpClient () else FakeMattermost ( payloads ) // create a client val mattermost = Mattermost . Http ( baseUri = Uri . of ( \"https://mattermost.com\" ), http = http . debug () ) val payload = TriggerWebhookPayload ( text = \"Hello world\" , iconUrl = \"http://icon.url\" , ) // all operations return a Result monad of the API type val result : Result < String , RemoteFailure > = mattermost . triggerWebhook ( key = UUID . randomUUID (). toString (), payload = payload , ) println ( result ) println ( payloads ) }","title":"Example usage"},{"location":"reference/mattermost/#default_fake_port_54786","text":"To start: FakeMattermost (). start ()","title":"Default Fake port: 54786"}]}